{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement keras.engine (from versions: none)\n",
      "ERROR: No matching distribution found for keras.engine\n"
     ]
    }
   ],
   "source": [
    "%pip install keras.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 total face names.\n",
      "There are 471 total face images.\n",
      "\n",
      "There are 120 training face images.\n",
      "There are 351 validation face images.\n",
      "There are 0 test face images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    \"\"\"\n",
    "    Loads the images from path.\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    path : String\n",
    "        Holds the path of the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Array\n",
    "        Two numpy arrays that holds the images and the targets.\n",
    "    \"\"\"\n",
    "    data = load_files(path)\n",
    "    face_files = np.array(data['filenames'])\n",
    "    face_targets = np_utils.to_categorical(np.array(data['target']), 2)\n",
    "    return face_files, face_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('images/train')\n",
    "valid_files, valid_targets = load_dataset('images/valid')\n",
    "test_files, test_targets = load_dataset('images/test')\n",
    "\n",
    "\n",
    "# load list of dog names\n",
    "face_names = [item[20:-1] for item in sorted(glob(\"images/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total face names.' % len(face_names))\n",
    "print('There are %s total face images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training face images.' % len(train_files))\n",
    "print('There are %d validation face images.' % len(valid_files))\n",
    "print('There are %d test face images.'% len(test_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_viz(history, xc_length):\n",
    "    \"\"\"\n",
    "    Visualizes training history.\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    history : Keras object\n",
    "        Holds the training history\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Empty.\n",
    "    \"\"\"\n",
    "    train_loss = history_aug.history['loss']\n",
    "    val_loss = history_aug.history['val_loss']\n",
    "    train_acc = history_aug.history['acc']\n",
    "    val_acc = history_aug.history['val_acc']\n",
    "    xc = range(xc_length)\n",
    "\n",
    "    # Visualize Train vs Validation loss\n",
    "    plt.figure(1,figsize=(7,5))\n",
    "    plt.plot(xc,train_loss)\n",
    "    plt.plot(xc,val_loss)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train_loss vs Val_loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    print (plt.style.available)\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    # Visualize Train vs Validation Accuracy\n",
    "    plt.figure(2,figsize=(7,5))\n",
    "    plt.plot(xc,train_acc)\n",
    "    plt.plot(xc,val_acc)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.title('Train Acc vs Val Acc')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Train','Val'],loc=4)\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loads the weights and Evaluates the model's performance\n",
    "def load_weights(model,file_name, test, test_targets):\n",
    "    \"\"\"\n",
    "    Load the best weights saved from during training the proposed CNN architecture and evaluates the model's performance.\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    model : Keras object\n",
    "        Holds the proposed CNN architecture.\n",
    "    \n",
    "    test : Numpy array\n",
    "        Holds the test images.\n",
    "    \n",
    "    test_targets : Numpy Array\n",
    "        Holds the images labels in a string format.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Empty.\n",
    "    \"\"\"\n",
    "    model.load_weights('saved_models/' + file_name) # Load weights\n",
    "\n",
    "    score = model.evaluate(test, test_targets, verbose=0)\n",
    "    print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.bar(range(2), [len(train_files_orig),len(train_files_fake)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Load original image\n",
    "img_1 = mpimg.imread(train_files[0])\n",
    "\n",
    "# Load fake image\n",
    "img_2 = mpimg.imread(train_files[2])\n",
    "\n",
    "# Print a subplot\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.imshow(img_1)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(img_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pre-process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    \"\"\"\n",
    "    Creates tensor of a single image to be consumed by the CNN architecture.\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    img_path : Numpy Array\n",
    "        Holds the images paths.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tensor : Tensorflow object.\n",
    "        Holds the converted image.\n",
    "    \"\"\"\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    \"\"\"\n",
    "    Creates tensors of images to be consumed by the CNN architecture.\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    img_path : Numpy Array\n",
    "        Holds the images paths.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_tensors : Tensorflow object.\n",
    "        Holds the converted images.\n",
    "    \"\"\"\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize, Rescale and Gray Scale Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_img(img, max_dim=96):\n",
    "    large_axis = max((0, 1), key=lambda x: img.size[x])\n",
    "    scalar = max_dim / float(img.size[large_axis])\n",
    "    resized = img.resize(\n",
    "        (int(img.size[0] * scalar), int(img.size[1] * scalar)))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def load_image_data(id_list, max_dim=96, center=True):   \n",
    "    X = np.empty((len(id_list), max_dim, max_dim, 1))\n",
    "    for i, idnum in enumerate(id_list):\n",
    "        x = image.load_img(\n",
    "            (str(idnum)), grayscale=True)\n",
    "        x = image.img_to_array(resize_img(x, max_dim=max_dim))\n",
    "        height = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        if center:\n",
    "            h1 = int((max_dim - height) / 2)\n",
    "            h2 = h1 + height\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (height, width)\n",
    "        X[i, h1:h2, w1:w2, :] = x\n",
    "    return np.around(X / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation For The Fake Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "def aug():\n",
    "    \"\"\"\n",
    "    Auguments the images in case the dataset of images is small.\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    Empty.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    datagen_train : ImageDatagenerator Object.\n",
    "        Holds the augumented train dataset.\n",
    "    \"\"\"\n",
    "    # create and configure augmented image generator\n",
    "    datagen_train = ImageDataGenerator(\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (10% of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (10% of total height)\n",
    "        #horizontal_flip=True,\n",
    "        #vertical_flip = True,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.2) # randomly flip images horizontally\n",
    "        # fit augmented image generator on data\n",
    "    return datagen_train\n",
    "    #datagen_valid.fit(valid_tensors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m4\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,577,542</span> (6.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,577,542\u001b[0m (6.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,575,524</span> (6.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,575,524\u001b[0m (6.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,018</span> (7.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,018\u001b[0m (7.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "\"\"\"\n",
    "    Propsoed CNN architecture.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Pamameters Initialization\n",
    "input_shape = (96, 96, 1)\n",
    "activation = 'relu'\n",
    "padding = 'same'\n",
    "droprate = 0.1\n",
    "epsilon=0.001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation=activation, padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization(epsilon=epsilon))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation=activation, padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization(epsilon=epsilon))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation=activation, padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization(epsilon=epsilon))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, activation=activation, padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization(epsilon=epsilon))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=3, activation=activation, padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization(epsilon=epsilon))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=3, activation=activation, padding=padding))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization(epsilon=epsilon))\n",
    "model.add(Dropout(droprate))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(256, kernel_initializer='glorot_normal', activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "          \n",
    "#model.add(Dense(128, kernel_initializer='glorot_normal', activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dropout(droprate))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary() # Summary of the architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters Initialization\n",
    "from keras.optimizers import rmsprop,SGD,Adam,Adadelta\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = RMSprop(lr=0.0001)\n",
    "\n",
    "# Compile your model, passing the optimizer identifier as a string\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def load_image_data(id_list, max_dim, center):\n",
    "    X = np.empty((len(id_list), max_dim, max_dim, 1))\n",
    "    for i, idnum in enumerate(id_list):\n",
    "        x = image.load_img(str(idnum))\n",
    "        x = x.convert('L')  # Convert image to grayscale\n",
    "        x = image.img_to_array(resize_img(x, max_dim=max_dim))\n",
    "        height = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        if center:\n",
    "            h1 = int((max_dim - height) / 2)\n",
    "            h2 = h1 + height\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "            X[i, h1:h2, w1:w2, 0:1] = x\n",
    "        else:\n",
    "            X[i, 0:height, 0:width, 0:1] = x\n",
    "    return X\n",
    "train_X = load_image_data(train_files,max_dim=224, center=True)\n",
    "valid_X = load_image_data(valid_files,max_dim=224, center=True)\n",
    "test_X = load_image_data(test_files,max_dim=224, center=True)\n",
    "\n",
    "train_augmented_X = aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model on Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=saved_models/weights.custom.best.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 6\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaved_models/weights.custom.best.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m hist \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_X, train_targets,\n\u001b[0;32m     11\u001b[0m                     steps_per_epoch\u001b[38;5;241m=\u001b[39mtrain_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] ,\n\u001b[0;32m     12\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mepochs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[checkpointer,early_stopping],\n\u001b[0;32m     13\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(valid_X, valid_targets),\n\u001b[0;32m     14\u001b[0m                     validation_steps\u001b[38;5;241m=\u001b[39mvalid_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] )\n",
      "File \u001b[1;32md:\\python\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:191\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[1;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filepath provided must end in `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras model format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=saved_models/weights.custom.best.hdf5"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping  \n",
    "\n",
    "batch_size = 10\n",
    "epochs = 100\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.custom.best.hdf5', \n",
    "                               monitor='val_loss',verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='auto')\n",
    "hist = model.fit(train_X, train_targets,\n",
    "                    steps_per_epoch=train_X.shape[0] ,\n",
    "                    epochs=epochs, verbose=1, callbacks=[checkpointer,early_stopping],\n",
    "                    validation_data=(valid_X, valid_targets),\n",
    "                    validation_steps=valid_X.shape[0] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on Orgiginal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights(model_custom,'weights.custom.best.hdf5', test_X, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model on Augumented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/427 [=============>................] - ETA: 1:25:29 - loss: 0.7600 - acc: 0.35 - ETA: 45:40 - loss: 0.6676 - acc: 0.5750 - ETA: 32:01 - loss: 0.6866 - acc: 0.60 - ETA: 24:56 - loss: 0.6680 - acc: 0.62 - ETA: 20:43 - loss: 0.6497 - acc: 0.62 - ETA: 17:51 - loss: 0.6721 - acc: 0.60 - ETA: 15:44 - loss: 0.6745 - acc: 0.60 - ETA: 14:06 - loss: 0.6799 - acc: 0.59 - ETA: 12:48 - loss: 0.6668 - acc: 0.62 - ETA: 11:36 - loss: 0.6545 - acc: 0.61 - ETA: 10:46 - loss: 0.6327 - acc: 0.63 - ETA: 10:03 - loss: 0.6482 - acc: 0.63 - ETA: 9:27 - loss: 0.6469 - acc: 0.6478 - ETA: 8:55 - loss: 0.6554 - acc: 0.637 - ETA: 8:28 - loss: 0.6532 - acc: 0.638 - ETA: 8:04 - loss: 0.6621 - acc: 0.635 - ETA: 7:43 - loss: 0.6633 - acc: 0.633 - ETA: 7:24 - loss: 0.6615 - acc: 0.634 - ETA: 7:07 - loss: 0.6576 - acc: 0.635 - ETA: 6:52 - loss: 0.6501 - acc: 0.646 - ETA: 6:36 - loss: 0.6445 - acc: 0.653 - ETA: 6:22 - loss: 0.6374 - acc: 0.662 - ETA: 6:10 - loss: 0.6476 - acc: 0.655 - ETA: 5:59 - loss: 0.6445 - acc: 0.661 - ETA: 5:48 - loss: 0.6409 - acc: 0.662 - ETA: 5:38 - loss: 0.6345 - acc: 0.673 - ETA: 5:29 - loss: 0.6411 - acc: 0.663 - ETA: 5:20 - loss: 0.6436 - acc: 0.659 - ETA: 5:12 - loss: 0.6402 - acc: 0.664 - ETA: 5:02 - loss: 0.6384 - acc: 0.661 - ETA: 4:55 - loss: 0.6354 - acc: 0.667 - ETA: 4:49 - loss: 0.6330 - acc: 0.670 - ETA: 4:42 - loss: 0.6320 - acc: 0.671 - ETA: 4:36 - loss: 0.6316 - acc: 0.671 - ETA: 4:30 - loss: 0.6266 - acc: 0.676 - ETA: 4:25 - loss: 0.6252 - acc: 0.679 - ETA: 4:20 - loss: 0.6216 - acc: 0.682 - ETA: 4:15 - loss: 0.6221 - acc: 0.682 - ETA: 4:10 - loss: 0.6223 - acc: 0.683 - ETA: 4:05 - loss: 0.6218 - acc: 0.682 - ETA: 4:01 - loss: 0.6208 - acc: 0.685 - ETA: 3:57 - loss: 0.6190 - acc: 0.686 - ETA: 3:53 - loss: 0.6183 - acc: 0.689 - ETA: 3:50 - loss: 0.6159 - acc: 0.694 - ETA: 3:47 - loss: 0.6179 - acc: 0.693 - ETA: 3:43 - loss: 0.6186 - acc: 0.692 - ETA: 3:40 - loss: 0.6195 - acc: 0.690 - ETA: 3:36 - loss: 0.6193 - acc: 0.687 - ETA: 3:33 - loss: 0.6169 - acc: 0.691 - ETA: 3:30 - loss: 0.6144 - acc: 0.693 - ETA: 3:28 - loss: 0.6138 - acc: 0.694 - ETA: 3:25 - loss: 0.6099 - acc: 0.698 - ETA: 3:23 - loss: 0.6105 - acc: 0.699 - ETA: 3:20 - loss: 0.6091 - acc: 0.700 - ETA: 3:18 - loss: 0.6068 - acc: 0.702 - ETA: 3:15 - loss: 0.6058 - acc: 0.702 - ETA: 3:13 - loss: 0.6047 - acc: 0.702 - ETA: 3:11 - loss: 0.6021 - acc: 0.705 - ETA: 3:08 - loss: 0.6005 - acc: 0.707 - ETA: 3:06 - loss: 0.6013 - acc: 0.706 - ETA: 3:04 - loss: 0.6010 - acc: 0.708 - ETA: 3:02 - loss: 0.6014 - acc: 0.707 - ETA: 3:00 - loss: 0.6009 - acc: 0.710 - ETA: 2:58 - loss: 0.5987 - acc: 0.713 - ETA: 2:56 - loss: 0.5967 - acc: 0.714 - ETA: 2:55 - loss: 0.5975 - acc: 0.714 - ETA: 2:53 - loss: 0.5961 - acc: 0.715 - ETA: 2:51 - loss: 0.5947 - acc: 0.715 - ETA: 2:50 - loss: 0.5936 - acc: 0.716 - ETA: 2:48 - loss: 0.5933 - acc: 0.716 - ETA: 2:46 - loss: 0.5931 - acc: 0.717 - ETA: 2:45 - loss: 0.5913 - acc: 0.720 - ETA: 2:44 - loss: 0.5879 - acc: 0.723 - ETA: 2:42 - loss: 0.5880 - acc: 0.725 - ETA: 2:41 - loss: 0.5873 - acc: 0.726 - ETA: 2:40 - loss: 0.5867 - acc: 0.727 - ETA: 2:38 - loss: 0.5867 - acc: 0.728 - ETA: 2:37 - loss: 0.5868 - acc: 0.729 - ETA: 2:36 - loss: 0.5875 - acc: 0.728 - ETA: 2:34 - loss: 0.5860 - acc: 0.728 - ETA: 2:33 - loss: 0.5854 - acc: 0.728 - ETA: 2:32 - loss: 0.5841 - acc: 0.729 - ETA: 2:31 - loss: 0.5823 - acc: 0.730 - ETA: 2:30 - loss: 0.5806 - acc: 0.731 - ETA: 2:28 - loss: 0.5803 - acc: 0.731 - ETA: 2:27 - loss: 0.5799 - acc: 0.731 - ETA: 2:26 - loss: 0.5789 - acc: 0.733 - ETA: 2:25 - loss: 0.5803 - acc: 0.731 - ETA: 2:24 - loss: 0.5792 - acc: 0.734 - ETA: 2:23 - loss: 0.5788 - acc: 0.734 - ETA: 2:22 - loss: 0.5784 - acc: 0.734 - ETA: 2:21 - loss: 0.5772 - acc: 0.735 - ETA: 2:20 - loss: 0.5755 - acc: 0.736 - ETA: 2:19 - loss: 0.5757 - acc: 0.735 - ETA: 2:18 - loss: 0.5748 - acc: 0.736 - ETA: 2:17 - loss: 0.5736 - acc: 0.737 - ETA: 2:16 - loss: 0.5747 - acc: 0.735 - ETA: 2:15 - loss: 0.5733 - acc: 0.736 - ETA: 2:14 - loss: 0.5724 - acc: 0.737 - ETA: 2:13 - loss: 0.5753 - acc: 0.736 - ETA: 2:12 - loss: 0.5744 - acc: 0.738 - ETA: 2:11 - loss: 0.5752 - acc: 0.737 - ETA: 2:10 - loss: 0.5759 - acc: 0.737 - ETA: 2:09 - loss: 0.5769 - acc: 0.738 - ETA: 2:08 - loss: 0.5758 - acc: 0.739 - ETA: 2:08 - loss: 0.5752 - acc: 0.739 - ETA: 2:07 - loss: 0.5737 - acc: 0.740 - ETA: 2:06 - loss: 0.5735 - acc: 0.740 - ETA: 2:05 - loss: 0.5727 - acc: 0.740 - ETA: 2:05 - loss: 0.5714 - acc: 0.741 - ETA: 2:04 - loss: 0.5707 - acc: 0.742 - ETA: 2:03 - loss: 0.5699 - acc: 0.742 - ETA: 2:02 - loss: 0.5689 - acc: 0.742 - ETA: 2:02 - loss: 0.5692 - acc: 0.742 - ETA: 2:01 - loss: 0.5693 - acc: 0.743 - ETA: 2:00 - loss: 0.5698 - acc: 0.742 - ETA: 2:00 - loss: 0.5681 - acc: 0.744 - ETA: 1:59 - loss: 0.5668 - acc: 0.745 - ETA: 1:58 - loss: 0.5646 - acc: 0.746 - ETA: 1:58 - loss: 0.5643 - acc: 0.747 - ETA: 1:57 - loss: 0.5649 - acc: 0.746 - ETA: 1:56 - loss: 0.5643 - acc: 0.746 - ETA: 1:56 - loss: 0.5636 - acc: 0.748 - ETA: 1:55 - loss: 0.5643 - acc: 0.747 - ETA: 1:54 - loss: 0.5642 - acc: 0.748 - ETA: 1:54 - loss: 0.5635 - acc: 0.748 - ETA: 1:53 - loss: 0.5624 - acc: 0.749 - ETA: 1:52 - loss: 0.5612 - acc: 0.748 - ETA: 1:51 - loss: 0.5611 - acc: 0.748 - ETA: 1:51 - loss: 0.5596 - acc: 0.749 - ETA: 1:50 - loss: 0.5589 - acc: 0.750 - ETA: 1:49 - loss: 0.5576 - acc: 0.750 - ETA: 1:49 - loss: 0.5578 - acc: 0.749 - ETA: 1:48 - loss: 0.5568 - acc: 0.750 - ETA: 1:47 - loss: 0.5555 - acc: 0.750 - ETA: 1:47 - loss: 0.5548 - acc: 0.751 - ETA: 1:46 - loss: 0.5531 - acc: 0.753 - ETA: 1:46 - loss: 0.5521 - acc: 0.754 - ETA: 1:45 - loss: 0.5508 - acc: 0.755 - ETA: 1:45 - loss: 0.5504 - acc: 0.755 - ETA: 1:44 - loss: 0.5509 - acc: 0.754 - ETA: 1:44 - loss: 0.5503 - acc: 0.755 - ETA: 1:43 - loss: 0.5495 - acc: 0.756 - ETA: 1:43 - loss: 0.5494 - acc: 0.756 - ETA: 1:42 - loss: 0.5485 - acc: 0.757 - ETA: 1:42 - loss: 0.5489 - acc: 0.757 - ETA: 1:41 - loss: 0.5481 - acc: 0.757 - ETA: 1:41 - loss: 0.5477 - acc: 0.758 - ETA: 1:40 - loss: 0.5466 - acc: 0.758 - ETA: 1:39 - loss: 0.5471 - acc: 0.758 - ETA: 1:39 - loss: 0.5458 - acc: 0.759 - ETA: 1:38 - loss: 0.5456 - acc: 0.760 - ETA: 1:38 - loss: 0.5446 - acc: 0.761 - ETA: 1:37 - loss: 0.5447 - acc: 0.760 - ETA: 1:37 - loss: 0.5445 - acc: 0.761 - ETA: 1:36 - loss: 0.5435 - acc: 0.762 - ETA: 1:36 - loss: 0.5432 - acc: 0.762 - ETA: 1:35 - loss: 0.5428 - acc: 0.762 - ETA: 1:35 - loss: 0.5433 - acc: 0.762 - ETA: 1:34 - loss: 0.5440 - acc: 0.762 - ETA: 1:34 - loss: 0.5439 - acc: 0.762 - ETA: 1:33 - loss: 0.5426 - acc: 0.762 - ETA: 1:33 - loss: 0.5427 - acc: 0.762 - ETA: 1:32 - loss: 0.5417 - acc: 0.762 - ETA: 1:32 - loss: 0.5409 - acc: 0.762 - ETA: 1:31 - loss: 0.5407 - acc: 0.762 - ETA: 1:31 - loss: 0.5395 - acc: 0.764 - ETA: 1:30 - loss: 0.5394 - acc: 0.763 - ETA: 1:30 - loss: 0.5386 - acc: 0.765 - ETA: 1:29 - loss: 0.5393 - acc: 0.764 - ETA: 1:29 - loss: 0.5391 - acc: 0.764 - ETA: 1:28 - loss: 0.5381 - acc: 0.765 - ETA: 1:28 - loss: 0.5378 - acc: 0.765 - ETA: 1:27 - loss: 0.5370 - acc: 0.766 - ETA: 1:27 - loss: 0.5368 - acc: 0.766 - ETA: 1:26 - loss: 0.5358 - acc: 0.767 - ETA: 1:26 - loss: 0.5355 - acc: 0.767 - ETA: 1:25 - loss: 0.5363 - acc: 0.766 - ETA: 1:25 - loss: 0.5363 - acc: 0.767 - ETA: 1:24 - loss: 0.5360 - acc: 0.767 - ETA: 1:24 - loss: 0.5352 - acc: 0.768 - ETA: 1:24 - loss: 0.5345 - acc: 0.769 - ETA: 1:23 - loss: 0.5338 - acc: 0.769 - ETA: 1:23 - loss: 0.5338 - acc: 0.769 - ETA: 1:22 - loss: 0.5331 - acc: 0.769 - ETA: 1:22 - loss: 0.5325 - acc: 0.770 - ETA: 1:21 - loss: 0.5321 - acc: 0.770 - ETA: 1:21 - loss: 0.5314 - acc: 0.771 - ETA: 1:21 - loss: 0.5301 - acc: 0.772 - ETA: 1:20 - loss: 0.5299 - acc: 0.772 - ETA: 1:20 - loss: 0.5290 - acc: 0.772 - ETA: 1:19 - loss: 0.5276 - acc: 0.773 - ETA: 1:19 - loss: 0.5268 - acc: 0.773 - ETA: 1:18 - loss: 0.5269 - acc: 0.773 - ETA: 1:18 - loss: 0.5263 - acc: 0.774 - ETA: 1:18 - loss: 0.5255 - acc: 0.774 - ETA: 1:17 - loss: 0.5256 - acc: 0.774 - ETA: 1:17 - loss: 0.5246 - acc: 0.775 - ETA: 1:16 - loss: 0.5244 - acc: 0.775 - ETA: 1:16 - loss: 0.5243 - acc: 0.774 - ETA: 1:15 - loss: 0.5234 - acc: 0.775 - ETA: 1:15 - loss: 0.5227 - acc: 0.775 - ETA: 1:14 - loss: 0.5235 - acc: 0.775 - ETA: 1:14 - loss: 0.5224 - acc: 0.776417/427 [============================>.] - ETA: 1:14 - loss: 0.5221 - acc: 0.776 - ETA: 1:13 - loss: 0.5213 - acc: 0.777 - ETA: 1:13 - loss: 0.5207 - acc: 0.777 - ETA: 1:12 - loss: 0.5200 - acc: 0.777 - ETA: 1:12 - loss: 0.5194 - acc: 0.778 - ETA: 1:12 - loss: 0.5192 - acc: 0.777 - ETA: 1:11 - loss: 0.5188 - acc: 0.777 - ETA: 1:11 - loss: 0.5184 - acc: 0.778 - ETA: 1:11 - loss: 0.5186 - acc: 0.778 - ETA: 1:10 - loss: 0.5173 - acc: 0.778 - ETA: 1:10 - loss: 0.5172 - acc: 0.778 - ETA: 1:09 - loss: 0.5169 - acc: 0.779 - ETA: 1:09 - loss: 0.5172 - acc: 0.778 - ETA: 1:09 - loss: 0.5169 - acc: 0.778 - ETA: 1:08 - loss: 0.5162 - acc: 0.779 - ETA: 1:08 - loss: 0.5161 - acc: 0.779 - ETA: 1:07 - loss: 0.5157 - acc: 0.779 - ETA: 1:07 - loss: 0.5155 - acc: 0.780 - ETA: 1:07 - loss: 0.5154 - acc: 0.780 - ETA: 1:06 - loss: 0.5146 - acc: 0.781 - ETA: 1:06 - loss: 0.5133 - acc: 0.782 - ETA: 1:06 - loss: 0.5123 - acc: 0.782 - ETA: 1:05 - loss: 0.5122 - acc: 0.782 - ETA: 1:05 - loss: 0.5123 - acc: 0.782 - ETA: 1:04 - loss: 0.5120 - acc: 0.782 - ETA: 1:04 - loss: 0.5120 - acc: 0.782 - ETA: 1:04 - loss: 0.5113 - acc: 0.782 - ETA: 1:03 - loss: 0.5108 - acc: 0.783 - ETA: 1:03 - loss: 0.5102 - acc: 0.783 - ETA: 1:03 - loss: 0.5096 - acc: 0.783 - ETA: 1:02 - loss: 0.5097 - acc: 0.784 - ETA: 1:02 - loss: 0.5092 - acc: 0.784 - ETA: 1:01 - loss: 0.5086 - acc: 0.785 - ETA: 1:01 - loss: 0.5088 - acc: 0.785 - ETA: 1:01 - loss: 0.5080 - acc: 0.785 - ETA: 1:00 - loss: 0.5074 - acc: 0.786 - ETA: 1:00 - loss: 0.5073 - acc: 0.786 - ETA: 59s - loss: 0.5069 - acc: 0.787 - ETA: 59s - loss: 0.5057 - acc: 0.78 - ETA: 59s - loss: 0.5057 - acc: 0.78 - ETA: 58s - loss: 0.5053 - acc: 0.78 - ETA: 58s - loss: 0.5044 - acc: 0.78 - ETA: 58s - loss: 0.5045 - acc: 0.78 - ETA: 57s - loss: 0.5041 - acc: 0.78 - ETA: 57s - loss: 0.5037 - acc: 0.78 - ETA: 56s - loss: 0.5028 - acc: 0.78 - ETA: 56s - loss: 0.5023 - acc: 0.78 - ETA: 56s - loss: 0.5022 - acc: 0.78 - ETA: 55s - loss: 0.5017 - acc: 0.78 - ETA: 55s - loss: 0.5011 - acc: 0.79 - ETA: 55s - loss: 0.5009 - acc: 0.79 - ETA: 54s - loss: 0.5001 - acc: 0.79 - ETA: 54s - loss: 0.5000 - acc: 0.79 - ETA: 54s - loss: 0.5003 - acc: 0.79 - ETA: 53s - loss: 0.5005 - acc: 0.79 - ETA: 53s - loss: 0.5003 - acc: 0.79 - ETA: 52s - loss: 0.4997 - acc: 0.79 - ETA: 52s - loss: 0.4993 - acc: 0.79 - ETA: 52s - loss: 0.4996 - acc: 0.79 - ETA: 51s - loss: 0.4991 - acc: 0.79 - ETA: 51s - loss: 0.4983 - acc: 0.79 - ETA: 51s - loss: 0.4981 - acc: 0.79 - ETA: 50s - loss: 0.4975 - acc: 0.79 - ETA: 50s - loss: 0.4973 - acc: 0.79 - ETA: 50s - loss: 0.4967 - acc: 0.79 - ETA: 49s - loss: 0.4957 - acc: 0.79 - ETA: 49s - loss: 0.4946 - acc: 0.79 - ETA: 49s - loss: 0.4945 - acc: 0.79 - ETA: 48s - loss: 0.4940 - acc: 0.79 - ETA: 48s - loss: 0.4940 - acc: 0.79 - ETA: 48s - loss: 0.4938 - acc: 0.79 - ETA: 47s - loss: 0.4933 - acc: 0.79 - ETA: 47s - loss: 0.4924 - acc: 0.79 - ETA: 47s - loss: 0.4923 - acc: 0.79 - ETA: 46s - loss: 0.4920 - acc: 0.79 - ETA: 46s - loss: 0.4918 - acc: 0.79 - ETA: 46s - loss: 0.4921 - acc: 0.79 - ETA: 45s - loss: 0.4915 - acc: 0.79 - ETA: 45s - loss: 0.4909 - acc: 0.79 - ETA: 45s - loss: 0.4904 - acc: 0.79 - ETA: 44s - loss: 0.4903 - acc: 0.79 - ETA: 44s - loss: 0.4906 - acc: 0.79 - ETA: 44s - loss: 0.4898 - acc: 0.79 - ETA: 43s - loss: 0.4896 - acc: 0.79 - ETA: 43s - loss: 0.4890 - acc: 0.79 - ETA: 43s - loss: 0.4881 - acc: 0.79 - ETA: 42s - loss: 0.4881 - acc: 0.79 - ETA: 42s - loss: 0.4877 - acc: 0.79 - ETA: 41s - loss: 0.4871 - acc: 0.79 - ETA: 41s - loss: 0.4868 - acc: 0.79 - ETA: 41s - loss: 0.4864 - acc: 0.79 - ETA: 40s - loss: 0.4864 - acc: 0.79 - ETA: 40s - loss: 0.4859 - acc: 0.79 - ETA: 40s - loss: 0.4853 - acc: 0.79 - ETA: 39s - loss: 0.4851 - acc: 0.79 - ETA: 39s - loss: 0.4845 - acc: 0.79 - ETA: 39s - loss: 0.4844 - acc: 0.79 - ETA: 38s - loss: 0.4839 - acc: 0.79 - ETA: 38s - loss: 0.4838 - acc: 0.79 - ETA: 38s - loss: 0.4838 - acc: 0.79 - ETA: 37s - loss: 0.4837 - acc: 0.80 - ETA: 37s - loss: 0.4834 - acc: 0.80 - ETA: 37s - loss: 0.4835 - acc: 0.80 - ETA: 36s - loss: 0.4832 - acc: 0.80 - ETA: 36s - loss: 0.4823 - acc: 0.80 - ETA: 36s - loss: 0.4815 - acc: 0.80 - ETA: 35s - loss: 0.4809 - acc: 0.80 - ETA: 35s - loss: 0.4803 - acc: 0.80 - ETA: 35s - loss: 0.4800 - acc: 0.80 - ETA: 34s - loss: 0.4803 - acc: 0.80 - ETA: 34s - loss: 0.4803 - acc: 0.80 - ETA: 34s - loss: 0.4802 - acc: 0.80 - ETA: 33s - loss: 0.4804 - acc: 0.80 - ETA: 33s - loss: 0.4796 - acc: 0.80 - ETA: 33s - loss: 0.4796 - acc: 0.80 - ETA: 33s - loss: 0.4793 - acc: 0.80 - ETA: 32s - loss: 0.4790 - acc: 0.80 - ETA: 32s - loss: 0.4792 - acc: 0.80 - ETA: 32s - loss: 0.4790 - acc: 0.80 - ETA: 31s - loss: 0.4783 - acc: 0.80 - ETA: 31s - loss: 0.4776 - acc: 0.80 - ETA: 31s - loss: 0.4770 - acc: 0.80 - ETA: 30s - loss: 0.4767 - acc: 0.80 - ETA: 30s - loss: 0.4769 - acc: 0.80 - ETA: 30s - loss: 0.4768 - acc: 0.80 - ETA: 29s - loss: 0.4762 - acc: 0.80 - ETA: 29s - loss: 0.4759 - acc: 0.80 - ETA: 29s - loss: 0.4759 - acc: 0.80 - ETA: 28s - loss: 0.4752 - acc: 0.80 - ETA: 28s - loss: 0.4748 - acc: 0.80 - ETA: 28s - loss: 0.4744 - acc: 0.80 - ETA: 27s - loss: 0.4744 - acc: 0.80 - ETA: 27s - loss: 0.4744 - acc: 0.80 - ETA: 27s - loss: 0.4745 - acc: 0.80 - ETA: 26s - loss: 0.4738 - acc: 0.80 - ETA: 26s - loss: 0.4731 - acc: 0.80 - ETA: 26s - loss: 0.4729 - acc: 0.80 - ETA: 26s - loss: 0.4724 - acc: 0.80 - ETA: 25s - loss: 0.4721 - acc: 0.80 - ETA: 25s - loss: 0.4722 - acc: 0.80 - ETA: 25s - loss: 0.4721 - acc: 0.80 - ETA: 24s - loss: 0.4715 - acc: 0.80 - ETA: 24s - loss: 0.4718 - acc: 0.80 - ETA: 24s - loss: 0.4719 - acc: 0.80 - ETA: 23s - loss: 0.4716 - acc: 0.80 - ETA: 23s - loss: 0.4711 - acc: 0.80 - ETA: 23s - loss: 0.4711 - acc: 0.80 - ETA: 22s - loss: 0.4712 - acc: 0.80 - ETA: 22s - loss: 0.4706 - acc: 0.80 - ETA: 22s - loss: 0.4704 - acc: 0.80 - ETA: 21s - loss: 0.4697 - acc: 0.80 - ETA: 21s - loss: 0.4692 - acc: 0.80 - ETA: 21s - loss: 0.4694 - acc: 0.80 - ETA: 20s - loss: 0.4690 - acc: 0.80 - ETA: 20s - loss: 0.4686 - acc: 0.80 - ETA: 20s - loss: 0.4690 - acc: 0.80 - ETA: 20s - loss: 0.4691 - acc: 0.80 - ETA: 19s - loss: 0.4686 - acc: 0.80 - ETA: 19s - loss: 0.4684 - acc: 0.80 - ETA: 19s - loss: 0.4683 - acc: 0.80 - ETA: 18s - loss: 0.4684 - acc: 0.80 - ETA: 18s - loss: 0.4680 - acc: 0.80 - ETA: 18s - loss: 0.4680 - acc: 0.80 - ETA: 17s - loss: 0.4673 - acc: 0.80 - ETA: 17s - loss: 0.4669 - acc: 0.80 - ETA: 17s - loss: 0.4663 - acc: 0.80 - ETA: 16s - loss: 0.4661 - acc: 0.80 - ETA: 16s - loss: 0.4661 - acc: 0.80 - ETA: 16s - loss: 0.4659 - acc: 0.80 - ETA: 16s - loss: 0.4654 - acc: 0.81 - ETA: 15s - loss: 0.4653 - acc: 0.81 - ETA: 15s - loss: 0.4656 - acc: 0.81 - ETA: 15s - loss: 0.4661 - acc: 0.80 - ETA: 14s - loss: 0.4660 - acc: 0.81 - ETA: 14s - loss: 0.4659 - acc: 0.81 - ETA: 14s - loss: 0.4654 - acc: 0.81 - ETA: 13s - loss: 0.4651 - acc: 0.81 - ETA: 13s - loss: 0.4647 - acc: 0.81 - ETA: 13s - loss: 0.4644 - acc: 0.81 - ETA: 12s - loss: 0.4642 - acc: 0.81 - ETA: 12s - loss: 0.4643 - acc: 0.81 - ETA: 12s - loss: 0.4636 - acc: 0.81 - ETA: 12s - loss: 0.4631 - acc: 0.81 - ETA: 11s - loss: 0.4632 - acc: 0.81 - ETA: 11s - loss: 0.4630 - acc: 0.81 - ETA: 11s - loss: 0.4629 - acc: 0.81 - ETA: 10s - loss: 0.4622 - acc: 0.81 - ETA: 10s - loss: 0.4619 - acc: 0.81 - ETA: 10s - loss: 0.4614 - acc: 0.81 - ETA: 9s - loss: 0.4610 - acc: 0.8127 - ETA: 9s - loss: 0.4606 - acc: 0.812 - ETA: 9s - loss: 0.4602 - acc: 0.812 - ETA: 9s - loss: 0.4595 - acc: 0.813 - ETA: 8s - loss: 0.4591 - acc: 0.813 - ETA: 8s - loss: 0.4594 - acc: 0.812 - ETA: 8s - loss: 0.4592 - acc: 0.812 - ETA: 7s - loss: 0.4593 - acc: 0.812 - ETA: 7s - loss: 0.4591 - acc: 0.812 - ETA: 7s - loss: 0.4586 - acc: 0.812 - ETA: 6s - loss: 0.4584 - acc: 0.812 - ETA: 6s - loss: 0.4583 - acc: 0.813 - ETA: 6s - loss: 0.4579 - acc: 0.813 - ETA: 6s - loss: 0.4576 - acc: 0.813 - ETA: 5s - loss: 0.4573 - acc: 0.813 - ETA: 5s - loss: 0.4569 - acc: 0.813 - ETA: 5s - loss: 0.4570 - acc: 0.813 - ETA: 4s - loss: 0.4566 - acc: 0.813 - ETA: 4s - loss: 0.4564 - acc: 0.813 - ETA: 4s - loss: 0.4560 - acc: 0.813 - ETA: 3s - loss: 0.4558 - acc: 0.813 - ETA: 3s - loss: 0.4554 - acc: 0.814 - ETA: 3s - loss: 0.4549 - acc: 0.814 - ETA: 2s - loss: 0.4547 - acc: 0.8145426/427 [============================>.] - ETA: 2s - loss: 0.4541 - acc: 0.815 - ETA: 2s - loss: 0.4535 - acc: 0.815 - ETA: 2s - loss: 0.4532 - acc: 0.815 - ETA: 1s - loss: 0.4530 - acc: 0.815 - ETA: 1s - loss: 0.4524 - acc: 0.815 - ETA: 1s - loss: 0.4524 - acc: 0.815 - ETA: 0s - loss: 0.4525 - acc: 0.815 - ETA: 0s - loss: 0.4518 - acc: 0.816 - ETA: 0s - loss: 0.4514 - acc: 0.8165\n",
      "Epoch 00001: val_loss improved from inf to 0.44760, saving model to saved_models/weights.aug.best.hdf5\n",
      "427/427 [==============================] - 134s 315ms/step - loss: 0.4522 - acc: 0.8161 - val_loss: 0.4476 - val_acc: 0.8462\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/427 [=============>................] - ETA: 7:36 - loss: 0.2591 - acc: 0.950 - ETA: 6:31 - loss: 0.3383 - acc: 0.875 - ETA: 5:54 - loss: 0.3611 - acc: 0.850 - ETA: 5:26 - loss: 0.3382 - acc: 0.875 - ETA: 4:58 - loss: 0.3334 - acc: 0.870 - ETA: 4:41 - loss: 0.3157 - acc: 0.883 - ETA: 4:32 - loss: 0.3134 - acc: 0.871 - ETA: 4:19 - loss: 0.3254 - acc: 0.868 - ETA: 4:07 - loss: 0.3300 - acc: 0.861 - ETA: 3:52 - loss: 0.3389 - acc: 0.860 - ETA: 3:41 - loss: 0.3504 - acc: 0.854 - ETA: 3:31 - loss: 0.3518 - acc: 0.850 - ETA: 3:24 - loss: 0.3467 - acc: 0.857 - ETA: 3:17 - loss: 0.3556 - acc: 0.857 - ETA: 3:10 - loss: 0.3496 - acc: 0.860 - ETA: 3:04 - loss: 0.3472 - acc: 0.859 - ETA: 2:59 - loss: 0.3469 - acc: 0.858 - ETA: 2:51 - loss: 0.3520 - acc: 0.858 - ETA: 2:47 - loss: 0.3554 - acc: 0.858 - ETA: 2:43 - loss: 0.3518 - acc: 0.860 - ETA: 2:43 - loss: 0.3515 - acc: 0.859 - ETA: 2:43 - loss: 0.3569 - acc: 0.854 - ETA: 2:42 - loss: 0.3577 - acc: 0.854 - ETA: 2:42 - loss: 0.3633 - acc: 0.854 - ETA: 2:41 - loss: 0.3611 - acc: 0.858 - ETA: 2:41 - loss: 0.3567 - acc: 0.859 - ETA: 2:39 - loss: 0.3567 - acc: 0.859 - ETA: 2:38 - loss: 0.3611 - acc: 0.855 - ETA: 2:36 - loss: 0.3689 - acc: 0.852 - ETA: 2:34 - loss: 0.3710 - acc: 0.853 - ETA: 2:32 - loss: 0.3676 - acc: 0.856 - ETA: 2:30 - loss: 0.3602 - acc: 0.859 - ETA: 2:30 - loss: 0.3653 - acc: 0.857 - ETA: 2:30 - loss: 0.3675 - acc: 0.859 - ETA: 2:30 - loss: 0.3611 - acc: 0.861 - ETA: 2:29 - loss: 0.3615 - acc: 0.859 - ETA: 2:27 - loss: 0.3562 - acc: 0.863 - ETA: 2:26 - loss: 0.3547 - acc: 0.866 - ETA: 2:25 - loss: 0.3586 - acc: 0.861 - ETA: 2:24 - loss: 0.3572 - acc: 0.861 - ETA: 2:22 - loss: 0.3599 - acc: 0.858 - ETA: 2:21 - loss: 0.3550 - acc: 0.860 - ETA: 2:20 - loss: 0.3597 - acc: 0.858 - ETA: 2:19 - loss: 0.3590 - acc: 0.859 - ETA: 2:19 - loss: 0.3617 - acc: 0.859 - ETA: 2:18 - loss: 0.3635 - acc: 0.857 - ETA: 2:18 - loss: 0.3620 - acc: 0.858 - ETA: 2:17 - loss: 0.3617 - acc: 0.858 - ETA: 2:17 - loss: 0.3596 - acc: 0.859 - ETA: 2:16 - loss: 0.3570 - acc: 0.861 - ETA: 2:15 - loss: 0.3635 - acc: 0.857 - ETA: 2:15 - loss: 0.3608 - acc: 0.858 - ETA: 2:14 - loss: 0.3621 - acc: 0.858 - ETA: 2:13 - loss: 0.3627 - acc: 0.857 - ETA: 2:12 - loss: 0.3639 - acc: 0.857 - ETA: 2:11 - loss: 0.3611 - acc: 0.859 - ETA: 2:09 - loss: 0.3605 - acc: 0.861 - ETA: 2:09 - loss: 0.3593 - acc: 0.861 - ETA: 2:08 - loss: 0.3581 - acc: 0.861 - ETA: 2:07 - loss: 0.3611 - acc: 0.859 - ETA: 2:06 - loss: 0.3615 - acc: 0.860 - ETA: 2:05 - loss: 0.3604 - acc: 0.859 - ETA: 2:04 - loss: 0.3611 - acc: 0.859 - ETA: 2:04 - loss: 0.3595 - acc: 0.861 - ETA: 2:03 - loss: 0.3576 - acc: 0.862 - ETA: 2:02 - loss: 0.3581 - acc: 0.860 - ETA: 2:01 - loss: 0.3599 - acc: 0.860 - ETA: 2:01 - loss: 0.3571 - acc: 0.861 - ETA: 2:00 - loss: 0.3577 - acc: 0.861 - ETA: 2:00 - loss: 0.3583 - acc: 0.860 - ETA: 1:59 - loss: 0.3560 - acc: 0.862 - ETA: 1:58 - loss: 0.3544 - acc: 0.862 - ETA: 1:58 - loss: 0.3523 - acc: 0.863 - ETA: 1:57 - loss: 0.3515 - acc: 0.864 - ETA: 1:55 - loss: 0.3539 - acc: 0.858 - ETA: 1:55 - loss: 0.3586 - acc: 0.855 - ETA: 1:54 - loss: 0.3570 - acc: 0.856 - ETA: 1:53 - loss: 0.3562 - acc: 0.855 - ETA: 1:53 - loss: 0.3555 - acc: 0.856 - ETA: 1:52 - loss: 0.3545 - acc: 0.856 - ETA: 1:51 - loss: 0.3525 - acc: 0.857 - ETA: 1:51 - loss: 0.3518 - acc: 0.858 - ETA: 1:50 - loss: 0.3503 - acc: 0.858 - ETA: 1:49 - loss: 0.3518 - acc: 0.857 - ETA: 1:48 - loss: 0.3521 - acc: 0.856 - ETA: 1:48 - loss: 0.3510 - acc: 0.858 - ETA: 1:47 - loss: 0.3520 - acc: 0.856 - ETA: 1:47 - loss: 0.3507 - acc: 0.857 - ETA: 1:46 - loss: 0.3509 - acc: 0.857 - ETA: 1:46 - loss: 0.3506 - acc: 0.858 - ETA: 1:45 - loss: 0.3502 - acc: 0.859 - ETA: 1:45 - loss: 0.3507 - acc: 0.859 - ETA: 1:44 - loss: 0.3508 - acc: 0.860 - ETA: 1:44 - loss: 0.3524 - acc: 0.860 - ETA: 1:43 - loss: 0.3552 - acc: 0.859 - ETA: 1:43 - loss: 0.3554 - acc: 0.858 - ETA: 1:43 - loss: 0.3567 - acc: 0.856 - ETA: 1:43 - loss: 0.3576 - acc: 0.856 - ETA: 1:42 - loss: 0.3591 - acc: 0.856 - ETA: 1:42 - loss: 0.3609 - acc: 0.853 - ETA: 1:41 - loss: 0.3617 - acc: 0.853 - ETA: 1:41 - loss: 0.3611 - acc: 0.853 - ETA: 1:41 - loss: 0.3615 - acc: 0.854 - ETA: 1:40 - loss: 0.3614 - acc: 0.853 - ETA: 1:40 - loss: 0.3623 - acc: 0.852 - ETA: 1:40 - loss: 0.3627 - acc: 0.852 - ETA: 1:39 - loss: 0.3628 - acc: 0.852 - ETA: 1:39 - loss: 0.3625 - acc: 0.852 - ETA: 1:39 - loss: 0.3610 - acc: 0.852 - ETA: 1:38 - loss: 0.3612 - acc: 0.854 - ETA: 1:37 - loss: 0.3617 - acc: 0.854 - ETA: 1:37 - loss: 0.3622 - acc: 0.853 - ETA: 1:36 - loss: 0.3620 - acc: 0.853 - ETA: 1:36 - loss: 0.3619 - acc: 0.854 - ETA: 1:36 - loss: 0.3625 - acc: 0.854 - ETA: 1:35 - loss: 0.3615 - acc: 0.854 - ETA: 1:35 - loss: 0.3613 - acc: 0.854 - ETA: 1:35 - loss: 0.3606 - acc: 0.854 - ETA: 1:34 - loss: 0.3606 - acc: 0.854 - ETA: 1:34 - loss: 0.3598 - acc: 0.854 - ETA: 1:33 - loss: 0.3587 - acc: 0.855 - ETA: 1:33 - loss: 0.3578 - acc: 0.855 - ETA: 1:33 - loss: 0.3563 - acc: 0.856 - ETA: 1:32 - loss: 0.3566 - acc: 0.856 - ETA: 1:32 - loss: 0.3567 - acc: 0.855 - ETA: 1:31 - loss: 0.3579 - acc: 0.854 - ETA: 1:31 - loss: 0.3572 - acc: 0.855 - ETA: 1:31 - loss: 0.3559 - acc: 0.856 - ETA: 1:30 - loss: 0.3562 - acc: 0.855 - ETA: 1:30 - loss: 0.3542 - acc: 0.856 - ETA: 1:30 - loss: 0.3539 - acc: 0.856 - ETA: 1:29 - loss: 0.3551 - acc: 0.855 - ETA: 1:29 - loss: 0.3549 - acc: 0.855 - ETA: 1:28 - loss: 0.3551 - acc: 0.855 - ETA: 1:28 - loss: 0.3538 - acc: 0.856 - ETA: 1:27 - loss: 0.3532 - acc: 0.856 - ETA: 1:27 - loss: 0.3551 - acc: 0.855 - ETA: 1:26 - loss: 0.3559 - acc: 0.855 - ETA: 1:26 - loss: 0.3561 - acc: 0.855 - ETA: 1:26 - loss: 0.3562 - acc: 0.854 - ETA: 1:25 - loss: 0.3559 - acc: 0.854 - ETA: 1:25 - loss: 0.3559 - acc: 0.855 - ETA: 1:25 - loss: 0.3546 - acc: 0.856 - ETA: 1:24 - loss: 0.3553 - acc: 0.855 - ETA: 1:24 - loss: 0.3542 - acc: 0.856 - ETA: 1:23 - loss: 0.3533 - acc: 0.856 - ETA: 1:23 - loss: 0.3534 - acc: 0.856 - ETA: 1:23 - loss: 0.3521 - acc: 0.857 - ETA: 1:22 - loss: 0.3526 - acc: 0.857 - ETA: 1:22 - loss: 0.3533 - acc: 0.857 - ETA: 1:22 - loss: 0.3537 - acc: 0.856 - ETA: 1:21 - loss: 0.3526 - acc: 0.857 - ETA: 1:21 - loss: 0.3529 - acc: 0.856 - ETA: 1:21 - loss: 0.3541 - acc: 0.856 - ETA: 1:20 - loss: 0.3533 - acc: 0.856 - ETA: 1:20 - loss: 0.3536 - acc: 0.856 - ETA: 1:20 - loss: 0.3539 - acc: 0.856 - ETA: 1:19 - loss: 0.3528 - acc: 0.857 - ETA: 1:19 - loss: 0.3524 - acc: 0.857 - ETA: 1:18 - loss: 0.3520 - acc: 0.858 - ETA: 1:18 - loss: 0.3517 - acc: 0.858 - ETA: 1:18 - loss: 0.3514 - acc: 0.858 - ETA: 1:17 - loss: 0.3519 - acc: 0.858 - ETA: 1:17 - loss: 0.3511 - acc: 0.859 - ETA: 1:17 - loss: 0.3508 - acc: 0.859 - ETA: 1:16 - loss: 0.3503 - acc: 0.859 - ETA: 1:16 - loss: 0.3494 - acc: 0.860 - ETA: 1:16 - loss: 0.3488 - acc: 0.860 - ETA: 1:15 - loss: 0.3489 - acc: 0.860 - ETA: 1:15 - loss: 0.3501 - acc: 0.859 - ETA: 1:15 - loss: 0.3499 - acc: 0.859 - ETA: 1:14 - loss: 0.3498 - acc: 0.859 - ETA: 1:14 - loss: 0.3499 - acc: 0.860 - ETA: 1:14 - loss: 0.3498 - acc: 0.860 - ETA: 1:13 - loss: 0.3501 - acc: 0.860 - ETA: 1:13 - loss: 0.3494 - acc: 0.859 - ETA: 1:13 - loss: 0.3491 - acc: 0.860 - ETA: 1:12 - loss: 0.3480 - acc: 0.860 - ETA: 1:12 - loss: 0.3476 - acc: 0.861 - ETA: 1:12 - loss: 0.3479 - acc: 0.860 - ETA: 1:11 - loss: 0.3482 - acc: 0.860 - ETA: 1:11 - loss: 0.3479 - acc: 0.861 - ETA: 1:11 - loss: 0.3487 - acc: 0.860 - ETA: 1:10 - loss: 0.3499 - acc: 0.860 - ETA: 1:10 - loss: 0.3500 - acc: 0.860 - ETA: 1:10 - loss: 0.3502 - acc: 0.860 - ETA: 1:09 - loss: 0.3493 - acc: 0.861 - ETA: 1:09 - loss: 0.3491 - acc: 0.861 - ETA: 1:09 - loss: 0.3484 - acc: 0.862 - ETA: 1:09 - loss: 0.3477 - acc: 0.862 - ETA: 1:08 - loss: 0.3475 - acc: 0.863 - ETA: 1:08 - loss: 0.3466 - acc: 0.863 - ETA: 1:08 - loss: 0.3461 - acc: 0.864 - ETA: 1:07 - loss: 0.3459 - acc: 0.863 - ETA: 1:07 - loss: 0.3455 - acc: 0.864 - ETA: 1:07 - loss: 0.3458 - acc: 0.864 - ETA: 1:06 - loss: 0.3462 - acc: 0.864 - ETA: 1:06 - loss: 0.3460 - acc: 0.863 - ETA: 1:06 - loss: 0.3465 - acc: 0.864 - ETA: 1:05 - loss: 0.3456 - acc: 0.864 - ETA: 1:05 - loss: 0.3457 - acc: 0.864 - ETA: 1:05 - loss: 0.3449 - acc: 0.864 - ETA: 1:04 - loss: 0.3447 - acc: 0.864 - ETA: 1:04 - loss: 0.3446 - acc: 0.8647418/427 [============================>.] - ETA: 1:04 - loss: 0.3454 - acc: 0.864 - ETA: 1:03 - loss: 0.3454 - acc: 0.864 - ETA: 1:03 - loss: 0.3453 - acc: 0.864 - ETA: 1:03 - loss: 0.3453 - acc: 0.864 - ETA: 1:03 - loss: 0.3455 - acc: 0.864 - ETA: 1:02 - loss: 0.3452 - acc: 0.864 - ETA: 1:02 - loss: 0.3451 - acc: 0.864 - ETA: 1:02 - loss: 0.3449 - acc: 0.865 - ETA: 1:01 - loss: 0.3455 - acc: 0.865 - ETA: 1:01 - loss: 0.3457 - acc: 0.865 - ETA: 1:01 - loss: 0.3462 - acc: 0.864 - ETA: 1:01 - loss: 0.3457 - acc: 0.865 - ETA: 1:00 - loss: 0.3456 - acc: 0.865 - ETA: 1:00 - loss: 0.3461 - acc: 0.865 - ETA: 1:00 - loss: 0.3459 - acc: 0.865 - ETA: 59s - loss: 0.3456 - acc: 0.865 - ETA: 59s - loss: 0.3452 - acc: 0.86 - ETA: 59s - loss: 0.3451 - acc: 0.86 - ETA: 58s - loss: 0.3449 - acc: 0.86 - ETA: 58s - loss: 0.3447 - acc: 0.86 - ETA: 58s - loss: 0.3451 - acc: 0.86 - ETA: 58s - loss: 0.3445 - acc: 0.86 - ETA: 57s - loss: 0.3448 - acc: 0.86 - ETA: 57s - loss: 0.3438 - acc: 0.86 - ETA: 56s - loss: 0.3437 - acc: 0.86 - ETA: 56s - loss: 0.3437 - acc: 0.86 - ETA: 56s - loss: 0.3445 - acc: 0.86 - ETA: 56s - loss: 0.3444 - acc: 0.86 - ETA: 55s - loss: 0.3437 - acc: 0.86 - ETA: 55s - loss: 0.3446 - acc: 0.86 - ETA: 55s - loss: 0.3445 - acc: 0.86 - ETA: 55s - loss: 0.3439 - acc: 0.86 - ETA: 54s - loss: 0.3435 - acc: 0.86 - ETA: 54s - loss: 0.3431 - acc: 0.86 - ETA: 54s - loss: 0.3426 - acc: 0.86 - ETA: 53s - loss: 0.3416 - acc: 0.86 - ETA: 53s - loss: 0.3411 - acc: 0.86 - ETA: 53s - loss: 0.3405 - acc: 0.86 - ETA: 52s - loss: 0.3407 - acc: 0.86 - ETA: 52s - loss: 0.3410 - acc: 0.86 - ETA: 52s - loss: 0.3411 - acc: 0.86 - ETA: 51s - loss: 0.3406 - acc: 0.86 - ETA: 51s - loss: 0.3398 - acc: 0.86 - ETA: 51s - loss: 0.3393 - acc: 0.86 - ETA: 50s - loss: 0.3389 - acc: 0.86 - ETA: 50s - loss: 0.3382 - acc: 0.86 - ETA: 50s - loss: 0.3385 - acc: 0.86 - ETA: 49s - loss: 0.3382 - acc: 0.86 - ETA: 49s - loss: 0.3383 - acc: 0.86 - ETA: 49s - loss: 0.3383 - acc: 0.86 - ETA: 48s - loss: 0.3389 - acc: 0.86 - ETA: 48s - loss: 0.3391 - acc: 0.86 - ETA: 48s - loss: 0.3386 - acc: 0.86 - ETA: 47s - loss: 0.3390 - acc: 0.86 - ETA: 47s - loss: 0.3387 - acc: 0.86 - ETA: 47s - loss: 0.3385 - acc: 0.86 - ETA: 47s - loss: 0.3377 - acc: 0.86 - ETA: 46s - loss: 0.3376 - acc: 0.86 - ETA: 46s - loss: 0.3383 - acc: 0.86 - ETA: 46s - loss: 0.3376 - acc: 0.86 - ETA: 45s - loss: 0.3385 - acc: 0.86 - ETA: 45s - loss: 0.3393 - acc: 0.86 - ETA: 45s - loss: 0.3387 - acc: 0.86 - ETA: 44s - loss: 0.3386 - acc: 0.86 - ETA: 44s - loss: 0.3384 - acc: 0.86 - ETA: 44s - loss: 0.3383 - acc: 0.86 - ETA: 44s - loss: 0.3376 - acc: 0.86 - ETA: 43s - loss: 0.3384 - acc: 0.86 - ETA: 43s - loss: 0.3381 - acc: 0.86 - ETA: 43s - loss: 0.3382 - acc: 0.86 - ETA: 42s - loss: 0.3376 - acc: 0.86 - ETA: 42s - loss: 0.3369 - acc: 0.87 - ETA: 42s - loss: 0.3363 - acc: 0.87 - ETA: 42s - loss: 0.3357 - acc: 0.87 - ETA: 41s - loss: 0.3360 - acc: 0.87 - ETA: 41s - loss: 0.3352 - acc: 0.87 - ETA: 41s - loss: 0.3355 - acc: 0.87 - ETA: 41s - loss: 0.3351 - acc: 0.87 - ETA: 40s - loss: 0.3354 - acc: 0.87 - ETA: 40s - loss: 0.3352 - acc: 0.87 - ETA: 40s - loss: 0.3354 - acc: 0.87 - ETA: 39s - loss: 0.3359 - acc: 0.87 - ETA: 39s - loss: 0.3359 - acc: 0.87 - ETA: 39s - loss: 0.3364 - acc: 0.87 - ETA: 39s - loss: 0.3367 - acc: 0.87 - ETA: 38s - loss: 0.3365 - acc: 0.87 - ETA: 38s - loss: 0.3366 - acc: 0.87 - ETA: 38s - loss: 0.3368 - acc: 0.87 - ETA: 37s - loss: 0.3363 - acc: 0.87 - ETA: 37s - loss: 0.3366 - acc: 0.87 - ETA: 37s - loss: 0.3364 - acc: 0.87 - ETA: 36s - loss: 0.3362 - acc: 0.87 - ETA: 36s - loss: 0.3361 - acc: 0.87 - ETA: 36s - loss: 0.3358 - acc: 0.87 - ETA: 36s - loss: 0.3369 - acc: 0.87 - ETA: 35s - loss: 0.3371 - acc: 0.87 - ETA: 35s - loss: 0.3366 - acc: 0.87 - ETA: 35s - loss: 0.3365 - acc: 0.87 - ETA: 34s - loss: 0.3366 - acc: 0.87 - ETA: 34s - loss: 0.3376 - acc: 0.86 - ETA: 34s - loss: 0.3369 - acc: 0.86 - ETA: 34s - loss: 0.3365 - acc: 0.87 - ETA: 33s - loss: 0.3365 - acc: 0.87 - ETA: 33s - loss: 0.3363 - acc: 0.87 - ETA: 33s - loss: 0.3370 - acc: 0.86 - ETA: 32s - loss: 0.3366 - acc: 0.87 - ETA: 32s - loss: 0.3367 - acc: 0.87 - ETA: 32s - loss: 0.3363 - acc: 0.87 - ETA: 32s - loss: 0.3357 - acc: 0.87 - ETA: 31s - loss: 0.3357 - acc: 0.87 - ETA: 31s - loss: 0.3355 - acc: 0.87 - ETA: 31s - loss: 0.3357 - acc: 0.87 - ETA: 30s - loss: 0.3355 - acc: 0.87 - ETA: 30s - loss: 0.3360 - acc: 0.87 - ETA: 30s - loss: 0.3354 - acc: 0.87 - ETA: 30s - loss: 0.3353 - acc: 0.87 - ETA: 29s - loss: 0.3357 - acc: 0.87 - ETA: 29s - loss: 0.3352 - acc: 0.87 - ETA: 29s - loss: 0.3352 - acc: 0.87 - ETA: 28s - loss: 0.3356 - acc: 0.87 - ETA: 28s - loss: 0.3358 - acc: 0.87 - ETA: 28s - loss: 0.3366 - acc: 0.87 - ETA: 28s - loss: 0.3369 - acc: 0.86 - ETA: 27s - loss: 0.3367 - acc: 0.86 - ETA: 27s - loss: 0.3364 - acc: 0.87 - ETA: 27s - loss: 0.3366 - acc: 0.87 - ETA: 26s - loss: 0.3366 - acc: 0.86 - ETA: 26s - loss: 0.3365 - acc: 0.87 - ETA: 26s - loss: 0.3369 - acc: 0.86 - ETA: 26s - loss: 0.3364 - acc: 0.87 - ETA: 25s - loss: 0.3362 - acc: 0.87 - ETA: 25s - loss: 0.3358 - acc: 0.87 - ETA: 25s - loss: 0.3356 - acc: 0.87 - ETA: 24s - loss: 0.3356 - acc: 0.87 - ETA: 24s - loss: 0.3353 - acc: 0.87 - ETA: 24s - loss: 0.3350 - acc: 0.87 - ETA: 24s - loss: 0.3348 - acc: 0.87 - ETA: 23s - loss: 0.3343 - acc: 0.87 - ETA: 23s - loss: 0.3341 - acc: 0.87 - ETA: 23s - loss: 0.3338 - acc: 0.87 - ETA: 22s - loss: 0.3332 - acc: 0.87 - ETA: 22s - loss: 0.3336 - acc: 0.87 - ETA: 22s - loss: 0.3333 - acc: 0.87 - ETA: 22s - loss: 0.3334 - acc: 0.87 - ETA: 21s - loss: 0.3334 - acc: 0.87 - ETA: 21s - loss: 0.3330 - acc: 0.87 - ETA: 21s - loss: 0.3333 - acc: 0.87 - ETA: 20s - loss: 0.3333 - acc: 0.87 - ETA: 20s - loss: 0.3336 - acc: 0.87 - ETA: 20s - loss: 0.3347 - acc: 0.87 - ETA: 20s - loss: 0.3343 - acc: 0.87 - ETA: 19s - loss: 0.3346 - acc: 0.87 - ETA: 19s - loss: 0.3344 - acc: 0.87 - ETA: 19s - loss: 0.3339 - acc: 0.87 - ETA: 18s - loss: 0.3341 - acc: 0.87 - ETA: 18s - loss: 0.3338 - acc: 0.87 - ETA: 18s - loss: 0.3337 - acc: 0.87 - ETA: 18s - loss: 0.3345 - acc: 0.87 - ETA: 17s - loss: 0.3351 - acc: 0.87 - ETA: 17s - loss: 0.3350 - acc: 0.87 - ETA: 17s - loss: 0.3356 - acc: 0.87 - ETA: 17s - loss: 0.3354 - acc: 0.87 - ETA: 16s - loss: 0.3354 - acc: 0.87 - ETA: 16s - loss: 0.3360 - acc: 0.87 - ETA: 16s - loss: 0.3359 - acc: 0.87 - ETA: 15s - loss: 0.3366 - acc: 0.87 - ETA: 15s - loss: 0.3368 - acc: 0.87 - ETA: 15s - loss: 0.3365 - acc: 0.87 - ETA: 14s - loss: 0.3364 - acc: 0.87 - ETA: 14s - loss: 0.3358 - acc: 0.87 - ETA: 14s - loss: 0.3358 - acc: 0.87 - ETA: 14s - loss: 0.3361 - acc: 0.87 - ETA: 13s - loss: 0.3361 - acc: 0.87 - ETA: 13s - loss: 0.3358 - acc: 0.87 - ETA: 13s - loss: 0.3357 - acc: 0.87 - ETA: 13s - loss: 0.3355 - acc: 0.87 - ETA: 12s - loss: 0.3351 - acc: 0.87 - ETA: 12s - loss: 0.3350 - acc: 0.87 - ETA: 12s - loss: 0.3347 - acc: 0.87 - ETA: 11s - loss: 0.3346 - acc: 0.87 - ETA: 11s - loss: 0.3347 - acc: 0.87 - ETA: 11s - loss: 0.3349 - acc: 0.87 - ETA: 11s - loss: 0.3348 - acc: 0.87 - ETA: 10s - loss: 0.3351 - acc: 0.87 - ETA: 10s - loss: 0.3348 - acc: 0.87 - ETA: 10s - loss: 0.3347 - acc: 0.87 - ETA: 9s - loss: 0.3349 - acc: 0.8716 - ETA: 9s - loss: 0.3349 - acc: 0.871 - ETA: 9s - loss: 0.3350 - acc: 0.871 - ETA: 9s - loss: 0.3346 - acc: 0.871 - ETA: 8s - loss: 0.3347 - acc: 0.871 - ETA: 8s - loss: 0.3345 - acc: 0.871 - ETA: 8s - loss: 0.3356 - acc: 0.871 - ETA: 8s - loss: 0.3353 - acc: 0.871 - ETA: 7s - loss: 0.3350 - acc: 0.871 - ETA: 7s - loss: 0.3348 - acc: 0.871 - ETA: 7s - loss: 0.3345 - acc: 0.871 - ETA: 6s - loss: 0.3343 - acc: 0.871 - ETA: 6s - loss: 0.3343 - acc: 0.871 - ETA: 6s - loss: 0.3339 - acc: 0.871 - ETA: 6s - loss: 0.3337 - acc: 0.872 - ETA: 5s - loss: 0.3336 - acc: 0.872 - ETA: 5s - loss: 0.3338 - acc: 0.872 - ETA: 5s - loss: 0.3335 - acc: 0.872 - ETA: 4s - loss: 0.3332 - acc: 0.872 - ETA: 4s - loss: 0.3329 - acc: 0.872 - ETA: 4s - loss: 0.3330 - acc: 0.872 - ETA: 4s - loss: 0.3326 - acc: 0.872 - ETA: 3s - loss: 0.3324 - acc: 0.872 - ETA: 3s - loss: 0.3320 - acc: 0.872 - ETA: 3s - loss: 0.3317 - acc: 0.872 - ETA: 3s - loss: 0.3314 - acc: 0.872 - ETA: 2s - loss: 0.3308 - acc: 0.873 - ETA: 2s - loss: 0.3310 - acc: 0.8731"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/427 [============================>.] - ETA: 2s - loss: 0.3315 - acc: 0.873 - ETA: 1s - loss: 0.3318 - acc: 0.873 - ETA: 1s - loss: 0.3318 - acc: 0.873 - ETA: 1s - loss: 0.3325 - acc: 0.872 - ETA: 1s - loss: 0.3323 - acc: 0.872 - ETA: 0s - loss: 0.3321 - acc: 0.872 - ETA: 0s - loss: 0.3317 - acc: 0.872 - ETA: 0s - loss: 0.3314 - acc: 0.8732\n",
      "Epoch 00002: val_loss improved from 0.44760 to 0.42865, saving model to saved_models/weights.aug.best.hdf5\n",
      "427/427 [==============================] - 119s 278ms/step - loss: 0.3313 - acc: 0.8732 - val_loss: 0.4286 - val_acc: 0.8376\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:41 - loss: 0.4080 - acc: 0.850 - ETA: 1:42 - loss: 0.3019 - acc: 0.900 - ETA: 1:41 - loss: 0.2935 - acc: 0.900 - ETA: 1:42 - loss: 0.3238 - acc: 0.900 - ETA: 1:45 - loss: 0.3326 - acc: 0.890 - ETA: 1:47 - loss: 0.3188 - acc: 0.900 - ETA: 1:47 - loss: 0.3227 - acc: 0.892 - ETA: 1:46 - loss: 0.3303 - acc: 0.893 - ETA: 1:46 - loss: 0.3239 - acc: 0.894 - ETA: 1:45 - loss: 0.3092 - acc: 0.900 - ETA: 1:44 - loss: 0.2970 - acc: 0.904 - ETA: 1:44 - loss: 0.3010 - acc: 0.900 - ETA: 1:44 - loss: 0.3106 - acc: 0.892 - ETA: 1:43 - loss: 0.3154 - acc: 0.889 - ETA: 1:43 - loss: 0.3199 - acc: 0.886 - ETA: 1:44 - loss: 0.3209 - acc: 0.887 - ETA: 1:44 - loss: 0.3084 - acc: 0.894 - ETA: 1:44 - loss: 0.3169 - acc: 0.888 - ETA: 1:41 - loss: 0.3325 - acc: 0.887 - ETA: 1:40 - loss: 0.3493 - acc: 0.877 - ETA: 1:40 - loss: 0.3447 - acc: 0.881 - ETA: 1:39 - loss: 0.3394 - acc: 0.884 - ETA: 1:39 - loss: 0.3363 - acc: 0.882 - ETA: 1:39 - loss: 0.3277 - acc: 0.885 - ETA: 1:39 - loss: 0.3221 - acc: 0.886 - ETA: 1:39 - loss: 0.3259 - acc: 0.884 - ETA: 1:37 - loss: 0.3418 - acc: 0.873 - ETA: 1:37 - loss: 0.3405 - acc: 0.874 - ETA: 1:37 - loss: 0.3365 - acc: 0.876 - ETA: 1:37 - loss: 0.3428 - acc: 0.872 - ETA: 1:37 - loss: 0.3412 - acc: 0.871 - ETA: 1:37 - loss: 0.3369 - acc: 0.874 - ETA: 1:37 - loss: 0.3344 - acc: 0.876 - ETA: 1:37 - loss: 0.3367 - acc: 0.877 - ETA: 1:37 - loss: 0.3320 - acc: 0.879 - ETA: 1:37 - loss: 0.3349 - acc: 0.878 - ETA: 1:37 - loss: 0.3351 - acc: 0.875 - ETA: 1:36 - loss: 0.3350 - acc: 0.874 - ETA: 1:36 - loss: 0.3326 - acc: 0.876 - ETA: 1:37 - loss: 0.3373 - acc: 0.872 - ETA: 1:36 - loss: 0.3350 - acc: 0.872 - ETA: 1:37 - loss: 0.3377 - acc: 0.872 - ETA: 1:36 - loss: 0.3399 - acc: 0.870 - ETA: 1:36 - loss: 0.3392 - acc: 0.871 - ETA: 1:36 - loss: 0.3385 - acc: 0.870 - ETA: 1:35 - loss: 0.3355 - acc: 0.872 - ETA: 1:35 - loss: 0.3325 - acc: 0.874 - ETA: 1:35 - loss: 0.3340 - acc: 0.872 - ETA: 1:35 - loss: 0.3340 - acc: 0.872 - ETA: 1:35 - loss: 0.3327 - acc: 0.871 - ETA: 1:34 - loss: 0.3317 - acc: 0.872 - ETA: 1:33 - loss: 0.3342 - acc: 0.869 - ETA: 1:33 - loss: 0.3324 - acc: 0.869 - ETA: 1:32 - loss: 0.3324 - acc: 0.867 - ETA: 1:32 - loss: 0.3301 - acc: 0.868 - ETA: 1:32 - loss: 0.3292 - acc: 0.867 - ETA: 1:32 - loss: 0.3280 - acc: 0.868 - ETA: 1:31 - loss: 0.3246 - acc: 0.870 - ETA: 1:31 - loss: 0.3263 - acc: 0.870 - ETA: 1:31 - loss: 0.3244 - acc: 0.871 - ETA: 1:31 - loss: 0.3250 - acc: 0.871 - ETA: 1:31 - loss: 0.3260 - acc: 0.870 - ETA: 1:31 - loss: 0.3242 - acc: 0.870 - ETA: 1:31 - loss: 0.3262 - acc: 0.869 - ETA: 1:31 - loss: 0.3247 - acc: 0.869 - ETA: 1:31 - loss: 0.3238 - acc: 0.870 - ETA: 1:31 - loss: 0.3263 - acc: 0.868 - ETA: 1:31 - loss: 0.3263 - acc: 0.868 - ETA: 1:30 - loss: 0.3302 - acc: 0.867 - ETA: 1:30 - loss: 0.3309 - acc: 0.867 - ETA: 1:30 - loss: 0.3340 - acc: 0.866 - ETA: 1:30 - loss: 0.3308 - acc: 0.868 - ETA: 1:30 - loss: 0.3287 - acc: 0.869 - ETA: 1:30 - loss: 0.3286 - acc: 0.868 - ETA: 1:29 - loss: 0.3295 - acc: 0.868 - ETA: 1:29 - loss: 0.3321 - acc: 0.867 - ETA: 1:29 - loss: 0.3312 - acc: 0.868 - ETA: 1:29 - loss: 0.3292 - acc: 0.869 - ETA: 1:28 - loss: 0.3324 - acc: 0.867 - ETA: 1:28 - loss: 0.3327 - acc: 0.868 - ETA: 1:28 - loss: 0.3326 - acc: 0.867 - ETA: 1:27 - loss: 0.3380 - acc: 0.865 - ETA: 1:27 - loss: 0.3378 - acc: 0.866 - ETA: 1:26 - loss: 0.3380 - acc: 0.865 - ETA: 1:26 - loss: 0.3370 - acc: 0.865 - ETA: 1:26 - loss: 0.3355 - acc: 0.866 - ETA: 1:26 - loss: 0.3394 - acc: 0.865 - ETA: 1:26 - loss: 0.3389 - acc: 0.865 - ETA: 1:25 - loss: 0.3392 - acc: 0.865 - ETA: 1:25 - loss: 0.3388 - acc: 0.866 - ETA: 1:25 - loss: 0.3384 - acc: 0.866 - ETA: 1:25 - loss: 0.3365 - acc: 0.866 - ETA: 1:25 - loss: 0.3343 - acc: 0.868 - ETA: 1:25 - loss: 0.3333 - acc: 0.868 - ETA: 1:24 - loss: 0.3365 - acc: 0.866 - ETA: 1:24 - loss: 0.3346 - acc: 0.868 - ETA: 1:23 - loss: 0.3334 - acc: 0.869 - ETA: 1:23 - loss: 0.3313 - acc: 0.870 - ETA: 1:23 - loss: 0.3312 - acc: 0.870 - ETA: 1:23 - loss: 0.3299 - acc: 0.871 - ETA: 1:23 - loss: 0.3291 - acc: 0.870 - ETA: 1:22 - loss: 0.3296 - acc: 0.870 - ETA: 1:22 - loss: 0.3294 - acc: 0.870 - ETA: 1:22 - loss: 0.3306 - acc: 0.870 - ETA: 1:21 - loss: 0.3287 - acc: 0.871 - ETA: 1:21 - loss: 0.3300 - acc: 0.870 - ETA: 1:21 - loss: 0.3319 - acc: 0.870 - ETA: 1:21 - loss: 0.3322 - acc: 0.870 - ETA: 1:20 - loss: 0.3329 - acc: 0.870 - ETA: 1:20 - loss: 0.3322 - acc: 0.871 - ETA: 1:20 - loss: 0.3320 - acc: 0.870 - ETA: 1:20 - loss: 0.3312 - acc: 0.870 - ETA: 1:20 - loss: 0.3296 - acc: 0.871 - ETA: 1:20 - loss: 0.3298 - acc: 0.871 - ETA: 1:19 - loss: 0.3306 - acc: 0.870 - ETA: 1:19 - loss: 0.3311 - acc: 0.870 - ETA: 1:19 - loss: 0.3298 - acc: 0.871 - ETA: 1:18 - loss: 0.3295 - acc: 0.870 - ETA: 1:18 - loss: 0.3297 - acc: 0.871 - ETA: 1:18 - loss: 0.3288 - acc: 0.871 - ETA: 1:18 - loss: 0.3276 - acc: 0.872 - ETA: 1:17 - loss: 0.3282 - acc: 0.872 - ETA: 1:17 - loss: 0.3291 - acc: 0.872 - ETA: 1:17 - loss: 0.3290 - acc: 0.872 - ETA: 1:17 - loss: 0.3274 - acc: 0.873 - ETA: 1:16 - loss: 0.3260 - acc: 0.874 - ETA: 1:16 - loss: 0.3262 - acc: 0.874 - ETA: 1:16 - loss: 0.3269 - acc: 0.874 - ETA: 1:16 - loss: 0.3286 - acc: 0.873 - ETA: 1:15 - loss: 0.3294 - acc: 0.872 - ETA: 1:15 - loss: 0.3288 - acc: 0.872 - ETA: 1:15 - loss: 0.3285 - acc: 0.872 - ETA: 1:15 - loss: 0.3289 - acc: 0.871 - ETA: 1:15 - loss: 0.3290 - acc: 0.871 - ETA: 1:14 - loss: 0.3277 - acc: 0.872 - ETA: 1:14 - loss: 0.3267 - acc: 0.873 - ETA: 1:14 - loss: 0.3255 - acc: 0.873 - ETA: 1:14 - loss: 0.3264 - acc: 0.872 - ETA: 1:14 - loss: 0.3249 - acc: 0.873 - ETA: 1:13 - loss: 0.3257 - acc: 0.873 - ETA: 1:13 - loss: 0.3254 - acc: 0.873 - ETA: 1:13 - loss: 0.3251 - acc: 0.874 - ETA: 1:13 - loss: 0.3237 - acc: 0.875 - ETA: 1:13 - loss: 0.3240 - acc: 0.875 - ETA: 1:12 - loss: 0.3240 - acc: 0.875 - ETA: 1:12 - loss: 0.3227 - acc: 0.876 - ETA: 1:12 - loss: 0.3230 - acc: 0.875 - ETA: 1:12 - loss: 0.3224 - acc: 0.875 - ETA: 1:11 - loss: 0.3226 - acc: 0.874 - ETA: 1:11 - loss: 0.3220 - acc: 0.875 - ETA: 1:11 - loss: 0.3221 - acc: 0.875 - ETA: 1:11 - loss: 0.3213 - acc: 0.875 - ETA: 1:11 - loss: 0.3208 - acc: 0.875 - ETA: 1:10 - loss: 0.3199 - acc: 0.876 - ETA: 1:10 - loss: 0.3190 - acc: 0.876 - ETA: 1:10 - loss: 0.3191 - acc: 0.877 - ETA: 1:10 - loss: 0.3198 - acc: 0.876 - ETA: 1:10 - loss: 0.3199 - acc: 0.877 - ETA: 1:09 - loss: 0.3196 - acc: 0.877 - ETA: 1:09 - loss: 0.3195 - acc: 0.877 - ETA: 1:09 - loss: 0.3199 - acc: 0.876 - ETA: 1:09 - loss: 0.3196 - acc: 0.876 - ETA: 1:09 - loss: 0.3189 - acc: 0.877 - ETA: 1:08 - loss: 0.3187 - acc: 0.876 - ETA: 1:08 - loss: 0.3189 - acc: 0.877 - ETA: 1:08 - loss: 0.3186 - acc: 0.876 - ETA: 1:07 - loss: 0.3196 - acc: 0.876 - ETA: 1:07 - loss: 0.3190 - acc: 0.876 - ETA: 1:07 - loss: 0.3208 - acc: 0.876 - ETA: 1:07 - loss: 0.3213 - acc: 0.875 - ETA: 1:06 - loss: 0.3208 - acc: 0.875 - ETA: 1:06 - loss: 0.3204 - acc: 0.876 - ETA: 1:06 - loss: 0.3210 - acc: 0.876 - ETA: 1:06 - loss: 0.3216 - acc: 0.875 - ETA: 1:05 - loss: 0.3203 - acc: 0.876 - ETA: 1:05 - loss: 0.3192 - acc: 0.877 - ETA: 1:05 - loss: 0.3193 - acc: 0.877 - ETA: 1:05 - loss: 0.3194 - acc: 0.877 - ETA: 1:04 - loss: 0.3196 - acc: 0.877 - ETA: 1:04 - loss: 0.3192 - acc: 0.877 - ETA: 1:04 - loss: 0.3184 - acc: 0.877 - ETA: 1:03 - loss: 0.3191 - acc: 0.876 - ETA: 1:03 - loss: 0.3193 - acc: 0.875 - ETA: 1:03 - loss: 0.3195 - acc: 0.875 - ETA: 1:03 - loss: 0.3188 - acc: 0.875 - ETA: 1:03 - loss: 0.3195 - acc: 0.875 - ETA: 1:02 - loss: 0.3210 - acc: 0.874 - ETA: 1:02 - loss: 0.3209 - acc: 0.874 - ETA: 1:02 - loss: 0.3202 - acc: 0.875 - ETA: 1:02 - loss: 0.3205 - acc: 0.875 - ETA: 1:01 - loss: 0.3205 - acc: 0.874 - ETA: 1:01 - loss: 0.3201 - acc: 0.874 - ETA: 1:01 - loss: 0.3192 - acc: 0.874 - ETA: 1:01 - loss: 0.3195 - acc: 0.874 - ETA: 1:00 - loss: 0.3205 - acc: 0.874 - ETA: 1:00 - loss: 0.3197 - acc: 0.874 - ETA: 1:00 - loss: 0.3210 - acc: 0.873 - ETA: 1:00 - loss: 0.3208 - acc: 0.873 - ETA: 59s - loss: 0.3196 - acc: 0.874 - ETA: 59s - loss: 0.3198 - acc: 0.87 - ETA: 59s - loss: 0.3196 - acc: 0.87 - ETA: 59s - loss: 0.3193 - acc: 0.87 - ETA: 58s - loss: 0.3183 - acc: 0.87 - ETA: 58s - loss: 0.3186 - acc: 0.87 - ETA: 58s - loss: 0.3181 - acc: 0.8754420/427 [============================>.] - ETA: 58s - loss: 0.3177 - acc: 0.87 - ETA: 57s - loss: 0.3173 - acc: 0.87 - ETA: 57s - loss: 0.3170 - acc: 0.87 - ETA: 57s - loss: 0.3181 - acc: 0.87 - ETA: 57s - loss: 0.3173 - acc: 0.87 - ETA: 56s - loss: 0.3162 - acc: 0.87 - ETA: 56s - loss: 0.3164 - acc: 0.87 - ETA: 56s - loss: 0.3158 - acc: 0.87 - ETA: 56s - loss: 0.3156 - acc: 0.87 - ETA: 55s - loss: 0.3152 - acc: 0.87 - ETA: 55s - loss: 0.3151 - acc: 0.87 - ETA: 55s - loss: 0.3144 - acc: 0.87 - ETA: 55s - loss: 0.3148 - acc: 0.87 - ETA: 54s - loss: 0.3160 - acc: 0.87 - ETA: 54s - loss: 0.3157 - acc: 0.87 - ETA: 54s - loss: 0.3162 - acc: 0.87 - ETA: 54s - loss: 0.3156 - acc: 0.87 - ETA: 53s - loss: 0.3155 - acc: 0.87 - ETA: 53s - loss: 0.3161 - acc: 0.87 - ETA: 53s - loss: 0.3157 - acc: 0.87 - ETA: 53s - loss: 0.3152 - acc: 0.87 - ETA: 52s - loss: 0.3153 - acc: 0.87 - ETA: 52s - loss: 0.3158 - acc: 0.87 - ETA: 52s - loss: 0.3166 - acc: 0.87 - ETA: 52s - loss: 0.3161 - acc: 0.87 - ETA: 51s - loss: 0.3162 - acc: 0.87 - ETA: 51s - loss: 0.3159 - acc: 0.87 - ETA: 51s - loss: 0.3162 - acc: 0.87 - ETA: 51s - loss: 0.3158 - acc: 0.87 - ETA: 50s - loss: 0.3153 - acc: 0.87 - ETA: 50s - loss: 0.3151 - acc: 0.87 - ETA: 50s - loss: 0.3156 - acc: 0.87 - ETA: 49s - loss: 0.3157 - acc: 0.87 - ETA: 49s - loss: 0.3149 - acc: 0.87 - ETA: 49s - loss: 0.3149 - acc: 0.87 - ETA: 49s - loss: 0.3146 - acc: 0.87 - ETA: 48s - loss: 0.3145 - acc: 0.87 - ETA: 48s - loss: 0.3140 - acc: 0.87 - ETA: 48s - loss: 0.3141 - acc: 0.87 - ETA: 48s - loss: 0.3142 - acc: 0.87 - ETA: 47s - loss: 0.3135 - acc: 0.87 - ETA: 47s - loss: 0.3145 - acc: 0.87 - ETA: 47s - loss: 0.3140 - acc: 0.87 - ETA: 46s - loss: 0.3145 - acc: 0.87 - ETA: 46s - loss: 0.3140 - acc: 0.87 - ETA: 46s - loss: 0.3138 - acc: 0.87 - ETA: 46s - loss: 0.3134 - acc: 0.87 - ETA: 45s - loss: 0.3140 - acc: 0.87 - ETA: 45s - loss: 0.3138 - acc: 0.87 - ETA: 45s - loss: 0.3135 - acc: 0.87 - ETA: 44s - loss: 0.3136 - acc: 0.87 - ETA: 44s - loss: 0.3130 - acc: 0.87 - ETA: 44s - loss: 0.3123 - acc: 0.87 - ETA: 44s - loss: 0.3120 - acc: 0.87 - ETA: 43s - loss: 0.3120 - acc: 0.87 - ETA: 43s - loss: 0.3119 - acc: 0.87 - ETA: 43s - loss: 0.3119 - acc: 0.87 - ETA: 43s - loss: 0.3120 - acc: 0.87 - ETA: 42s - loss: 0.3123 - acc: 0.87 - ETA: 42s - loss: 0.3121 - acc: 0.87 - ETA: 42s - loss: 0.3120 - acc: 0.87 - ETA: 41s - loss: 0.3119 - acc: 0.87 - ETA: 41s - loss: 0.3115 - acc: 0.87 - ETA: 41s - loss: 0.3108 - acc: 0.87 - ETA: 41s - loss: 0.3115 - acc: 0.87 - ETA: 40s - loss: 0.3112 - acc: 0.87 - ETA: 40s - loss: 0.3105 - acc: 0.87 - ETA: 40s - loss: 0.3102 - acc: 0.87 - ETA: 40s - loss: 0.3107 - acc: 0.87 - ETA: 39s - loss: 0.3103 - acc: 0.87 - ETA: 39s - loss: 0.3100 - acc: 0.87 - ETA: 39s - loss: 0.3096 - acc: 0.88 - ETA: 39s - loss: 0.3098 - acc: 0.87 - ETA: 38s - loss: 0.3096 - acc: 0.88 - ETA: 38s - loss: 0.3089 - acc: 0.88 - ETA: 38s - loss: 0.3091 - acc: 0.87 - ETA: 38s - loss: 0.3089 - acc: 0.88 - ETA: 37s - loss: 0.3089 - acc: 0.88 - ETA: 37s - loss: 0.3093 - acc: 0.88 - ETA: 37s - loss: 0.3086 - acc: 0.88 - ETA: 37s - loss: 0.3081 - acc: 0.88 - ETA: 36s - loss: 0.3078 - acc: 0.88 - ETA: 36s - loss: 0.3080 - acc: 0.88 - ETA: 36s - loss: 0.3079 - acc: 0.88 - ETA: 35s - loss: 0.3082 - acc: 0.88 - ETA: 35s - loss: 0.3077 - acc: 0.88 - ETA: 35s - loss: 0.3081 - acc: 0.88 - ETA: 35s - loss: 0.3075 - acc: 0.88 - ETA: 34s - loss: 0.3074 - acc: 0.88 - ETA: 34s - loss: 0.3073 - acc: 0.88 - ETA: 34s - loss: 0.3070 - acc: 0.88 - ETA: 34s - loss: 0.3075 - acc: 0.88 - ETA: 33s - loss: 0.3071 - acc: 0.88 - ETA: 33s - loss: 0.3070 - acc: 0.88 - ETA: 33s - loss: 0.3079 - acc: 0.88 - ETA: 33s - loss: 0.3076 - acc: 0.88 - ETA: 32s - loss: 0.3079 - acc: 0.88 - ETA: 32s - loss: 0.3075 - acc: 0.88 - ETA: 32s - loss: 0.3071 - acc: 0.88 - ETA: 32s - loss: 0.3069 - acc: 0.88 - ETA: 31s - loss: 0.3065 - acc: 0.88 - ETA: 31s - loss: 0.3071 - acc: 0.88 - ETA: 31s - loss: 0.3069 - acc: 0.88 - ETA: 30s - loss: 0.3066 - acc: 0.88 - ETA: 30s - loss: 0.3064 - acc: 0.88 - ETA: 30s - loss: 0.3068 - acc: 0.88 - ETA: 30s - loss: 0.3062 - acc: 0.88 - ETA: 29s - loss: 0.3060 - acc: 0.88 - ETA: 29s - loss: 0.3063 - acc: 0.88 - ETA: 29s - loss: 0.3066 - acc: 0.88 - ETA: 29s - loss: 0.3068 - acc: 0.88 - ETA: 28s - loss: 0.3070 - acc: 0.88 - ETA: 28s - loss: 0.3075 - acc: 0.88 - ETA: 28s - loss: 0.3076 - acc: 0.88 - ETA: 28s - loss: 0.3078 - acc: 0.88 - ETA: 27s - loss: 0.3078 - acc: 0.88 - ETA: 27s - loss: 0.3083 - acc: 0.87 - ETA: 27s - loss: 0.3082 - acc: 0.87 - ETA: 27s - loss: 0.3081 - acc: 0.87 - ETA: 26s - loss: 0.3079 - acc: 0.87 - ETA: 26s - loss: 0.3078 - acc: 0.87 - ETA: 26s - loss: 0.3085 - acc: 0.87 - ETA: 26s - loss: 0.3085 - acc: 0.87 - ETA: 25s - loss: 0.3080 - acc: 0.87 - ETA: 25s - loss: 0.3079 - acc: 0.87 - ETA: 25s - loss: 0.3076 - acc: 0.87 - ETA: 24s - loss: 0.3072 - acc: 0.88 - ETA: 24s - loss: 0.3066 - acc: 0.88 - ETA: 24s - loss: 0.3067 - acc: 0.88 - ETA: 24s - loss: 0.3062 - acc: 0.88 - ETA: 23s - loss: 0.3067 - acc: 0.88 - ETA: 23s - loss: 0.3063 - acc: 0.88 - ETA: 23s - loss: 0.3060 - acc: 0.88 - ETA: 23s - loss: 0.3063 - acc: 0.88 - ETA: 22s - loss: 0.3058 - acc: 0.88 - ETA: 22s - loss: 0.3058 - acc: 0.88 - ETA: 22s - loss: 0.3057 - acc: 0.88 - ETA: 22s - loss: 0.3059 - acc: 0.88 - ETA: 21s - loss: 0.3059 - acc: 0.88 - ETA: 21s - loss: 0.3054 - acc: 0.88 - ETA: 21s - loss: 0.3058 - acc: 0.88 - ETA: 21s - loss: 0.3058 - acc: 0.88 - ETA: 20s - loss: 0.3059 - acc: 0.88 - ETA: 20s - loss: 0.3063 - acc: 0.88 - ETA: 20s - loss: 0.3064 - acc: 0.88 - ETA: 20s - loss: 0.3063 - acc: 0.88 - ETA: 19s - loss: 0.3060 - acc: 0.88 - ETA: 19s - loss: 0.3058 - acc: 0.88 - ETA: 19s - loss: 0.3055 - acc: 0.88 - ETA: 18s - loss: 0.3054 - acc: 0.88 - ETA: 18s - loss: 0.3054 - acc: 0.88 - ETA: 18s - loss: 0.3058 - acc: 0.88 - ETA: 18s - loss: 0.3064 - acc: 0.88 - ETA: 17s - loss: 0.3061 - acc: 0.88 - ETA: 17s - loss: 0.3063 - acc: 0.88 - ETA: 17s - loss: 0.3062 - acc: 0.88 - ETA: 17s - loss: 0.3061 - acc: 0.88 - ETA: 16s - loss: 0.3062 - acc: 0.88 - ETA: 16s - loss: 0.3062 - acc: 0.88 - ETA: 16s - loss: 0.3059 - acc: 0.88 - ETA: 16s - loss: 0.3059 - acc: 0.88 - ETA: 15s - loss: 0.3060 - acc: 0.88 - ETA: 15s - loss: 0.3059 - acc: 0.88 - ETA: 15s - loss: 0.3056 - acc: 0.88 - ETA: 15s - loss: 0.3055 - acc: 0.88 - ETA: 14s - loss: 0.3056 - acc: 0.88 - ETA: 14s - loss: 0.3051 - acc: 0.88 - ETA: 14s - loss: 0.3051 - acc: 0.88 - ETA: 13s - loss: 0.3050 - acc: 0.88 - ETA: 13s - loss: 0.3048 - acc: 0.88 - ETA: 13s - loss: 0.3046 - acc: 0.88 - ETA: 13s - loss: 0.3043 - acc: 0.88 - ETA: 12s - loss: 0.3046 - acc: 0.88 - ETA: 12s - loss: 0.3043 - acc: 0.88 - ETA: 12s - loss: 0.3046 - acc: 0.88 - ETA: 12s - loss: 0.3055 - acc: 0.88 - ETA: 11s - loss: 0.3050 - acc: 0.88 - ETA: 11s - loss: 0.3055 - acc: 0.88 - ETA: 11s - loss: 0.3053 - acc: 0.88 - ETA: 11s - loss: 0.3052 - acc: 0.88 - ETA: 10s - loss: 0.3050 - acc: 0.88 - ETA: 10s - loss: 0.3049 - acc: 0.88 - ETA: 10s - loss: 0.3048 - acc: 0.88 - ETA: 9s - loss: 0.3047 - acc: 0.8810 - ETA: 9s - loss: 0.3050 - acc: 0.880 - ETA: 9s - loss: 0.3050 - acc: 0.881 - ETA: 9s - loss: 0.3053 - acc: 0.881 - ETA: 8s - loss: 0.3052 - acc: 0.881 - ETA: 8s - loss: 0.3051 - acc: 0.881 - ETA: 8s - loss: 0.3052 - acc: 0.880 - ETA: 8s - loss: 0.3054 - acc: 0.880 - ETA: 7s - loss: 0.3054 - acc: 0.880 - ETA: 7s - loss: 0.3057 - acc: 0.880 - ETA: 7s - loss: 0.3056 - acc: 0.880 - ETA: 7s - loss: 0.3053 - acc: 0.880 - ETA: 6s - loss: 0.3049 - acc: 0.880 - ETA: 6s - loss: 0.3048 - acc: 0.880 - ETA: 6s - loss: 0.3046 - acc: 0.880 - ETA: 6s - loss: 0.3050 - acc: 0.880 - ETA: 5s - loss: 0.3049 - acc: 0.880 - ETA: 5s - loss: 0.3047 - acc: 0.880 - ETA: 5s - loss: 0.3046 - acc: 0.881 - ETA: 4s - loss: 0.3043 - acc: 0.881 - ETA: 4s - loss: 0.3042 - acc: 0.881 - ETA: 4s - loss: 0.3037 - acc: 0.881 - ETA: 4s - loss: 0.3035 - acc: 0.881 - ETA: 3s - loss: 0.3034 - acc: 0.881 - ETA: 3s - loss: 0.3031 - acc: 0.882 - ETA: 3s - loss: 0.3032 - acc: 0.881 - ETA: 3s - loss: 0.3031 - acc: 0.881 - ETA: 2s - loss: 0.3030 - acc: 0.881 - ETA: 2s - loss: 0.3029 - acc: 0.881 - ETA: 2s - loss: 0.3027 - acc: 0.882 - ETA: 2s - loss: 0.3025 - acc: 0.882 - ETA: 1s - loss: 0.3023 - acc: 0.8823426/427 [============================>.] - ETA: 1s - loss: 0.3025 - acc: 0.882 - ETA: 1s - loss: 0.3024 - acc: 0.882 - ETA: 1s - loss: 0.3027 - acc: 0.882 - ETA: 0s - loss: 0.3024 - acc: 0.882 - ETA: 0s - loss: 0.3024 - acc: 0.882 - ETA: 0s - loss: 0.3020 - acc: 0.8825\n",
      "Epoch 00003: val_loss did not improve\n",
      "427/427 [==============================] - 113s 265ms/step - loss: 0.3019 - acc: 0.8824 - val_loss: 0.4294 - val_acc: 0.8433\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:44 - loss: 0.2071 - acc: 0.850 - ETA: 1:44 - loss: 0.1972 - acc: 0.900 - ETA: 1:43 - loss: 0.2417 - acc: 0.850 - ETA: 1:43 - loss: 0.2368 - acc: 0.875 - ETA: 1:44 - loss: 0.2260 - acc: 0.880 - ETA: 1:44 - loss: 0.2414 - acc: 0.875 - ETA: 1:45 - loss: 0.2382 - acc: 0.885 - ETA: 1:46 - loss: 0.2444 - acc: 0.881 - ETA: 1:47 - loss: 0.2443 - acc: 0.888 - ETA: 1:47 - loss: 0.2560 - acc: 0.880 - ETA: 1:46 - loss: 0.2505 - acc: 0.881 - ETA: 1:45 - loss: 0.2550 - acc: 0.883 - ETA: 1:44 - loss: 0.2484 - acc: 0.884 - ETA: 1:43 - loss: 0.2497 - acc: 0.882 - ETA: 1:43 - loss: 0.2514 - acc: 0.883 - ETA: 1:42 - loss: 0.2536 - acc: 0.884 - ETA: 1:42 - loss: 0.2662 - acc: 0.888 - ETA: 1:43 - loss: 0.2557 - acc: 0.894 - ETA: 1:42 - loss: 0.2657 - acc: 0.892 - ETA: 1:42 - loss: 0.2691 - acc: 0.892 - ETA: 1:42 - loss: 0.2663 - acc: 0.892 - ETA: 1:42 - loss: 0.2698 - acc: 0.888 - ETA: 1:42 - loss: 0.2737 - acc: 0.889 - ETA: 1:42 - loss: 0.2708 - acc: 0.889 - ETA: 1:42 - loss: 0.2779 - acc: 0.884 - ETA: 1:42 - loss: 0.2734 - acc: 0.886 - ETA: 1:42 - loss: 0.2692 - acc: 0.890 - ETA: 1:42 - loss: 0.2687 - acc: 0.891 - ETA: 1:41 - loss: 0.2669 - acc: 0.891 - ETA: 1:41 - loss: 0.2661 - acc: 0.890 - ETA: 1:42 - loss: 0.2667 - acc: 0.888 - ETA: 1:42 - loss: 0.2644 - acc: 0.890 - ETA: 1:42 - loss: 0.2722 - acc: 0.889 - ETA: 1:42 - loss: 0.2703 - acc: 0.889 - ETA: 1:39 - loss: 0.2698 - acc: 0.888 - ETA: 1:39 - loss: 0.2749 - acc: 0.887 - ETA: 1:39 - loss: 0.2743 - acc: 0.886 - ETA: 1:38 - loss: 0.2713 - acc: 0.888 - ETA: 1:38 - loss: 0.2686 - acc: 0.889 - ETA: 1:38 - loss: 0.2672 - acc: 0.890 - ETA: 1:37 - loss: 0.2641 - acc: 0.892 - ETA: 1:37 - loss: 0.2634 - acc: 0.894 - ETA: 1:37 - loss: 0.2640 - acc: 0.894 - ETA: 1:36 - loss: 0.2644 - acc: 0.894 - ETA: 1:36 - loss: 0.2681 - acc: 0.895 - ETA: 1:36 - loss: 0.2677 - acc: 0.896 - ETA: 1:35 - loss: 0.2632 - acc: 0.899 - ETA: 1:35 - loss: 0.2653 - acc: 0.897 - ETA: 1:34 - loss: 0.2621 - acc: 0.899 - ETA: 1:33 - loss: 0.2598 - acc: 0.900 - ETA: 1:33 - loss: 0.2583 - acc: 0.901 - ETA: 1:33 - loss: 0.2581 - acc: 0.901 - ETA: 1:32 - loss: 0.2591 - acc: 0.901 - ETA: 1:32 - loss: 0.2569 - acc: 0.902 - ETA: 1:32 - loss: 0.2607 - acc: 0.901 - ETA: 1:32 - loss: 0.2618 - acc: 0.901 - ETA: 1:32 - loss: 0.2634 - acc: 0.899 - ETA: 1:32 - loss: 0.2610 - acc: 0.901 - ETA: 1:31 - loss: 0.2590 - acc: 0.901 - ETA: 1:31 - loss: 0.2582 - acc: 0.902 - ETA: 1:31 - loss: 0.2620 - acc: 0.900 - ETA: 1:31 - loss: 0.2662 - acc: 0.900 - ETA: 1:30 - loss: 0.2684 - acc: 0.898 - ETA: 1:30 - loss: 0.2691 - acc: 0.897 - ETA: 1:30 - loss: 0.2671 - acc: 0.898 - ETA: 1:30 - loss: 0.2655 - acc: 0.899 - ETA: 1:29 - loss: 0.2707 - acc: 0.896 - ETA: 1:28 - loss: 0.2711 - acc: 0.896 - ETA: 1:28 - loss: 0.2713 - acc: 0.896 - ETA: 1:28 - loss: 0.2722 - acc: 0.895 - ETA: 1:27 - loss: 0.2702 - acc: 0.896 - ETA: 1:27 - loss: 0.2703 - acc: 0.896 - ETA: 1:27 - loss: 0.2704 - acc: 0.896 - ETA: 1:27 - loss: 0.2723 - acc: 0.896 - ETA: 1:26 - loss: 0.2713 - acc: 0.896 - ETA: 1:26 - loss: 0.2719 - acc: 0.896 - ETA: 1:26 - loss: 0.2721 - acc: 0.896 - ETA: 1:25 - loss: 0.2730 - acc: 0.896 - ETA: 1:25 - loss: 0.2722 - acc: 0.895 - ETA: 1:25 - loss: 0.2737 - acc: 0.895 - ETA: 1:25 - loss: 0.2734 - acc: 0.895 - ETA: 1:25 - loss: 0.2730 - acc: 0.896 - ETA: 1:25 - loss: 0.2710 - acc: 0.897 - ETA: 1:25 - loss: 0.2710 - acc: 0.896 - ETA: 1:24 - loss: 0.2692 - acc: 0.897 - ETA: 1:24 - loss: 0.2688 - acc: 0.897 - ETA: 1:24 - loss: 0.2675 - acc: 0.897 - ETA: 1:24 - loss: 0.2684 - acc: 0.898 - ETA: 1:24 - loss: 0.2672 - acc: 0.898 - ETA: 1:23 - loss: 0.2651 - acc: 0.899 - ETA: 1:23 - loss: 0.2639 - acc: 0.900 - ETA: 1:23 - loss: 0.2626 - acc: 0.901 - ETA: 1:23 - loss: 0.2633 - acc: 0.901 - ETA: 1:23 - loss: 0.2637 - acc: 0.901 - ETA: 1:23 - loss: 0.2635 - acc: 0.901 - ETA: 1:22 - loss: 0.2692 - acc: 0.900 - ETA: 1:22 - loss: 0.2694 - acc: 0.900 - ETA: 1:22 - loss: 0.2704 - acc: 0.900 - ETA: 1:22 - loss: 0.2695 - acc: 0.901 - ETA: 1:21 - loss: 0.2681 - acc: 0.902 - ETA: 1:21 - loss: 0.2664 - acc: 0.903 - ETA: 1:20 - loss: 0.2658 - acc: 0.903 - ETA: 1:20 - loss: 0.2655 - acc: 0.902 - ETA: 1:20 - loss: 0.2642 - acc: 0.902 - ETA: 1:20 - loss: 0.2630 - acc: 0.903 - ETA: 1:20 - loss: 0.2648 - acc: 0.901 - ETA: 1:20 - loss: 0.2651 - acc: 0.901 - ETA: 1:20 - loss: 0.2656 - acc: 0.901 - ETA: 1:19 - loss: 0.2659 - acc: 0.901 - ETA: 1:19 - loss: 0.2645 - acc: 0.902 - ETA: 1:19 - loss: 0.2633 - acc: 0.902 - ETA: 1:19 - loss: 0.2624 - acc: 0.902 - ETA: 1:18 - loss: 0.2624 - acc: 0.902 - ETA: 1:18 - loss: 0.2614 - acc: 0.903 - ETA: 1:18 - loss: 0.2605 - acc: 0.903 - ETA: 1:18 - loss: 0.2601 - acc: 0.903 - ETA: 1:17 - loss: 0.2613 - acc: 0.902 - ETA: 1:17 - loss: 0.2610 - acc: 0.902 - ETA: 1:17 - loss: 0.2615 - acc: 0.901 - ETA: 1:17 - loss: 0.2620 - acc: 0.902 - ETA: 1:16 - loss: 0.2612 - acc: 0.902 - ETA: 1:16 - loss: 0.2606 - acc: 0.903 - ETA: 1:16 - loss: 0.2597 - acc: 0.903 - ETA: 1:15 - loss: 0.2583 - acc: 0.903 - ETA: 1:15 - loss: 0.2598 - acc: 0.902 - ETA: 1:14 - loss: 0.2594 - acc: 0.902 - ETA: 1:14 - loss: 0.2599 - acc: 0.902 - ETA: 1:14 - loss: 0.2595 - acc: 0.902 - ETA: 1:14 - loss: 0.2590 - acc: 0.902 - ETA: 1:14 - loss: 0.2606 - acc: 0.902 - ETA: 1:14 - loss: 0.2596 - acc: 0.902 - ETA: 1:13 - loss: 0.2600 - acc: 0.902 - ETA: 1:13 - loss: 0.2595 - acc: 0.902 - ETA: 1:13 - loss: 0.2590 - acc: 0.902 - ETA: 1:13 - loss: 0.2587 - acc: 0.902 - ETA: 1:12 - loss: 0.2584 - acc: 0.902 - ETA: 1:12 - loss: 0.2583 - acc: 0.902 - ETA: 1:12 - loss: 0.2579 - acc: 0.902 - ETA: 1:11 - loss: 0.2574 - acc: 0.902 - ETA: 1:11 - loss: 0.2561 - acc: 0.903 - ETA: 1:11 - loss: 0.2573 - acc: 0.903 - ETA: 1:10 - loss: 0.2578 - acc: 0.903 - ETA: 1:10 - loss: 0.2570 - acc: 0.903 - ETA: 1:10 - loss: 0.2568 - acc: 0.903 - ETA: 1:10 - loss: 0.2579 - acc: 0.903 - ETA: 1:09 - loss: 0.2575 - acc: 0.903 - ETA: 1:09 - loss: 0.2572 - acc: 0.903 - ETA: 1:09 - loss: 0.2585 - acc: 0.902 - ETA: 1:09 - loss: 0.2591 - acc: 0.902 - ETA: 1:09 - loss: 0.2595 - acc: 0.902 - ETA: 1:08 - loss: 0.2583 - acc: 0.902 - ETA: 1:08 - loss: 0.2577 - acc: 0.903 - ETA: 1:08 - loss: 0.2603 - acc: 0.902 - ETA: 1:07 - loss: 0.2600 - acc: 0.902 - ETA: 1:07 - loss: 0.2592 - acc: 0.902 - ETA: 1:07 - loss: 0.2587 - acc: 0.903 - ETA: 1:07 - loss: 0.2581 - acc: 0.903 - ETA: 1:07 - loss: 0.2576 - acc: 0.903 - ETA: 1:07 - loss: 0.2568 - acc: 0.904 - ETA: 1:06 - loss: 0.2559 - acc: 0.904 - ETA: 1:06 - loss: 0.2571 - acc: 0.904 - ETA: 1:06 - loss: 0.2575 - acc: 0.903 - ETA: 1:06 - loss: 0.2584 - acc: 0.903 - ETA: 1:05 - loss: 0.2581 - acc: 0.903 - ETA: 1:05 - loss: 0.2593 - acc: 0.903 - ETA: 1:05 - loss: 0.2607 - acc: 0.903 - ETA: 1:05 - loss: 0.2609 - acc: 0.903 - ETA: 1:05 - loss: 0.2602 - acc: 0.903 - ETA: 1:04 - loss: 0.2599 - acc: 0.903 - ETA: 1:04 - loss: 0.2611 - acc: 0.903 - ETA: 1:04 - loss: 0.2602 - acc: 0.903 - ETA: 1:04 - loss: 0.2595 - acc: 0.903 - ETA: 1:04 - loss: 0.2617 - acc: 0.902 - ETA: 1:03 - loss: 0.2610 - acc: 0.903 - ETA: 1:03 - loss: 0.2613 - acc: 0.903 - ETA: 1:03 - loss: 0.2624 - acc: 0.902 - ETA: 1:03 - loss: 0.2626 - acc: 0.902 - ETA: 1:03 - loss: 0.2627 - acc: 0.902 - ETA: 1:02 - loss: 0.2627 - acc: 0.902 - ETA: 1:02 - loss: 0.2626 - acc: 0.902 - ETA: 1:02 - loss: 0.2628 - acc: 0.901 - ETA: 1:01 - loss: 0.2623 - acc: 0.902 - ETA: 1:01 - loss: 0.2628 - acc: 0.902 - ETA: 1:01 - loss: 0.2625 - acc: 0.902 - ETA: 1:00 - loss: 0.2615 - acc: 0.902 - ETA: 1:00 - loss: 0.2612 - acc: 0.902 - ETA: 1:00 - loss: 0.2613 - acc: 0.902 - ETA: 1:00 - loss: 0.2627 - acc: 0.902 - ETA: 59s - loss: 0.2634 - acc: 0.902 - ETA: 59s - loss: 0.2636 - acc: 0.90 - ETA: 59s - loss: 0.2640 - acc: 0.90 - ETA: 59s - loss: 0.2634 - acc: 0.90 - ETA: 58s - loss: 0.2626 - acc: 0.90 - ETA: 58s - loss: 0.2621 - acc: 0.90 - ETA: 58s - loss: 0.2619 - acc: 0.90 - ETA: 58s - loss: 0.2614 - acc: 0.90 - ETA: 57s - loss: 0.2605 - acc: 0.90 - ETA: 57s - loss: 0.2615 - acc: 0.90 - ETA: 57s - loss: 0.2607 - acc: 0.90 - ETA: 57s - loss: 0.2602 - acc: 0.90 - ETA: 57s - loss: 0.2616 - acc: 0.90 - ETA: 56s - loss: 0.2608 - acc: 0.90 - ETA: 56s - loss: 0.2615 - acc: 0.90 - ETA: 56s - loss: 0.2628 - acc: 0.90 - ETA: 56s - loss: 0.2623 - acc: 0.9033420/427 [============================>.] - ETA: 56s - loss: 0.2613 - acc: 0.90 - ETA: 55s - loss: 0.2615 - acc: 0.90 - ETA: 55s - loss: 0.2615 - acc: 0.90 - ETA: 55s - loss: 0.2618 - acc: 0.90 - ETA: 54s - loss: 0.2614 - acc: 0.90 - ETA: 54s - loss: 0.2608 - acc: 0.90 - ETA: 54s - loss: 0.2605 - acc: 0.90 - ETA: 54s - loss: 0.2608 - acc: 0.90 - ETA: 53s - loss: 0.2612 - acc: 0.90 - ETA: 53s - loss: 0.2605 - acc: 0.90 - ETA: 53s - loss: 0.2599 - acc: 0.90 - ETA: 53s - loss: 0.2589 - acc: 0.90 - ETA: 53s - loss: 0.2595 - acc: 0.90 - ETA: 52s - loss: 0.2598 - acc: 0.90 - ETA: 52s - loss: 0.2604 - acc: 0.90 - ETA: 52s - loss: 0.2598 - acc: 0.90 - ETA: 51s - loss: 0.2601 - acc: 0.90 - ETA: 51s - loss: 0.2603 - acc: 0.90 - ETA: 51s - loss: 0.2603 - acc: 0.90 - ETA: 51s - loss: 0.2603 - acc: 0.90 - ETA: 51s - loss: 0.2613 - acc: 0.90 - ETA: 50s - loss: 0.2614 - acc: 0.90 - ETA: 50s - loss: 0.2616 - acc: 0.90 - ETA: 50s - loss: 0.2615 - acc: 0.90 - ETA: 50s - loss: 0.2610 - acc: 0.90 - ETA: 49s - loss: 0.2609 - acc: 0.90 - ETA: 49s - loss: 0.2609 - acc: 0.90 - ETA: 49s - loss: 0.2607 - acc: 0.90 - ETA: 49s - loss: 0.2607 - acc: 0.90 - ETA: 48s - loss: 0.2601 - acc: 0.90 - ETA: 48s - loss: 0.2598 - acc: 0.90 - ETA: 48s - loss: 0.2599 - acc: 0.90 - ETA: 48s - loss: 0.2597 - acc: 0.90 - ETA: 47s - loss: 0.2597 - acc: 0.90 - ETA: 47s - loss: 0.2590 - acc: 0.90 - ETA: 47s - loss: 0.2588 - acc: 0.90 - ETA: 47s - loss: 0.2587 - acc: 0.90 - ETA: 47s - loss: 0.2581 - acc: 0.90 - ETA: 46s - loss: 0.2594 - acc: 0.90 - ETA: 46s - loss: 0.2588 - acc: 0.90 - ETA: 46s - loss: 0.2590 - acc: 0.90 - ETA: 46s - loss: 0.2590 - acc: 0.90 - ETA: 45s - loss: 0.2584 - acc: 0.90 - ETA: 45s - loss: 0.2578 - acc: 0.90 - ETA: 45s - loss: 0.2583 - acc: 0.90 - ETA: 45s - loss: 0.2585 - acc: 0.90 - ETA: 44s - loss: 0.2579 - acc: 0.90 - ETA: 44s - loss: 0.2583 - acc: 0.90 - ETA: 44s - loss: 0.2589 - acc: 0.90 - ETA: 44s - loss: 0.2587 - acc: 0.90 - ETA: 44s - loss: 0.2586 - acc: 0.90 - ETA: 43s - loss: 0.2586 - acc: 0.90 - ETA: 43s - loss: 0.2583 - acc: 0.90 - ETA: 43s - loss: 0.2586 - acc: 0.90 - ETA: 42s - loss: 0.2586 - acc: 0.90 - ETA: 42s - loss: 0.2596 - acc: 0.90 - ETA: 42s - loss: 0.2599 - acc: 0.90 - ETA: 42s - loss: 0.2597 - acc: 0.90 - ETA: 41s - loss: 0.2602 - acc: 0.90 - ETA: 41s - loss: 0.2598 - acc: 0.90 - ETA: 41s - loss: 0.2601 - acc: 0.90 - ETA: 41s - loss: 0.2600 - acc: 0.90 - ETA: 41s - loss: 0.2605 - acc: 0.90 - ETA: 40s - loss: 0.2606 - acc: 0.90 - ETA: 40s - loss: 0.2612 - acc: 0.90 - ETA: 40s - loss: 0.2610 - acc: 0.90 - ETA: 40s - loss: 0.2604 - acc: 0.90 - ETA: 39s - loss: 0.2610 - acc: 0.90 - ETA: 39s - loss: 0.2604 - acc: 0.90 - ETA: 39s - loss: 0.2604 - acc: 0.90 - ETA: 39s - loss: 0.2605 - acc: 0.90 - ETA: 38s - loss: 0.2601 - acc: 0.90 - ETA: 38s - loss: 0.2595 - acc: 0.90 - ETA: 38s - loss: 0.2589 - acc: 0.90 - ETA: 37s - loss: 0.2586 - acc: 0.90 - ETA: 37s - loss: 0.2584 - acc: 0.90 - ETA: 37s - loss: 0.2580 - acc: 0.90 - ETA: 37s - loss: 0.2574 - acc: 0.90 - ETA: 37s - loss: 0.2569 - acc: 0.90 - ETA: 36s - loss: 0.2569 - acc: 0.90 - ETA: 36s - loss: 0.2570 - acc: 0.90 - ETA: 36s - loss: 0.2568 - acc: 0.90 - ETA: 35s - loss: 0.2565 - acc: 0.90 - ETA: 35s - loss: 0.2566 - acc: 0.90 - ETA: 35s - loss: 0.2565 - acc: 0.90 - ETA: 35s - loss: 0.2559 - acc: 0.90 - ETA: 34s - loss: 0.2563 - acc: 0.90 - ETA: 34s - loss: 0.2559 - acc: 0.90 - ETA: 34s - loss: 0.2561 - acc: 0.90 - ETA: 34s - loss: 0.2559 - acc: 0.90 - ETA: 33s - loss: 0.2565 - acc: 0.90 - ETA: 33s - loss: 0.2565 - acc: 0.90 - ETA: 33s - loss: 0.2562 - acc: 0.90 - ETA: 33s - loss: 0.2569 - acc: 0.90 - ETA: 32s - loss: 0.2584 - acc: 0.90 - ETA: 32s - loss: 0.2582 - acc: 0.90 - ETA: 32s - loss: 0.2577 - acc: 0.90 - ETA: 32s - loss: 0.2582 - acc: 0.90 - ETA: 31s - loss: 0.2580 - acc: 0.90 - ETA: 31s - loss: 0.2580 - acc: 0.90 - ETA: 31s - loss: 0.2575 - acc: 0.90 - ETA: 31s - loss: 0.2579 - acc: 0.90 - ETA: 30s - loss: 0.2575 - acc: 0.90 - ETA: 30s - loss: 0.2584 - acc: 0.90 - ETA: 30s - loss: 0.2578 - acc: 0.90 - ETA: 29s - loss: 0.2578 - acc: 0.90 - ETA: 29s - loss: 0.2583 - acc: 0.90 - ETA: 29s - loss: 0.2580 - acc: 0.90 - ETA: 29s - loss: 0.2585 - acc: 0.90 - ETA: 28s - loss: 0.2585 - acc: 0.90 - ETA: 28s - loss: 0.2584 - acc: 0.90 - ETA: 28s - loss: 0.2594 - acc: 0.90 - ETA: 28s - loss: 0.2599 - acc: 0.90 - ETA: 27s - loss: 0.2600 - acc: 0.90 - ETA: 27s - loss: 0.2602 - acc: 0.90 - ETA: 27s - loss: 0.2597 - acc: 0.90 - ETA: 27s - loss: 0.2594 - acc: 0.90 - ETA: 26s - loss: 0.2596 - acc: 0.90 - ETA: 26s - loss: 0.2593 - acc: 0.90 - ETA: 26s - loss: 0.2590 - acc: 0.90 - ETA: 26s - loss: 0.2594 - acc: 0.90 - ETA: 25s - loss: 0.2596 - acc: 0.90 - ETA: 25s - loss: 0.2598 - acc: 0.90 - ETA: 25s - loss: 0.2594 - acc: 0.90 - ETA: 25s - loss: 0.2595 - acc: 0.90 - ETA: 24s - loss: 0.2593 - acc: 0.90 - ETA: 24s - loss: 0.2590 - acc: 0.90 - ETA: 24s - loss: 0.2592 - acc: 0.90 - ETA: 24s - loss: 0.2589 - acc: 0.90 - ETA: 23s - loss: 0.2594 - acc: 0.90 - ETA: 23s - loss: 0.2601 - acc: 0.90 - ETA: 23s - loss: 0.2597 - acc: 0.90 - ETA: 23s - loss: 0.2595 - acc: 0.90 - ETA: 22s - loss: 0.2599 - acc: 0.90 - ETA: 22s - loss: 0.2599 - acc: 0.90 - ETA: 22s - loss: 0.2596 - acc: 0.90 - ETA: 22s - loss: 0.2593 - acc: 0.90 - ETA: 21s - loss: 0.2590 - acc: 0.90 - ETA: 21s - loss: 0.2587 - acc: 0.90 - ETA: 21s - loss: 0.2583 - acc: 0.90 - ETA: 21s - loss: 0.2580 - acc: 0.90 - ETA: 20s - loss: 0.2577 - acc: 0.90 - ETA: 20s - loss: 0.2576 - acc: 0.90 - ETA: 20s - loss: 0.2583 - acc: 0.90 - ETA: 19s - loss: 0.2585 - acc: 0.90 - ETA: 19s - loss: 0.2589 - acc: 0.90 - ETA: 19s - loss: 0.2593 - acc: 0.90 - ETA: 19s - loss: 0.2591 - acc: 0.90 - ETA: 18s - loss: 0.2590 - acc: 0.90 - ETA: 18s - loss: 0.2589 - acc: 0.90 - ETA: 18s - loss: 0.2590 - acc: 0.90 - ETA: 18s - loss: 0.2596 - acc: 0.90 - ETA: 17s - loss: 0.2596 - acc: 0.90 - ETA: 17s - loss: 0.2592 - acc: 0.90 - ETA: 17s - loss: 0.2600 - acc: 0.90 - ETA: 17s - loss: 0.2597 - acc: 0.90 - ETA: 16s - loss: 0.2595 - acc: 0.90 - ETA: 16s - loss: 0.2591 - acc: 0.90 - ETA: 16s - loss: 0.2587 - acc: 0.90 - ETA: 16s - loss: 0.2585 - acc: 0.90 - ETA: 15s - loss: 0.2583 - acc: 0.90 - ETA: 15s - loss: 0.2582 - acc: 0.90 - ETA: 15s - loss: 0.2580 - acc: 0.90 - ETA: 15s - loss: 0.2580 - acc: 0.90 - ETA: 14s - loss: 0.2578 - acc: 0.90 - ETA: 14s - loss: 0.2580 - acc: 0.90 - ETA: 14s - loss: 0.2580 - acc: 0.90 - ETA: 13s - loss: 0.2579 - acc: 0.90 - ETA: 13s - loss: 0.2576 - acc: 0.90 - ETA: 13s - loss: 0.2575 - acc: 0.90 - ETA: 13s - loss: 0.2574 - acc: 0.90 - ETA: 12s - loss: 0.2576 - acc: 0.90 - ETA: 12s - loss: 0.2572 - acc: 0.90 - ETA: 12s - loss: 0.2570 - acc: 0.90 - ETA: 12s - loss: 0.2568 - acc: 0.90 - ETA: 11s - loss: 0.2569 - acc: 0.90 - ETA: 11s - loss: 0.2568 - acc: 0.90 - ETA: 11s - loss: 0.2566 - acc: 0.90 - ETA: 11s - loss: 0.2571 - acc: 0.90 - ETA: 10s - loss: 0.2573 - acc: 0.90 - ETA: 10s - loss: 0.2575 - acc: 0.90 - ETA: 10s - loss: 0.2576 - acc: 0.90 - ETA: 10s - loss: 0.2578 - acc: 0.90 - ETA: 9s - loss: 0.2578 - acc: 0.9051 - ETA: 9s - loss: 0.2583 - acc: 0.904 - ETA: 9s - loss: 0.2584 - acc: 0.904 - ETA: 9s - loss: 0.2581 - acc: 0.904 - ETA: 8s - loss: 0.2578 - acc: 0.905 - ETA: 8s - loss: 0.2585 - acc: 0.904 - ETA: 8s - loss: 0.2581 - acc: 0.905 - ETA: 8s - loss: 0.2578 - acc: 0.905 - ETA: 7s - loss: 0.2575 - acc: 0.905 - ETA: 7s - loss: 0.2573 - acc: 0.905 - ETA: 7s - loss: 0.2574 - acc: 0.905 - ETA: 7s - loss: 0.2576 - acc: 0.905 - ETA: 6s - loss: 0.2575 - acc: 0.905 - ETA: 6s - loss: 0.2576 - acc: 0.905 - ETA: 6s - loss: 0.2577 - acc: 0.905 - ETA: 5s - loss: 0.2580 - acc: 0.905 - ETA: 5s - loss: 0.2578 - acc: 0.905 - ETA: 5s - loss: 0.2578 - acc: 0.905 - ETA: 5s - loss: 0.2576 - acc: 0.905 - ETA: 4s - loss: 0.2573 - acc: 0.906 - ETA: 4s - loss: 0.2579 - acc: 0.905 - ETA: 4s - loss: 0.2578 - acc: 0.905 - ETA: 4s - loss: 0.2585 - acc: 0.905 - ETA: 3s - loss: 0.2587 - acc: 0.905 - ETA: 3s - loss: 0.2585 - acc: 0.905 - ETA: 3s - loss: 0.2581 - acc: 0.905 - ETA: 3s - loss: 0.2585 - acc: 0.905 - ETA: 2s - loss: 0.2585 - acc: 0.905 - ETA: 2s - loss: 0.2586 - acc: 0.905 - ETA: 2s - loss: 0.2592 - acc: 0.905 - ETA: 2s - loss: 0.2591 - acc: 0.904 - ETA: 1s - loss: 0.2590 - acc: 0.9048"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/427 [============================>.] - ETA: 1s - loss: 0.2592 - acc: 0.904 - ETA: 1s - loss: 0.2596 - acc: 0.904 - ETA: 1s - loss: 0.2595 - acc: 0.904 - ETA: 0s - loss: 0.2596 - acc: 0.904 - ETA: 0s - loss: 0.2596 - acc: 0.904 - ETA: 0s - loss: 0.2594 - acc: 0.9048\n",
      "Epoch 00004: val_loss improved from 0.42865 to 0.40438, saving model to saved_models/weights.aug.best.hdf5\n",
      "427/427 [==============================] - 112s 263ms/step - loss: 0.2593 - acc: 0.9049 - val_loss: 0.4044 - val_acc: 0.8405\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:46 - loss: 0.3700 - acc: 0.800 - ETA: 1:54 - loss: 0.2491 - acc: 0.900 - ETA: 1:30 - loss: 0.3360 - acc: 0.885 - ETA: 1:34 - loss: 0.3150 - acc: 0.889 - ETA: 1:36 - loss: 0.2889 - acc: 0.891 - ETA: 1:37 - loss: 0.3205 - acc: 0.876 - ETA: 1:37 - loss: 0.2913 - acc: 0.893 - ETA: 1:42 - loss: 0.2657 - acc: 0.907 - ETA: 1:43 - loss: 0.2668 - acc: 0.900 - ETA: 1:36 - loss: 0.2473 - acc: 0.910 - ETA: 1:37 - loss: 0.2363 - acc: 0.914 - ETA: 1:38 - loss: 0.2490 - acc: 0.913 - ETA: 1:38 - loss: 0.2619 - acc: 0.908 - ETA: 1:38 - loss: 0.2629 - acc: 0.904 - ETA: 1:39 - loss: 0.2660 - acc: 0.900 - ETA: 1:39 - loss: 0.2663 - acc: 0.900 - ETA: 1:39 - loss: 0.2573 - acc: 0.906 - ETA: 1:40 - loss: 0.2570 - acc: 0.908 - ETA: 1:40 - loss: 0.2520 - acc: 0.910 - ETA: 1:41 - loss: 0.2549 - acc: 0.907 - ETA: 1:41 - loss: 0.2553 - acc: 0.909 - ETA: 1:42 - loss: 0.2665 - acc: 0.902 - ETA: 1:43 - loss: 0.2623 - acc: 0.902 - ETA: 1:43 - loss: 0.2618 - acc: 0.904 - ETA: 1:43 - loss: 0.2691 - acc: 0.902 - ETA: 1:43 - loss: 0.2754 - acc: 0.900 - ETA: 1:43 - loss: 0.2738 - acc: 0.902 - ETA: 1:42 - loss: 0.2815 - acc: 0.900 - ETA: 1:42 - loss: 0.2808 - acc: 0.898 - ETA: 1:42 - loss: 0.2763 - acc: 0.898 - ETA: 1:43 - loss: 0.2752 - acc: 0.897 - ETA: 1:43 - loss: 0.2719 - acc: 0.898 - ETA: 1:43 - loss: 0.2661 - acc: 0.901 - ETA: 1:42 - loss: 0.2611 - acc: 0.904 - ETA: 1:42 - loss: 0.2634 - acc: 0.904 - ETA: 1:42 - loss: 0.2594 - acc: 0.907 - ETA: 1:41 - loss: 0.2628 - acc: 0.905 - ETA: 1:41 - loss: 0.2607 - acc: 0.906 - ETA: 1:41 - loss: 0.2594 - acc: 0.907 - ETA: 1:40 - loss: 0.2610 - acc: 0.907 - ETA: 1:40 - loss: 0.2632 - acc: 0.907 - ETA: 1:40 - loss: 0.2604 - acc: 0.909 - ETA: 1:39 - loss: 0.2578 - acc: 0.911 - ETA: 1:39 - loss: 0.2619 - acc: 0.910 - ETA: 1:39 - loss: 0.2607 - acc: 0.910 - ETA: 1:39 - loss: 0.2671 - acc: 0.907 - ETA: 1:39 - loss: 0.2659 - acc: 0.908 - ETA: 1:37 - loss: 0.2848 - acc: 0.901 - ETA: 1:37 - loss: 0.2807 - acc: 0.902 - ETA: 1:37 - loss: 0.2805 - acc: 0.901 - ETA: 1:36 - loss: 0.2763 - acc: 0.903 - ETA: 1:36 - loss: 0.2783 - acc: 0.902 - ETA: 1:36 - loss: 0.2778 - acc: 0.902 - ETA: 1:36 - loss: 0.2849 - acc: 0.899 - ETA: 1:35 - loss: 0.2834 - acc: 0.900 - ETA: 1:35 - loss: 0.2807 - acc: 0.901 - ETA: 1:35 - loss: 0.2783 - acc: 0.901 - ETA: 1:35 - loss: 0.2781 - acc: 0.901 - ETA: 1:34 - loss: 0.2764 - acc: 0.902 - ETA: 1:33 - loss: 0.2752 - acc: 0.903 - ETA: 1:33 - loss: 0.2754 - acc: 0.902 - ETA: 1:33 - loss: 0.2777 - acc: 0.900 - ETA: 1:32 - loss: 0.2766 - acc: 0.901 - ETA: 1:32 - loss: 0.2782 - acc: 0.900 - ETA: 1:32 - loss: 0.2773 - acc: 0.900 - ETA: 1:32 - loss: 0.2781 - acc: 0.899 - ETA: 1:31 - loss: 0.2783 - acc: 0.899 - ETA: 1:31 - loss: 0.2771 - acc: 0.899 - ETA: 1:31 - loss: 0.2803 - acc: 0.898 - ETA: 1:31 - loss: 0.2813 - acc: 0.897 - ETA: 1:31 - loss: 0.2794 - acc: 0.898 - ETA: 1:31 - loss: 0.2796 - acc: 0.897 - ETA: 1:30 - loss: 0.2780 - acc: 0.898 - ETA: 1:30 - loss: 0.2783 - acc: 0.897 - ETA: 1:30 - loss: 0.2762 - acc: 0.898 - ETA: 1:30 - loss: 0.2745 - acc: 0.899 - ETA: 1:29 - loss: 0.2741 - acc: 0.899 - ETA: 1:29 - loss: 0.2763 - acc: 0.898 - ETA: 1:28 - loss: 0.2745 - acc: 0.899 - ETA: 1:28 - loss: 0.2743 - acc: 0.900 - ETA: 1:28 - loss: 0.2742 - acc: 0.899 - ETA: 1:28 - loss: 0.2721 - acc: 0.901 - ETA: 1:28 - loss: 0.2732 - acc: 0.901 - ETA: 1:28 - loss: 0.2718 - acc: 0.901 - ETA: 1:27 - loss: 0.2696 - acc: 0.902 - ETA: 1:27 - loss: 0.2684 - acc: 0.903 - ETA: 1:27 - loss: 0.2711 - acc: 0.902 - ETA: 1:27 - loss: 0.2698 - acc: 0.902 - ETA: 1:27 - loss: 0.2702 - acc: 0.901 - ETA: 1:26 - loss: 0.2694 - acc: 0.902 - ETA: 1:26 - loss: 0.2707 - acc: 0.901 - ETA: 1:26 - loss: 0.2705 - acc: 0.902 - ETA: 1:26 - loss: 0.2721 - acc: 0.902 - ETA: 1:26 - loss: 0.2700 - acc: 0.903 - ETA: 1:26 - loss: 0.2696 - acc: 0.903 - ETA: 1:25 - loss: 0.2708 - acc: 0.903 - ETA: 1:25 - loss: 0.2710 - acc: 0.902 - ETA: 1:24 - loss: 0.2706 - acc: 0.903 - ETA: 1:24 - loss: 0.2703 - acc: 0.903 - ETA: 1:24 - loss: 0.2689 - acc: 0.904 - ETA: 1:24 - loss: 0.2700 - acc: 0.904 - ETA: 1:23 - loss: 0.2694 - acc: 0.904 - ETA: 1:23 - loss: 0.2679 - acc: 0.905 - ETA: 1:23 - loss: 0.2681 - acc: 0.904 - ETA: 1:23 - loss: 0.2677 - acc: 0.904 - ETA: 1:22 - loss: 0.2662 - acc: 0.905 - ETA: 1:22 - loss: 0.2656 - acc: 0.905 - ETA: 1:22 - loss: 0.2654 - acc: 0.905 - ETA: 1:21 - loss: 0.2642 - acc: 0.906 - ETA: 1:21 - loss: 0.2624 - acc: 0.907 - ETA: 1:21 - loss: 0.2629 - acc: 0.906 - ETA: 1:21 - loss: 0.2635 - acc: 0.906 - ETA: 1:20 - loss: 0.2630 - acc: 0.907 - ETA: 1:20 - loss: 0.2632 - acc: 0.907 - ETA: 1:20 - loss: 0.2628 - acc: 0.907 - ETA: 1:20 - loss: 0.2617 - acc: 0.908 - ETA: 1:19 - loss: 0.2613 - acc: 0.908 - ETA: 1:19 - loss: 0.2600 - acc: 0.908 - ETA: 1:19 - loss: 0.2593 - acc: 0.908 - ETA: 1:19 - loss: 0.2586 - acc: 0.909 - ETA: 1:18 - loss: 0.2576 - acc: 0.909 - ETA: 1:18 - loss: 0.2567 - acc: 0.910 - ETA: 1:18 - loss: 0.2563 - acc: 0.910 - ETA: 1:18 - loss: 0.2567 - acc: 0.910 - ETA: 1:17 - loss: 0.2588 - acc: 0.909 - ETA: 1:17 - loss: 0.2583 - acc: 0.909 - ETA: 1:17 - loss: 0.2575 - acc: 0.909 - ETA: 1:16 - loss: 0.2565 - acc: 0.910 - ETA: 1:16 - loss: 0.2558 - acc: 0.910 - ETA: 1:16 - loss: 0.2560 - acc: 0.910 - ETA: 1:15 - loss: 0.2558 - acc: 0.910 - ETA: 1:15 - loss: 0.2564 - acc: 0.909 - ETA: 1:15 - loss: 0.2578 - acc: 0.909 - ETA: 1:15 - loss: 0.2582 - acc: 0.908 - ETA: 1:14 - loss: 0.2592 - acc: 0.908 - ETA: 1:14 - loss: 0.2584 - acc: 0.908 - ETA: 1:14 - loss: 0.2575 - acc: 0.909 - ETA: 1:14 - loss: 0.2581 - acc: 0.909 - ETA: 1:13 - loss: 0.2586 - acc: 0.908 - ETA: 1:13 - loss: 0.2577 - acc: 0.909 - ETA: 1:13 - loss: 0.2573 - acc: 0.909 - ETA: 1:13 - loss: 0.2568 - acc: 0.909 - ETA: 1:13 - loss: 0.2572 - acc: 0.909 - ETA: 1:13 - loss: 0.2581 - acc: 0.908 - ETA: 1:12 - loss: 0.2580 - acc: 0.908 - ETA: 1:12 - loss: 0.2568 - acc: 0.908 - ETA: 1:12 - loss: 0.2575 - acc: 0.908 - ETA: 1:12 - loss: 0.2568 - acc: 0.908 - ETA: 1:11 - loss: 0.2574 - acc: 0.908 - ETA: 1:11 - loss: 0.2569 - acc: 0.908 - ETA: 1:11 - loss: 0.2567 - acc: 0.909 - ETA: 1:11 - loss: 0.2574 - acc: 0.908 - ETA: 1:10 - loss: 0.2577 - acc: 0.908 - ETA: 1:10 - loss: 0.2570 - acc: 0.908 - ETA: 1:10 - loss: 0.2562 - acc: 0.908 - ETA: 1:10 - loss: 0.2550 - acc: 0.909 - ETA: 1:09 - loss: 0.2546 - acc: 0.909 - ETA: 1:09 - loss: 0.2537 - acc: 0.910 - ETA: 1:09 - loss: 0.2547 - acc: 0.909 - ETA: 1:08 - loss: 0.2553 - acc: 0.909 - ETA: 1:08 - loss: 0.2566 - acc: 0.908 - ETA: 1:08 - loss: 0.2558 - acc: 0.909 - ETA: 1:08 - loss: 0.2569 - acc: 0.908 - ETA: 1:08 - loss: 0.2580 - acc: 0.908 - ETA: 1:07 - loss: 0.2581 - acc: 0.908 - ETA: 1:07 - loss: 0.2578 - acc: 0.908 - ETA: 1:07 - loss: 0.2573 - acc: 0.908 - ETA: 1:07 - loss: 0.2563 - acc: 0.908 - ETA: 1:06 - loss: 0.2567 - acc: 0.908 - ETA: 1:06 - loss: 0.2557 - acc: 0.909 - ETA: 1:06 - loss: 0.2569 - acc: 0.908 - ETA: 1:06 - loss: 0.2567 - acc: 0.908 - ETA: 1:05 - loss: 0.2569 - acc: 0.908 - ETA: 1:05 - loss: 0.2577 - acc: 0.908 - ETA: 1:05 - loss: 0.2587 - acc: 0.908 - ETA: 1:04 - loss: 0.2586 - acc: 0.907 - ETA: 1:04 - loss: 0.2581 - acc: 0.907 - ETA: 1:04 - loss: 0.2590 - acc: 0.907 - ETA: 1:03 - loss: 0.2596 - acc: 0.906 - ETA: 1:03 - loss: 0.2590 - acc: 0.907 - ETA: 1:03 - loss: 0.2583 - acc: 0.907 - ETA: 1:03 - loss: 0.2585 - acc: 0.907 - ETA: 1:02 - loss: 0.2585 - acc: 0.907 - ETA: 1:02 - loss: 0.2578 - acc: 0.907 - ETA: 1:02 - loss: 0.2584 - acc: 0.907 - ETA: 1:02 - loss: 0.2589 - acc: 0.907 - ETA: 1:01 - loss: 0.2582 - acc: 0.908 - ETA: 1:01 - loss: 0.2593 - acc: 0.907 - ETA: 1:01 - loss: 0.2609 - acc: 0.907 - ETA: 1:01 - loss: 0.2609 - acc: 0.906 - ETA: 1:00 - loss: 0.2599 - acc: 0.907 - ETA: 1:00 - loss: 0.2603 - acc: 0.907 - ETA: 1:00 - loss: 0.2610 - acc: 0.907 - ETA: 1:00 - loss: 0.2613 - acc: 0.906 - ETA: 59s - loss: 0.2608 - acc: 0.907 - ETA: 59s - loss: 0.2600 - acc: 0.90 - ETA: 59s - loss: 0.2594 - acc: 0.90 - ETA: 59s - loss: 0.2591 - acc: 0.90 - ETA: 58s - loss: 0.2594 - acc: 0.90 - ETA: 58s - loss: 0.2589 - acc: 0.90 - ETA: 58s - loss: 0.2592 - acc: 0.90 - ETA: 57s - loss: 0.2583 - acc: 0.90 - ETA: 57s - loss: 0.2576 - acc: 0.90 - ETA: 57s - loss: 0.2574 - acc: 0.90 - ETA: 57s - loss: 0.2568 - acc: 0.9097420/427 [============================>.] - ETA: 56s - loss: 0.2568 - acc: 0.90 - ETA: 56s - loss: 0.2569 - acc: 0.90 - ETA: 56s - loss: 0.2568 - acc: 0.90 - ETA: 56s - loss: 0.2564 - acc: 0.90 - ETA: 56s - loss: 0.2573 - acc: 0.90 - ETA: 55s - loss: 0.2566 - acc: 0.90 - ETA: 55s - loss: 0.2561 - acc: 0.90 - ETA: 55s - loss: 0.2567 - acc: 0.90 - ETA: 54s - loss: 0.2556 - acc: 0.90 - ETA: 54s - loss: 0.2548 - acc: 0.90 - ETA: 54s - loss: 0.2547 - acc: 0.90 - ETA: 54s - loss: 0.2541 - acc: 0.90 - ETA: 53s - loss: 0.2549 - acc: 0.90 - ETA: 53s - loss: 0.2544 - acc: 0.90 - ETA: 53s - loss: 0.2545 - acc: 0.90 - ETA: 53s - loss: 0.2546 - acc: 0.90 - ETA: 52s - loss: 0.2545 - acc: 0.90 - ETA: 52s - loss: 0.2537 - acc: 0.90 - ETA: 52s - loss: 0.2536 - acc: 0.90 - ETA: 52s - loss: 0.2534 - acc: 0.90 - ETA: 51s - loss: 0.2531 - acc: 0.90 - ETA: 51s - loss: 0.2529 - acc: 0.90 - ETA: 51s - loss: 0.2529 - acc: 0.90 - ETA: 51s - loss: 0.2525 - acc: 0.90 - ETA: 50s - loss: 0.2521 - acc: 0.90 - ETA: 50s - loss: 0.2533 - acc: 0.90 - ETA: 50s - loss: 0.2534 - acc: 0.90 - ETA: 50s - loss: 0.2534 - acc: 0.90 - ETA: 49s - loss: 0.2533 - acc: 0.90 - ETA: 49s - loss: 0.2532 - acc: 0.90 - ETA: 49s - loss: 0.2533 - acc: 0.90 - ETA: 49s - loss: 0.2529 - acc: 0.91 - ETA: 48s - loss: 0.2535 - acc: 0.90 - ETA: 48s - loss: 0.2529 - acc: 0.91 - ETA: 48s - loss: 0.2528 - acc: 0.91 - ETA: 47s - loss: 0.2529 - acc: 0.90 - ETA: 47s - loss: 0.2524 - acc: 0.91 - ETA: 47s - loss: 0.2521 - acc: 0.91 - ETA: 47s - loss: 0.2513 - acc: 0.91 - ETA: 46s - loss: 0.2516 - acc: 0.91 - ETA: 46s - loss: 0.2516 - acc: 0.91 - ETA: 46s - loss: 0.2516 - acc: 0.91 - ETA: 46s - loss: 0.2509 - acc: 0.91 - ETA: 45s - loss: 0.2503 - acc: 0.91 - ETA: 45s - loss: 0.2505 - acc: 0.91 - ETA: 45s - loss: 0.2501 - acc: 0.91 - ETA: 44s - loss: 0.2504 - acc: 0.91 - ETA: 44s - loss: 0.2510 - acc: 0.90 - ETA: 44s - loss: 0.2510 - acc: 0.90 - ETA: 44s - loss: 0.2511 - acc: 0.90 - ETA: 43s - loss: 0.2509 - acc: 0.90 - ETA: 43s - loss: 0.2504 - acc: 0.90 - ETA: 43s - loss: 0.2500 - acc: 0.90 - ETA: 43s - loss: 0.2507 - acc: 0.90 - ETA: 42s - loss: 0.2503 - acc: 0.91 - ETA: 42s - loss: 0.2513 - acc: 0.90 - ETA: 42s - loss: 0.2516 - acc: 0.90 - ETA: 42s - loss: 0.2511 - acc: 0.90 - ETA: 41s - loss: 0.2508 - acc: 0.90 - ETA: 41s - loss: 0.2505 - acc: 0.90 - ETA: 41s - loss: 0.2500 - acc: 0.91 - ETA: 41s - loss: 0.2499 - acc: 0.91 - ETA: 40s - loss: 0.2499 - acc: 0.91 - ETA: 40s - loss: 0.2500 - acc: 0.91 - ETA: 40s - loss: 0.2495 - acc: 0.91 - ETA: 40s - loss: 0.2488 - acc: 0.91 - ETA: 39s - loss: 0.2488 - acc: 0.91 - ETA: 39s - loss: 0.2485 - acc: 0.91 - ETA: 39s - loss: 0.2486 - acc: 0.91 - ETA: 39s - loss: 0.2488 - acc: 0.91 - ETA: 38s - loss: 0.2483 - acc: 0.91 - ETA: 38s - loss: 0.2482 - acc: 0.91 - ETA: 38s - loss: 0.2478 - acc: 0.91 - ETA: 38s - loss: 0.2479 - acc: 0.91 - ETA: 37s - loss: 0.2484 - acc: 0.91 - ETA: 37s - loss: 0.2486 - acc: 0.91 - ETA: 37s - loss: 0.2485 - acc: 0.91 - ETA: 37s - loss: 0.2483 - acc: 0.91 - ETA: 36s - loss: 0.2477 - acc: 0.91 - ETA: 36s - loss: 0.2482 - acc: 0.91 - ETA: 36s - loss: 0.2486 - acc: 0.91 - ETA: 36s - loss: 0.2488 - acc: 0.91 - ETA: 35s - loss: 0.2485 - acc: 0.91 - ETA: 35s - loss: 0.2485 - acc: 0.91 - ETA: 35s - loss: 0.2486 - acc: 0.91 - ETA: 34s - loss: 0.2483 - acc: 0.91 - ETA: 34s - loss: 0.2484 - acc: 0.91 - ETA: 34s - loss: 0.2486 - acc: 0.91 - ETA: 34s - loss: 0.2483 - acc: 0.91 - ETA: 33s - loss: 0.2488 - acc: 0.91 - ETA: 33s - loss: 0.2502 - acc: 0.90 - ETA: 33s - loss: 0.2503 - acc: 0.90 - ETA: 33s - loss: 0.2498 - acc: 0.91 - ETA: 32s - loss: 0.2493 - acc: 0.91 - ETA: 32s - loss: 0.2498 - acc: 0.91 - ETA: 32s - loss: 0.2499 - acc: 0.91 - ETA: 32s - loss: 0.2493 - acc: 0.91 - ETA: 31s - loss: 0.2492 - acc: 0.91 - ETA: 31s - loss: 0.2500 - acc: 0.91 - ETA: 31s - loss: 0.2501 - acc: 0.91 - ETA: 31s - loss: 0.2503 - acc: 0.91 - ETA: 30s - loss: 0.2500 - acc: 0.91 - ETA: 30s - loss: 0.2495 - acc: 0.91 - ETA: 30s - loss: 0.2489 - acc: 0.91 - ETA: 30s - loss: 0.2485 - acc: 0.91 - ETA: 29s - loss: 0.2479 - acc: 0.91 - ETA: 29s - loss: 0.2482 - acc: 0.91 - ETA: 29s - loss: 0.2480 - acc: 0.91 - ETA: 28s - loss: 0.2475 - acc: 0.91 - ETA: 28s - loss: 0.2475 - acc: 0.91 - ETA: 28s - loss: 0.2473 - acc: 0.91 - ETA: 28s - loss: 0.2474 - acc: 0.91 - ETA: 27s - loss: 0.2469 - acc: 0.91 - ETA: 27s - loss: 0.2465 - acc: 0.91 - ETA: 27s - loss: 0.2460 - acc: 0.91 - ETA: 27s - loss: 0.2466 - acc: 0.91 - ETA: 26s - loss: 0.2467 - acc: 0.91 - ETA: 26s - loss: 0.2467 - acc: 0.91 - ETA: 26s - loss: 0.2466 - acc: 0.91 - ETA: 26s - loss: 0.2465 - acc: 0.91 - ETA: 25s - loss: 0.2471 - acc: 0.91 - ETA: 25s - loss: 0.2469 - acc: 0.91 - ETA: 25s - loss: 0.2471 - acc: 0.91 - ETA: 25s - loss: 0.2471 - acc: 0.91 - ETA: 24s - loss: 0.2469 - acc: 0.91 - ETA: 24s - loss: 0.2468 - acc: 0.91 - ETA: 24s - loss: 0.2474 - acc: 0.91 - ETA: 24s - loss: 0.2472 - acc: 0.91 - ETA: 23s - loss: 0.2471 - acc: 0.91 - ETA: 23s - loss: 0.2473 - acc: 0.91 - ETA: 23s - loss: 0.2486 - acc: 0.91 - ETA: 23s - loss: 0.2485 - acc: 0.91 - ETA: 22s - loss: 0.2480 - acc: 0.91 - ETA: 22s - loss: 0.2475 - acc: 0.91 - ETA: 22s - loss: 0.2475 - acc: 0.91 - ETA: 22s - loss: 0.2478 - acc: 0.91 - ETA: 21s - loss: 0.2477 - acc: 0.91 - ETA: 21s - loss: 0.2474 - acc: 0.91 - ETA: 21s - loss: 0.2469 - acc: 0.91 - ETA: 21s - loss: 0.2469 - acc: 0.91 - ETA: 20s - loss: 0.2475 - acc: 0.91 - ETA: 20s - loss: 0.2475 - acc: 0.91 - ETA: 20s - loss: 0.2474 - acc: 0.91 - ETA: 19s - loss: 0.2470 - acc: 0.91 - ETA: 19s - loss: 0.2467 - acc: 0.91 - ETA: 19s - loss: 0.2475 - acc: 0.91 - ETA: 19s - loss: 0.2480 - acc: 0.91 - ETA: 18s - loss: 0.2477 - acc: 0.91 - ETA: 18s - loss: 0.2477 - acc: 0.91 - ETA: 18s - loss: 0.2479 - acc: 0.91 - ETA: 18s - loss: 0.2478 - acc: 0.91 - ETA: 17s - loss: 0.2475 - acc: 0.91 - ETA: 17s - loss: 0.2474 - acc: 0.91 - ETA: 17s - loss: 0.2475 - acc: 0.91 - ETA: 17s - loss: 0.2472 - acc: 0.91 - ETA: 16s - loss: 0.2469 - acc: 0.91 - ETA: 16s - loss: 0.2464 - acc: 0.91 - ETA: 16s - loss: 0.2461 - acc: 0.91 - ETA: 16s - loss: 0.2462 - acc: 0.91 - ETA: 15s - loss: 0.2460 - acc: 0.91 - ETA: 15s - loss: 0.2457 - acc: 0.91 - ETA: 15s - loss: 0.2460 - acc: 0.91 - ETA: 15s - loss: 0.2457 - acc: 0.91 - ETA: 14s - loss: 0.2458 - acc: 0.91 - ETA: 14s - loss: 0.2457 - acc: 0.91 - ETA: 14s - loss: 0.2456 - acc: 0.91 - ETA: 14s - loss: 0.2454 - acc: 0.91 - ETA: 13s - loss: 0.2455 - acc: 0.91 - ETA: 13s - loss: 0.2456 - acc: 0.91 - ETA: 13s - loss: 0.2456 - acc: 0.91 - ETA: 13s - loss: 0.2458 - acc: 0.91 - ETA: 12s - loss: 0.2457 - acc: 0.91 - ETA: 12s - loss: 0.2458 - acc: 0.91 - ETA: 12s - loss: 0.2454 - acc: 0.91 - ETA: 12s - loss: 0.2450 - acc: 0.91 - ETA: 11s - loss: 0.2448 - acc: 0.91 - ETA: 11s - loss: 0.2446 - acc: 0.91 - ETA: 11s - loss: 0.2450 - acc: 0.91 - ETA: 11s - loss: 0.2448 - acc: 0.91 - ETA: 10s - loss: 0.2444 - acc: 0.91 - ETA: 10s - loss: 0.2439 - acc: 0.91 - ETA: 10s - loss: 0.2441 - acc: 0.91 - ETA: 9s - loss: 0.2444 - acc: 0.9114 - ETA: 9s - loss: 0.2448 - acc: 0.911 - ETA: 9s - loss: 0.2444 - acc: 0.911 - ETA: 9s - loss: 0.2442 - acc: 0.911 - ETA: 8s - loss: 0.2440 - acc: 0.911 - ETA: 8s - loss: 0.2441 - acc: 0.911 - ETA: 8s - loss: 0.2446 - acc: 0.911 - ETA: 8s - loss: 0.2451 - acc: 0.911 - ETA: 7s - loss: 0.2451 - acc: 0.911 - ETA: 7s - loss: 0.2457 - acc: 0.911 - ETA: 7s - loss: 0.2456 - acc: 0.910 - ETA: 7s - loss: 0.2459 - acc: 0.910 - ETA: 6s - loss: 0.2461 - acc: 0.910 - ETA: 6s - loss: 0.2465 - acc: 0.910 - ETA: 6s - loss: 0.2467 - acc: 0.910 - ETA: 6s - loss: 0.2465 - acc: 0.910 - ETA: 5s - loss: 0.2467 - acc: 0.909 - ETA: 5s - loss: 0.2467 - acc: 0.909 - ETA: 5s - loss: 0.2468 - acc: 0.909 - ETA: 5s - loss: 0.2465 - acc: 0.910 - ETA: 4s - loss: 0.2466 - acc: 0.910 - ETA: 4s - loss: 0.2462 - acc: 0.910 - ETA: 4s - loss: 0.2466 - acc: 0.910 - ETA: 4s - loss: 0.2465 - acc: 0.910 - ETA: 3s - loss: 0.2468 - acc: 0.910 - ETA: 3s - loss: 0.2467 - acc: 0.910 - ETA: 3s - loss: 0.2463 - acc: 0.910 - ETA: 3s - loss: 0.2469 - acc: 0.910 - ETA: 2s - loss: 0.2471 - acc: 0.910 - ETA: 2s - loss: 0.2469 - acc: 0.910 - ETA: 2s - loss: 0.2465 - acc: 0.910 - ETA: 2s - loss: 0.2463 - acc: 0.910 - ETA: 1s - loss: 0.2462 - acc: 0.9104426/427 [============================>.] - ETA: 1s - loss: 0.2463 - acc: 0.910 - ETA: 1s - loss: 0.2460 - acc: 0.910 - ETA: 1s - loss: 0.2458 - acc: 0.910 - ETA: 0s - loss: 0.2463 - acc: 0.910 - ETA: 0s - loss: 0.2460 - acc: 0.910 - ETA: 0s - loss: 0.2459 - acc: 0.9105\n",
      "Epoch 00005: val_loss did not improve\n",
      "427/427 [==============================] - 111s 259ms/step - loss: 0.2460 - acc: 0.9104 - val_loss: 0.4214 - val_acc: 0.8661\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:48 - loss: 0.0805 - acc: 1.000 - ETA: 1:46 - loss: 0.1918 - acc: 0.925 - ETA: 1:46 - loss: 0.1954 - acc: 0.933 - ETA: 1:46 - loss: 0.1954 - acc: 0.925 - ETA: 1:45 - loss: 0.2273 - acc: 0.910 - ETA: 1:45 - loss: 0.2164 - acc: 0.916 - ETA: 1:45 - loss: 0.2166 - acc: 0.921 - ETA: 1:37 - loss: 0.2394 - acc: 0.895 - ETA: 1:38 - loss: 0.2204 - acc: 0.907 - ETA: 1:38 - loss: 0.2119 - acc: 0.911 - ETA: 1:39 - loss: 0.2104 - acc: 0.910 - ETA: 1:39 - loss: 0.2040 - acc: 0.913 - ETA: 1:39 - loss: 0.2228 - acc: 0.904 - ETA: 1:39 - loss: 0.2161 - acc: 0.911 - ETA: 1:40 - loss: 0.2281 - acc: 0.907 - ETA: 1:41 - loss: 0.2283 - acc: 0.904 - ETA: 1:42 - loss: 0.2189 - acc: 0.909 - ETA: 1:42 - loss: 0.2189 - acc: 0.909 - ETA: 1:41 - loss: 0.2210 - acc: 0.908 - ETA: 1:41 - loss: 0.2245 - acc: 0.908 - ETA: 1:42 - loss: 0.2200 - acc: 0.910 - ETA: 1:42 - loss: 0.2252 - acc: 0.905 - ETA: 1:42 - loss: 0.2224 - acc: 0.907 - ETA: 1:41 - loss: 0.2202 - acc: 0.908 - ETA: 1:41 - loss: 0.2198 - acc: 0.910 - ETA: 1:41 - loss: 0.2222 - acc: 0.908 - ETA: 1:41 - loss: 0.2245 - acc: 0.907 - ETA: 1:41 - loss: 0.2228 - acc: 0.907 - ETA: 1:41 - loss: 0.2193 - acc: 0.907 - ETA: 1:41 - loss: 0.2187 - acc: 0.907 - ETA: 1:41 - loss: 0.2138 - acc: 0.910 - ETA: 1:41 - loss: 0.2125 - acc: 0.911 - ETA: 1:40 - loss: 0.2180 - acc: 0.908 - ETA: 1:40 - loss: 0.2148 - acc: 0.909 - ETA: 1:40 - loss: 0.2178 - acc: 0.907 - ETA: 1:38 - loss: 0.2161 - acc: 0.910 - ETA: 1:38 - loss: 0.2248 - acc: 0.908 - ETA: 1:38 - loss: 0.2311 - acc: 0.905 - ETA: 1:38 - loss: 0.2351 - acc: 0.902 - ETA: 1:38 - loss: 0.2347 - acc: 0.902 - ETA: 1:38 - loss: 0.2332 - acc: 0.904 - ETA: 1:38 - loss: 0.2317 - acc: 0.906 - ETA: 1:38 - loss: 0.2290 - acc: 0.907 - ETA: 1:38 - loss: 0.2291 - acc: 0.906 - ETA: 1:37 - loss: 0.2274 - acc: 0.907 - ETA: 1:37 - loss: 0.2267 - acc: 0.907 - ETA: 1:37 - loss: 0.2229 - acc: 0.909 - ETA: 1:36 - loss: 0.2223 - acc: 0.910 - ETA: 1:36 - loss: 0.2223 - acc: 0.910 - ETA: 1:36 - loss: 0.2200 - acc: 0.912 - ETA: 1:36 - loss: 0.2202 - acc: 0.913 - ETA: 1:35 - loss: 0.2203 - acc: 0.913 - ETA: 1:34 - loss: 0.2236 - acc: 0.912 - ETA: 1:34 - loss: 0.2265 - acc: 0.911 - ETA: 1:33 - loss: 0.2245 - acc: 0.913 - ETA: 1:33 - loss: 0.2236 - acc: 0.913 - ETA: 1:33 - loss: 0.2240 - acc: 0.914 - ETA: 1:32 - loss: 0.2244 - acc: 0.913 - ETA: 1:32 - loss: 0.2215 - acc: 0.914 - ETA: 1:32 - loss: 0.2235 - acc: 0.914 - ETA: 1:32 - loss: 0.2282 - acc: 0.912 - ETA: 1:32 - loss: 0.2289 - acc: 0.912 - ETA: 1:31 - loss: 0.2273 - acc: 0.913 - ETA: 1:31 - loss: 0.2279 - acc: 0.912 - ETA: 1:31 - loss: 0.2256 - acc: 0.914 - ETA: 1:31 - loss: 0.2243 - acc: 0.914 - ETA: 1:31 - loss: 0.2245 - acc: 0.914 - ETA: 1:31 - loss: 0.2235 - acc: 0.915 - ETA: 1:30 - loss: 0.2230 - acc: 0.915 - ETA: 1:30 - loss: 0.2222 - acc: 0.916 - ETA: 1:30 - loss: 0.2201 - acc: 0.917 - ETA: 1:30 - loss: 0.2193 - acc: 0.917 - ETA: 1:29 - loss: 0.2179 - acc: 0.918 - ETA: 1:29 - loss: 0.2179 - acc: 0.917 - ETA: 1:29 - loss: 0.2182 - acc: 0.917 - ETA: 1:29 - loss: 0.2181 - acc: 0.916 - ETA: 1:28 - loss: 0.2211 - acc: 0.915 - ETA: 1:28 - loss: 0.2195 - acc: 0.916 - ETA: 1:28 - loss: 0.2173 - acc: 0.917 - ETA: 1:27 - loss: 0.2174 - acc: 0.917 - ETA: 1:27 - loss: 0.2183 - acc: 0.916 - ETA: 1:27 - loss: 0.2171 - acc: 0.917 - ETA: 1:27 - loss: 0.2172 - acc: 0.917 - ETA: 1:26 - loss: 0.2163 - acc: 0.918 - ETA: 1:26 - loss: 0.2183 - acc: 0.917 - ETA: 1:25 - loss: 0.2192 - acc: 0.917 - ETA: 1:25 - loss: 0.2177 - acc: 0.918 - ETA: 1:25 - loss: 0.2209 - acc: 0.916 - ETA: 1:25 - loss: 0.2193 - acc: 0.917 - ETA: 1:25 - loss: 0.2228 - acc: 0.916 - ETA: 1:25 - loss: 0.2219 - acc: 0.916 - ETA: 1:25 - loss: 0.2217 - acc: 0.916 - ETA: 1:25 - loss: 0.2220 - acc: 0.915 - ETA: 1:24 - loss: 0.2216 - acc: 0.916 - ETA: 1:24 - loss: 0.2207 - acc: 0.916 - ETA: 1:24 - loss: 0.2199 - acc: 0.916 - ETA: 1:24 - loss: 0.2197 - acc: 0.917 - ETA: 1:23 - loss: 0.2202 - acc: 0.917 - ETA: 1:23 - loss: 0.2187 - acc: 0.918 - ETA: 1:23 - loss: 0.2177 - acc: 0.918 - ETA: 1:23 - loss: 0.2164 - acc: 0.919 - ETA: 1:23 - loss: 0.2165 - acc: 0.918 - ETA: 1:22 - loss: 0.2186 - acc: 0.917 - ETA: 1:22 - loss: 0.2219 - acc: 0.915 - ETA: 1:21 - loss: 0.2220 - acc: 0.915 - ETA: 1:21 - loss: 0.2234 - acc: 0.915 - ETA: 1:21 - loss: 0.2227 - acc: 0.915 - ETA: 1:21 - loss: 0.2227 - acc: 0.915 - ETA: 1:21 - loss: 0.2220 - acc: 0.916 - ETA: 1:20 - loss: 0.2230 - acc: 0.916 - ETA: 1:20 - loss: 0.2238 - acc: 0.916 - ETA: 1:20 - loss: 0.2272 - acc: 0.914 - ETA: 1:20 - loss: 0.2256 - acc: 0.915 - ETA: 1:19 - loss: 0.2247 - acc: 0.915 - ETA: 1:19 - loss: 0.2231 - acc: 0.916 - ETA: 1:19 - loss: 0.2223 - acc: 0.916 - ETA: 1:19 - loss: 0.2233 - acc: 0.916 - ETA: 1:18 - loss: 0.2223 - acc: 0.916 - ETA: 1:18 - loss: 0.2220 - acc: 0.917 - ETA: 1:18 - loss: 0.2212 - acc: 0.917 - ETA: 1:18 - loss: 0.2217 - acc: 0.916 - ETA: 1:17 - loss: 0.2217 - acc: 0.917 - ETA: 1:17 - loss: 0.2224 - acc: 0.916 - ETA: 1:17 - loss: 0.2230 - acc: 0.916 - ETA: 1:17 - loss: 0.2226 - acc: 0.917 - ETA: 1:16 - loss: 0.2236 - acc: 0.917 - ETA: 1:16 - loss: 0.2224 - acc: 0.917 - ETA: 1:15 - loss: 0.2220 - acc: 0.918 - ETA: 1:15 - loss: 0.2235 - acc: 0.917 - ETA: 1:15 - loss: 0.2237 - acc: 0.918 - ETA: 1:15 - loss: 0.2241 - acc: 0.917 - ETA: 1:14 - loss: 0.2246 - acc: 0.917 - ETA: 1:14 - loss: 0.2241 - acc: 0.917 - ETA: 1:14 - loss: 0.2241 - acc: 0.917 - ETA: 1:14 - loss: 0.2231 - acc: 0.918 - ETA: 1:14 - loss: 0.2225 - acc: 0.918 - ETA: 1:13 - loss: 0.2214 - acc: 0.919 - ETA: 1:13 - loss: 0.2208 - acc: 0.919 - ETA: 1:13 - loss: 0.2203 - acc: 0.919 - ETA: 1:13 - loss: 0.2195 - acc: 0.920 - ETA: 1:12 - loss: 0.2201 - acc: 0.919 - ETA: 1:12 - loss: 0.2203 - acc: 0.918 - ETA: 1:12 - loss: 0.2193 - acc: 0.919 - ETA: 1:12 - loss: 0.2185 - acc: 0.919 - ETA: 1:11 - loss: 0.2188 - acc: 0.919 - ETA: 1:11 - loss: 0.2189 - acc: 0.919 - ETA: 1:11 - loss: 0.2196 - acc: 0.919 - ETA: 1:11 - loss: 0.2191 - acc: 0.919 - ETA: 1:10 - loss: 0.2181 - acc: 0.920 - ETA: 1:10 - loss: 0.2186 - acc: 0.920 - ETA: 1:10 - loss: 0.2188 - acc: 0.920 - ETA: 1:09 - loss: 0.2185 - acc: 0.920 - ETA: 1:09 - loss: 0.2186 - acc: 0.920 - ETA: 1:09 - loss: 0.2188 - acc: 0.920 - ETA: 1:09 - loss: 0.2199 - acc: 0.920 - ETA: 1:09 - loss: 0.2201 - acc: 0.920 - ETA: 1:08 - loss: 0.2200 - acc: 0.920 - ETA: 1:08 - loss: 0.2193 - acc: 0.920 - ETA: 1:08 - loss: 0.2198 - acc: 0.920 - ETA: 1:08 - loss: 0.2219 - acc: 0.920 - ETA: 1:08 - loss: 0.2215 - acc: 0.920 - ETA: 1:07 - loss: 0.2210 - acc: 0.920 - ETA: 1:07 - loss: 0.2210 - acc: 0.919 - ETA: 1:07 - loss: 0.2205 - acc: 0.920 - ETA: 1:06 - loss: 0.2204 - acc: 0.920 - ETA: 1:06 - loss: 0.2202 - acc: 0.920 - ETA: 1:06 - loss: 0.2200 - acc: 0.920 - ETA: 1:06 - loss: 0.2198 - acc: 0.919 - ETA: 1:05 - loss: 0.2209 - acc: 0.919 - ETA: 1:05 - loss: 0.2207 - acc: 0.919 - ETA: 1:05 - loss: 0.2206 - acc: 0.919 - ETA: 1:05 - loss: 0.2198 - acc: 0.919 - ETA: 1:04 - loss: 0.2209 - acc: 0.919 - ETA: 1:04 - loss: 0.2211 - acc: 0.919 - ETA: 1:04 - loss: 0.2207 - acc: 0.919 - ETA: 1:04 - loss: 0.2202 - acc: 0.919 - ETA: 1:03 - loss: 0.2200 - acc: 0.920 - ETA: 1:03 - loss: 0.2197 - acc: 0.920 - ETA: 1:03 - loss: 0.2203 - acc: 0.919 - ETA: 1:03 - loss: 0.2203 - acc: 0.919 - ETA: 1:02 - loss: 0.2197 - acc: 0.920 - ETA: 1:02 - loss: 0.2194 - acc: 0.920 - ETA: 1:02 - loss: 0.2190 - acc: 0.920 - ETA: 1:02 - loss: 0.2197 - acc: 0.920 - ETA: 1:01 - loss: 0.2198 - acc: 0.920 - ETA: 1:01 - loss: 0.2193 - acc: 0.920 - ETA: 1:01 - loss: 0.2191 - acc: 0.920 - ETA: 1:01 - loss: 0.2188 - acc: 0.920 - ETA: 1:00 - loss: 0.2182 - acc: 0.920 - ETA: 1:00 - loss: 0.2182 - acc: 0.920 - ETA: 1:00 - loss: 0.2197 - acc: 0.919 - ETA: 59s - loss: 0.2193 - acc: 0.920 - ETA: 59s - loss: 0.2196 - acc: 0.91 - ETA: 59s - loss: 0.2192 - acc: 0.91 - ETA: 59s - loss: 0.2215 - acc: 0.91 - ETA: 58s - loss: 0.2213 - acc: 0.91 - ETA: 58s - loss: 0.2213 - acc: 0.91 - ETA: 58s - loss: 0.2221 - acc: 0.91 - ETA: 58s - loss: 0.2220 - acc: 0.91 - ETA: 57s - loss: 0.2217 - acc: 0.91 - ETA: 57s - loss: 0.2229 - acc: 0.91 - ETA: 57s - loss: 0.2234 - acc: 0.91 - ETA: 57s - loss: 0.2236 - acc: 0.91 - ETA: 56s - loss: 0.2235 - acc: 0.91 - ETA: 56s - loss: 0.2231 - acc: 0.9188420/427 [============================>.] - ETA: 56s - loss: 0.2233 - acc: 0.91 - ETA: 56s - loss: 0.2231 - acc: 0.91 - ETA: 55s - loss: 0.2237 - acc: 0.91 - ETA: 55s - loss: 0.2247 - acc: 0.91 - ETA: 55s - loss: 0.2249 - acc: 0.91 - ETA: 55s - loss: 0.2245 - acc: 0.91 - ETA: 54s - loss: 0.2247 - acc: 0.91 - ETA: 54s - loss: 0.2258 - acc: 0.91 - ETA: 54s - loss: 0.2252 - acc: 0.91 - ETA: 53s - loss: 0.2248 - acc: 0.91 - ETA: 53s - loss: 0.2244 - acc: 0.91 - ETA: 53s - loss: 0.2240 - acc: 0.91 - ETA: 53s - loss: 0.2242 - acc: 0.91 - ETA: 53s - loss: 0.2258 - acc: 0.91 - ETA: 52s - loss: 0.2257 - acc: 0.91 - ETA: 52s - loss: 0.2250 - acc: 0.91 - ETA: 52s - loss: 0.2260 - acc: 0.91 - ETA: 52s - loss: 0.2260 - acc: 0.91 - ETA: 51s - loss: 0.2260 - acc: 0.91 - ETA: 51s - loss: 0.2259 - acc: 0.91 - ETA: 51s - loss: 0.2256 - acc: 0.91 - ETA: 51s - loss: 0.2253 - acc: 0.91 - ETA: 50s - loss: 0.2256 - acc: 0.91 - ETA: 50s - loss: 0.2250 - acc: 0.91 - ETA: 50s - loss: 0.2254 - acc: 0.91 - ETA: 50s - loss: 0.2247 - acc: 0.91 - ETA: 49s - loss: 0.2245 - acc: 0.91 - ETA: 49s - loss: 0.2252 - acc: 0.91 - ETA: 49s - loss: 0.2254 - acc: 0.91 - ETA: 49s - loss: 0.2252 - acc: 0.91 - ETA: 48s - loss: 0.2254 - acc: 0.91 - ETA: 48s - loss: 0.2256 - acc: 0.91 - ETA: 48s - loss: 0.2280 - acc: 0.91 - ETA: 47s - loss: 0.2282 - acc: 0.91 - ETA: 47s - loss: 0.2278 - acc: 0.91 - ETA: 47s - loss: 0.2275 - acc: 0.91 - ETA: 47s - loss: 0.2272 - acc: 0.91 - ETA: 46s - loss: 0.2272 - acc: 0.91 - ETA: 46s - loss: 0.2270 - acc: 0.91 - ETA: 46s - loss: 0.2276 - acc: 0.91 - ETA: 46s - loss: 0.2274 - acc: 0.91 - ETA: 45s - loss: 0.2271 - acc: 0.91 - ETA: 45s - loss: 0.2271 - acc: 0.91 - ETA: 45s - loss: 0.2273 - acc: 0.91 - ETA: 45s - loss: 0.2273 - acc: 0.91 - ETA: 44s - loss: 0.2271 - acc: 0.91 - ETA: 44s - loss: 0.2265 - acc: 0.91 - ETA: 44s - loss: 0.2258 - acc: 0.91 - ETA: 44s - loss: 0.2259 - acc: 0.91 - ETA: 43s - loss: 0.2266 - acc: 0.91 - ETA: 43s - loss: 0.2264 - acc: 0.91 - ETA: 43s - loss: 0.2266 - acc: 0.91 - ETA: 43s - loss: 0.2271 - acc: 0.91 - ETA: 42s - loss: 0.2278 - acc: 0.91 - ETA: 42s - loss: 0.2298 - acc: 0.91 - ETA: 42s - loss: 0.2294 - acc: 0.91 - ETA: 41s - loss: 0.2289 - acc: 0.91 - ETA: 41s - loss: 0.2293 - acc: 0.91 - ETA: 41s - loss: 0.2294 - acc: 0.91 - ETA: 41s - loss: 0.2288 - acc: 0.91 - ETA: 40s - loss: 0.2289 - acc: 0.91 - ETA: 40s - loss: 0.2289 - acc: 0.91 - ETA: 40s - loss: 0.2288 - acc: 0.91 - ETA: 40s - loss: 0.2283 - acc: 0.91 - ETA: 39s - loss: 0.2280 - acc: 0.91 - ETA: 39s - loss: 0.2277 - acc: 0.91 - ETA: 39s - loss: 0.2281 - acc: 0.91 - ETA: 39s - loss: 0.2275 - acc: 0.91 - ETA: 38s - loss: 0.2280 - acc: 0.91 - ETA: 38s - loss: 0.2283 - acc: 0.91 - ETA: 38s - loss: 0.2282 - acc: 0.91 - ETA: 38s - loss: 0.2287 - acc: 0.91 - ETA: 37s - loss: 0.2291 - acc: 0.91 - ETA: 37s - loss: 0.2286 - acc: 0.91 - ETA: 37s - loss: 0.2285 - acc: 0.91 - ETA: 37s - loss: 0.2297 - acc: 0.91 - ETA: 36s - loss: 0.2295 - acc: 0.91 - ETA: 36s - loss: 0.2295 - acc: 0.91 - ETA: 36s - loss: 0.2299 - acc: 0.91 - ETA: 36s - loss: 0.2297 - acc: 0.91 - ETA: 35s - loss: 0.2302 - acc: 0.91 - ETA: 35s - loss: 0.2301 - acc: 0.91 - ETA: 35s - loss: 0.2296 - acc: 0.91 - ETA: 35s - loss: 0.2296 - acc: 0.91 - ETA: 34s - loss: 0.2289 - acc: 0.91 - ETA: 34s - loss: 0.2286 - acc: 0.91 - ETA: 34s - loss: 0.2282 - acc: 0.91 - ETA: 34s - loss: 0.2278 - acc: 0.91 - ETA: 33s - loss: 0.2285 - acc: 0.91 - ETA: 33s - loss: 0.2280 - acc: 0.91 - ETA: 33s - loss: 0.2275 - acc: 0.91 - ETA: 33s - loss: 0.2273 - acc: 0.91 - ETA: 32s - loss: 0.2271 - acc: 0.91 - ETA: 32s - loss: 0.2271 - acc: 0.91 - ETA: 32s - loss: 0.2268 - acc: 0.91 - ETA: 32s - loss: 0.2264 - acc: 0.91 - ETA: 31s - loss: 0.2265 - acc: 0.91 - ETA: 31s - loss: 0.2260 - acc: 0.91 - ETA: 31s - loss: 0.2256 - acc: 0.91 - ETA: 31s - loss: 0.2251 - acc: 0.91 - ETA: 30s - loss: 0.2254 - acc: 0.91 - ETA: 30s - loss: 0.2256 - acc: 0.91 - ETA: 30s - loss: 0.2260 - acc: 0.91 - ETA: 30s - loss: 0.2262 - acc: 0.91 - ETA: 29s - loss: 0.2257 - acc: 0.91 - ETA: 29s - loss: 0.2256 - acc: 0.91 - ETA: 29s - loss: 0.2253 - acc: 0.91 - ETA: 29s - loss: 0.2250 - acc: 0.91 - ETA: 28s - loss: 0.2254 - acc: 0.91 - ETA: 28s - loss: 0.2249 - acc: 0.91 - ETA: 28s - loss: 0.2251 - acc: 0.91 - ETA: 27s - loss: 0.2255 - acc: 0.91 - ETA: 27s - loss: 0.2256 - acc: 0.91 - ETA: 27s - loss: 0.2252 - acc: 0.91 - ETA: 27s - loss: 0.2250 - acc: 0.91 - ETA: 26s - loss: 0.2251 - acc: 0.91 - ETA: 26s - loss: 0.2247 - acc: 0.91 - ETA: 26s - loss: 0.2246 - acc: 0.91 - ETA: 26s - loss: 0.2245 - acc: 0.91 - ETA: 25s - loss: 0.2242 - acc: 0.91 - ETA: 25s - loss: 0.2248 - acc: 0.91 - ETA: 25s - loss: 0.2246 - acc: 0.91 - ETA: 25s - loss: 0.2242 - acc: 0.91 - ETA: 24s - loss: 0.2237 - acc: 0.91 - ETA: 24s - loss: 0.2231 - acc: 0.91 - ETA: 24s - loss: 0.2236 - acc: 0.91 - ETA: 24s - loss: 0.2234 - acc: 0.91 - ETA: 23s - loss: 0.2240 - acc: 0.91 - ETA: 23s - loss: 0.2243 - acc: 0.91 - ETA: 23s - loss: 0.2246 - acc: 0.91 - ETA: 23s - loss: 0.2242 - acc: 0.91 - ETA: 22s - loss: 0.2243 - acc: 0.91 - ETA: 22s - loss: 0.2247 - acc: 0.91 - ETA: 22s - loss: 0.2247 - acc: 0.91 - ETA: 22s - loss: 0.2249 - acc: 0.91 - ETA: 21s - loss: 0.2244 - acc: 0.91 - ETA: 21s - loss: 0.2243 - acc: 0.91 - ETA: 21s - loss: 0.2243 - acc: 0.91 - ETA: 21s - loss: 0.2243 - acc: 0.91 - ETA: 20s - loss: 0.2242 - acc: 0.91 - ETA: 20s - loss: 0.2240 - acc: 0.91 - ETA: 20s - loss: 0.2250 - acc: 0.91 - ETA: 20s - loss: 0.2249 - acc: 0.91 - ETA: 19s - loss: 0.2245 - acc: 0.91 - ETA: 19s - loss: 0.2243 - acc: 0.91 - ETA: 19s - loss: 0.2240 - acc: 0.92 - ETA: 19s - loss: 0.2241 - acc: 0.91 - ETA: 18s - loss: 0.2238 - acc: 0.92 - ETA: 18s - loss: 0.2237 - acc: 0.92 - ETA: 18s - loss: 0.2237 - acc: 0.92 - ETA: 18s - loss: 0.2241 - acc: 0.91 - ETA: 17s - loss: 0.2242 - acc: 0.91 - ETA: 17s - loss: 0.2241 - acc: 0.91 - ETA: 17s - loss: 0.2241 - acc: 0.91 - ETA: 17s - loss: 0.2240 - acc: 0.91 - ETA: 16s - loss: 0.2236 - acc: 0.91 - ETA: 16s - loss: 0.2236 - acc: 0.91 - ETA: 16s - loss: 0.2234 - acc: 0.91 - ETA: 16s - loss: 0.2247 - acc: 0.91 - ETA: 15s - loss: 0.2244 - acc: 0.91 - ETA: 15s - loss: 0.2245 - acc: 0.91 - ETA: 15s - loss: 0.2254 - acc: 0.91 - ETA: 15s - loss: 0.2259 - acc: 0.91 - ETA: 14s - loss: 0.2261 - acc: 0.91 - ETA: 14s - loss: 0.2261 - acc: 0.91 - ETA: 14s - loss: 0.2261 - acc: 0.91 - ETA: 14s - loss: 0.2259 - acc: 0.91 - ETA: 13s - loss: 0.2258 - acc: 0.91 - ETA: 13s - loss: 0.2255 - acc: 0.91 - ETA: 13s - loss: 0.2252 - acc: 0.91 - ETA: 13s - loss: 0.2252 - acc: 0.91 - ETA: 12s - loss: 0.2257 - acc: 0.91 - ETA: 12s - loss: 0.2260 - acc: 0.91 - ETA: 12s - loss: 0.2256 - acc: 0.91 - ETA: 11s - loss: 0.2254 - acc: 0.91 - ETA: 11s - loss: 0.2251 - acc: 0.91 - ETA: 11s - loss: 0.2251 - acc: 0.91 - ETA: 11s - loss: 0.2250 - acc: 0.91 - ETA: 10s - loss: 0.2248 - acc: 0.91 - ETA: 10s - loss: 0.2247 - acc: 0.91 - ETA: 10s - loss: 0.2246 - acc: 0.91 - ETA: 10s - loss: 0.2241 - acc: 0.91 - ETA: 9s - loss: 0.2239 - acc: 0.9190 - ETA: 9s - loss: 0.2239 - acc: 0.919 - ETA: 9s - loss: 0.2237 - acc: 0.919 - ETA: 9s - loss: 0.2241 - acc: 0.919 - ETA: 8s - loss: 0.2243 - acc: 0.918 - ETA: 8s - loss: 0.2238 - acc: 0.919 - ETA: 8s - loss: 0.2235 - acc: 0.919 - ETA: 8s - loss: 0.2231 - acc: 0.919 - ETA: 7s - loss: 0.2229 - acc: 0.919 - ETA: 7s - loss: 0.2226 - acc: 0.919 - ETA: 7s - loss: 0.2225 - acc: 0.919 - ETA: 7s - loss: 0.2225 - acc: 0.919 - ETA: 6s - loss: 0.2224 - acc: 0.919 - ETA: 6s - loss: 0.2223 - acc: 0.920 - ETA: 6s - loss: 0.2221 - acc: 0.920 - ETA: 6s - loss: 0.2219 - acc: 0.920 - ETA: 5s - loss: 0.2216 - acc: 0.920 - ETA: 5s - loss: 0.2214 - acc: 0.920 - ETA: 5s - loss: 0.2222 - acc: 0.920 - ETA: 5s - loss: 0.2229 - acc: 0.920 - ETA: 4s - loss: 0.2229 - acc: 0.919 - ETA: 4s - loss: 0.2229 - acc: 0.919 - ETA: 4s - loss: 0.2227 - acc: 0.919 - ETA: 4s - loss: 0.2229 - acc: 0.919 - ETA: 3s - loss: 0.2232 - acc: 0.919 - ETA: 3s - loss: 0.2234 - acc: 0.919 - ETA: 3s - loss: 0.2235 - acc: 0.919 - ETA: 3s - loss: 0.2235 - acc: 0.919 - ETA: 2s - loss: 0.2230 - acc: 0.919 - ETA: 2s - loss: 0.2226 - acc: 0.919 - ETA: 2s - loss: 0.2224 - acc: 0.919 - ETA: 2s - loss: 0.2221 - acc: 0.919 - ETA: 1s - loss: 0.2225 - acc: 0.9196"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/427 [============================>.] - ETA: 1s - loss: 0.2231 - acc: 0.919 - ETA: 1s - loss: 0.2232 - acc: 0.919 - ETA: 1s - loss: 0.2230 - acc: 0.919 - ETA: 0s - loss: 0.2229 - acc: 0.919 - ETA: 0s - loss: 0.2244 - acc: 0.919 - ETA: 0s - loss: 0.2240 - acc: 0.9192\n",
      "Epoch 00006: val_loss did not improve\n",
      "427/427 [==============================] - 110s 258ms/step - loss: 0.2238 - acc: 0.9193 - val_loss: 0.4141 - val_acc: 0.8575\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:46 - loss: 0.2545 - acc: 0.900 - ETA: 1:45 - loss: 0.2156 - acc: 0.900 - ETA: 1:45 - loss: 0.2045 - acc: 0.883 - ETA: 1:45 - loss: 0.1716 - acc: 0.912 - ETA: 1:44 - loss: 0.1649 - acc: 0.910 - ETA: 1:44 - loss: 0.1617 - acc: 0.916 - ETA: 1:44 - loss: 0.1515 - acc: 0.928 - ETA: 1:45 - loss: 0.1731 - acc: 0.925 - ETA: 1:46 - loss: 0.1873 - acc: 0.916 - ETA: 1:47 - loss: 0.1801 - acc: 0.920 - ETA: 1:47 - loss: 0.1933 - acc: 0.918 - ETA: 1:47 - loss: 0.1911 - acc: 0.920 - ETA: 1:42 - loss: 0.2117 - acc: 0.915 - ETA: 1:42 - loss: 0.2013 - acc: 0.921 - ETA: 1:42 - loss: 0.2014 - acc: 0.920 - ETA: 1:42 - loss: 0.1970 - acc: 0.922 - ETA: 1:42 - loss: 0.1979 - acc: 0.921 - ETA: 1:41 - loss: 0.1930 - acc: 0.925 - ETA: 1:41 - loss: 0.1885 - acc: 0.929 - ETA: 1:41 - loss: 0.1833 - acc: 0.932 - ETA: 1:41 - loss: 0.1803 - acc: 0.933 - ETA: 1:41 - loss: 0.1768 - acc: 0.934 - ETA: 1:41 - loss: 0.1792 - acc: 0.932 - ETA: 1:40 - loss: 0.1852 - acc: 0.929 - ETA: 1:40 - loss: 0.2071 - acc: 0.920 - ETA: 1:40 - loss: 0.2216 - acc: 0.917 - ETA: 1:40 - loss: 0.2190 - acc: 0.918 - ETA: 1:39 - loss: 0.2146 - acc: 0.919 - ETA: 1:39 - loss: 0.2154 - acc: 0.919 - ETA: 1:39 - loss: 0.2196 - acc: 0.918 - ETA: 1:39 - loss: 0.2150 - acc: 0.921 - ETA: 1:40 - loss: 0.2183 - acc: 0.920 - ETA: 1:40 - loss: 0.2244 - acc: 0.919 - ETA: 1:40 - loss: 0.2237 - acc: 0.920 - ETA: 1:41 - loss: 0.2221 - acc: 0.921 - ETA: 1:40 - loss: 0.2241 - acc: 0.922 - ETA: 1:40 - loss: 0.2250 - acc: 0.921 - ETA: 1:38 - loss: 0.2202 - acc: 0.923 - ETA: 1:38 - loss: 0.2193 - acc: 0.923 - ETA: 1:38 - loss: 0.2168 - acc: 0.923 - ETA: 1:38 - loss: 0.2145 - acc: 0.925 - ETA: 1:38 - loss: 0.2114 - acc: 0.927 - ETA: 1:38 - loss: 0.2115 - acc: 0.926 - ETA: 1:38 - loss: 0.2083 - acc: 0.928 - ETA: 1:38 - loss: 0.2063 - acc: 0.929 - ETA: 1:37 - loss: 0.2048 - acc: 0.929 - ETA: 1:37 - loss: 0.2069 - acc: 0.926 - ETA: 1:37 - loss: 0.2062 - acc: 0.927 - ETA: 1:36 - loss: 0.2049 - acc: 0.927 - ETA: 1:36 - loss: 0.2030 - acc: 0.929 - ETA: 1:36 - loss: 0.2046 - acc: 0.927 - ETA: 1:35 - loss: 0.2143 - acc: 0.922 - ETA: 1:35 - loss: 0.2165 - acc: 0.920 - ETA: 1:35 - loss: 0.2169 - acc: 0.921 - ETA: 1:35 - loss: 0.2196 - acc: 0.919 - ETA: 1:35 - loss: 0.2185 - acc: 0.918 - ETA: 1:35 - loss: 0.2160 - acc: 0.920 - ETA: 1:35 - loss: 0.2152 - acc: 0.920 - ETA: 1:34 - loss: 0.2154 - acc: 0.922 - ETA: 1:34 - loss: 0.2180 - acc: 0.921 - ETA: 1:34 - loss: 0.2199 - acc: 0.920 - ETA: 1:33 - loss: 0.2193 - acc: 0.919 - ETA: 1:32 - loss: 0.2246 - acc: 0.916 - ETA: 1:32 - loss: 0.2245 - acc: 0.915 - ETA: 1:32 - loss: 0.2228 - acc: 0.916 - ETA: 1:31 - loss: 0.2239 - acc: 0.915 - ETA: 1:31 - loss: 0.2279 - acc: 0.913 - ETA: 1:31 - loss: 0.2308 - acc: 0.914 - ETA: 1:31 - loss: 0.2310 - acc: 0.913 - ETA: 1:30 - loss: 0.2343 - acc: 0.913 - ETA: 1:30 - loss: 0.2323 - acc: 0.914 - ETA: 1:30 - loss: 0.2318 - acc: 0.914 - ETA: 1:29 - loss: 0.2339 - acc: 0.912 - ETA: 1:29 - loss: 0.2327 - acc: 0.913 - ETA: 1:29 - loss: 0.2337 - acc: 0.913 - ETA: 1:29 - loss: 0.2342 - acc: 0.912 - ETA: 1:28 - loss: 0.2333 - acc: 0.913 - ETA: 1:28 - loss: 0.2316 - acc: 0.914 - ETA: 1:28 - loss: 0.2318 - acc: 0.914 - ETA: 1:28 - loss: 0.2315 - acc: 0.914 - ETA: 1:28 - loss: 0.2305 - acc: 0.914 - ETA: 1:28 - loss: 0.2317 - acc: 0.914 - ETA: 1:27 - loss: 0.2308 - acc: 0.914 - ETA: 1:27 - loss: 0.2290 - acc: 0.915 - ETA: 1:27 - loss: 0.2272 - acc: 0.916 - ETA: 1:27 - loss: 0.2259 - acc: 0.917 - ETA: 1:26 - loss: 0.2252 - acc: 0.917 - ETA: 1:26 - loss: 0.2252 - acc: 0.916 - ETA: 1:26 - loss: 0.2245 - acc: 0.917 - ETA: 1:25 - loss: 0.2251 - acc: 0.916 - ETA: 1:25 - loss: 0.2258 - acc: 0.916 - ETA: 1:25 - loss: 0.2259 - acc: 0.916 - ETA: 1:25 - loss: 0.2258 - acc: 0.916 - ETA: 1:24 - loss: 0.2251 - acc: 0.916 - ETA: 1:24 - loss: 0.2261 - acc: 0.914 - ETA: 1:23 - loss: 0.2268 - acc: 0.914 - ETA: 1:23 - loss: 0.2265 - acc: 0.914 - ETA: 1:23 - loss: 0.2256 - acc: 0.915 - ETA: 1:23 - loss: 0.2259 - acc: 0.914 - ETA: 1:23 - loss: 0.2250 - acc: 0.915 - ETA: 1:22 - loss: 0.2236 - acc: 0.916 - ETA: 1:22 - loss: 0.2222 - acc: 0.917 - ETA: 1:22 - loss: 0.2215 - acc: 0.917 - ETA: 1:22 - loss: 0.2221 - acc: 0.917 - ETA: 1:22 - loss: 0.2210 - acc: 0.918 - ETA: 1:22 - loss: 0.2214 - acc: 0.918 - ETA: 1:22 - loss: 0.2228 - acc: 0.917 - ETA: 1:21 - loss: 0.2224 - acc: 0.917 - ETA: 1:21 - loss: 0.2232 - acc: 0.917 - ETA: 1:20 - loss: 0.2227 - acc: 0.918 - ETA: 1:20 - loss: 0.2223 - acc: 0.918 - ETA: 1:20 - loss: 0.2225 - acc: 0.918 - ETA: 1:20 - loss: 0.2230 - acc: 0.918 - ETA: 1:19 - loss: 0.2219 - acc: 0.918 - ETA: 1:19 - loss: 0.2223 - acc: 0.918 - ETA: 1:19 - loss: 0.2212 - acc: 0.918 - ETA: 1:18 - loss: 0.2204 - acc: 0.919 - ETA: 1:18 - loss: 0.2204 - acc: 0.918 - ETA: 1:18 - loss: 0.2195 - acc: 0.919 - ETA: 1:18 - loss: 0.2186 - acc: 0.920 - ETA: 1:18 - loss: 0.2180 - acc: 0.920 - ETA: 1:17 - loss: 0.2170 - acc: 0.920 - ETA: 1:17 - loss: 0.2165 - acc: 0.920 - ETA: 1:17 - loss: 0.2155 - acc: 0.921 - ETA: 1:17 - loss: 0.2162 - acc: 0.921 - ETA: 1:17 - loss: 0.2153 - acc: 0.921 - ETA: 1:16 - loss: 0.2158 - acc: 0.921 - ETA: 1:16 - loss: 0.2176 - acc: 0.920 - ETA: 1:16 - loss: 0.2189 - acc: 0.920 - ETA: 1:16 - loss: 0.2194 - acc: 0.920 - ETA: 1:15 - loss: 0.2208 - acc: 0.920 - ETA: 1:15 - loss: 0.2203 - acc: 0.920 - ETA: 1:15 - loss: 0.2207 - acc: 0.920 - ETA: 1:15 - loss: 0.2199 - acc: 0.920 - ETA: 1:14 - loss: 0.2191 - acc: 0.921 - ETA: 1:14 - loss: 0.2193 - acc: 0.921 - ETA: 1:14 - loss: 0.2184 - acc: 0.922 - ETA: 1:13 - loss: 0.2181 - acc: 0.922 - ETA: 1:13 - loss: 0.2188 - acc: 0.922 - ETA: 1:13 - loss: 0.2181 - acc: 0.922 - ETA: 1:12 - loss: 0.2182 - acc: 0.922 - ETA: 1:12 - loss: 0.2179 - acc: 0.922 - ETA: 1:12 - loss: 0.2168 - acc: 0.923 - ETA: 1:12 - loss: 0.2157 - acc: 0.923 - ETA: 1:11 - loss: 0.2166 - acc: 0.923 - ETA: 1:11 - loss: 0.2179 - acc: 0.922 - ETA: 1:11 - loss: 0.2172 - acc: 0.923 - ETA: 1:11 - loss: 0.2164 - acc: 0.923 - ETA: 1:10 - loss: 0.2157 - acc: 0.923 - ETA: 1:10 - loss: 0.2161 - acc: 0.923 - ETA: 1:10 - loss: 0.2156 - acc: 0.923 - ETA: 1:10 - loss: 0.2157 - acc: 0.923 - ETA: 1:10 - loss: 0.2155 - acc: 0.923 - ETA: 1:09 - loss: 0.2154 - acc: 0.923 - ETA: 1:09 - loss: 0.2158 - acc: 0.922 - ETA: 1:09 - loss: 0.2154 - acc: 0.923 - ETA: 1:08 - loss: 0.2144 - acc: 0.923 - ETA: 1:08 - loss: 0.2149 - acc: 0.923 - ETA: 1:08 - loss: 0.2153 - acc: 0.923 - ETA: 1:08 - loss: 0.2154 - acc: 0.923 - ETA: 1:08 - loss: 0.2152 - acc: 0.923 - ETA: 1:07 - loss: 0.2151 - acc: 0.923 - ETA: 1:07 - loss: 0.2167 - acc: 0.922 - ETA: 1:07 - loss: 0.2159 - acc: 0.923 - ETA: 1:07 - loss: 0.2167 - acc: 0.922 - ETA: 1:06 - loss: 0.2161 - acc: 0.923 - ETA: 1:06 - loss: 0.2156 - acc: 0.923 - ETA: 1:06 - loss: 0.2149 - acc: 0.924 - ETA: 1:06 - loss: 0.2162 - acc: 0.923 - ETA: 1:05 - loss: 0.2152 - acc: 0.924 - ETA: 1:05 - loss: 0.2155 - acc: 0.924 - ETA: 1:05 - loss: 0.2152 - acc: 0.924 - ETA: 1:05 - loss: 0.2148 - acc: 0.925 - ETA: 1:04 - loss: 0.2153 - acc: 0.924 - ETA: 1:04 - loss: 0.2154 - acc: 0.924 - ETA: 1:04 - loss: 0.2147 - acc: 0.924 - ETA: 1:04 - loss: 0.2145 - acc: 0.924 - ETA: 1:03 - loss: 0.2139 - acc: 0.925 - ETA: 1:03 - loss: 0.2140 - acc: 0.925 - ETA: 1:03 - loss: 0.2131 - acc: 0.925 - ETA: 1:03 - loss: 0.2133 - acc: 0.925 - ETA: 1:02 - loss: 0.2129 - acc: 0.925 - ETA: 1:02 - loss: 0.2147 - acc: 0.924 - ETA: 1:02 - loss: 0.2148 - acc: 0.924 - ETA: 1:02 - loss: 0.2144 - acc: 0.924 - ETA: 1:01 - loss: 0.2139 - acc: 0.924 - ETA: 1:01 - loss: 0.2150 - acc: 0.924 - ETA: 1:01 - loss: 0.2154 - acc: 0.923 - ETA: 1:00 - loss: 0.2148 - acc: 0.924 - ETA: 1:00 - loss: 0.2147 - acc: 0.924 - ETA: 1:00 - loss: 0.2160 - acc: 0.924 - ETA: 59s - loss: 0.2150 - acc: 0.924 - ETA: 59s - loss: 0.2144 - acc: 0.92 - ETA: 59s - loss: 0.2153 - acc: 0.92 - ETA: 59s - loss: 0.2151 - acc: 0.92 - ETA: 58s - loss: 0.2145 - acc: 0.92 - ETA: 58s - loss: 0.2146 - acc: 0.92 - ETA: 58s - loss: 0.2140 - acc: 0.92 - ETA: 58s - loss: 0.2139 - acc: 0.92 - ETA: 57s - loss: 0.2145 - acc: 0.92 - ETA: 57s - loss: 0.2145 - acc: 0.92 - ETA: 57s - loss: 0.2144 - acc: 0.92 - ETA: 57s - loss: 0.2136 - acc: 0.92 - ETA: 56s - loss: 0.2147 - acc: 0.92 - ETA: 56s - loss: 0.2144 - acc: 0.9241420/427 [============================>.] - ETA: 56s - loss: 0.2142 - acc: 0.92 - ETA: 56s - loss: 0.2136 - acc: 0.92 - ETA: 55s - loss: 0.2130 - acc: 0.92 - ETA: 55s - loss: 0.2135 - acc: 0.92 - ETA: 55s - loss: 0.2143 - acc: 0.92 - ETA: 55s - loss: 0.2141 - acc: 0.92 - ETA: 54s - loss: 0.2135 - acc: 0.92 - ETA: 54s - loss: 0.2139 - acc: 0.92 - ETA: 54s - loss: 0.2134 - acc: 0.92 - ETA: 54s - loss: 0.2128 - acc: 0.92 - ETA: 53s - loss: 0.2130 - acc: 0.92 - ETA: 53s - loss: 0.2131 - acc: 0.92 - ETA: 53s - loss: 0.2129 - acc: 0.92 - ETA: 53s - loss: 0.2133 - acc: 0.92 - ETA: 52s - loss: 0.2136 - acc: 0.92 - ETA: 52s - loss: 0.2131 - acc: 0.92 - ETA: 52s - loss: 0.2128 - acc: 0.92 - ETA: 52s - loss: 0.2120 - acc: 0.92 - ETA: 52s - loss: 0.2119 - acc: 0.92 - ETA: 51s - loss: 0.2117 - acc: 0.92 - ETA: 51s - loss: 0.2124 - acc: 0.92 - ETA: 51s - loss: 0.2126 - acc: 0.92 - ETA: 51s - loss: 0.2122 - acc: 0.92 - ETA: 50s - loss: 0.2147 - acc: 0.92 - ETA: 50s - loss: 0.2147 - acc: 0.92 - ETA: 50s - loss: 0.2145 - acc: 0.92 - ETA: 49s - loss: 0.2139 - acc: 0.92 - ETA: 49s - loss: 0.2133 - acc: 0.92 - ETA: 49s - loss: 0.2142 - acc: 0.92 - ETA: 49s - loss: 0.2150 - acc: 0.92 - ETA: 48s - loss: 0.2153 - acc: 0.92 - ETA: 48s - loss: 0.2163 - acc: 0.92 - ETA: 48s - loss: 0.2161 - acc: 0.92 - ETA: 48s - loss: 0.2159 - acc: 0.92 - ETA: 47s - loss: 0.2159 - acc: 0.92 - ETA: 47s - loss: 0.2161 - acc: 0.92 - ETA: 47s - loss: 0.2162 - acc: 0.92 - ETA: 47s - loss: 0.2156 - acc: 0.92 - ETA: 46s - loss: 0.2151 - acc: 0.92 - ETA: 46s - loss: 0.2149 - acc: 0.92 - ETA: 46s - loss: 0.2146 - acc: 0.92 - ETA: 46s - loss: 0.2152 - acc: 0.92 - ETA: 45s - loss: 0.2151 - acc: 0.92 - ETA: 45s - loss: 0.2154 - acc: 0.92 - ETA: 45s - loss: 0.2150 - acc: 0.92 - ETA: 44s - loss: 0.2144 - acc: 0.92 - ETA: 44s - loss: 0.2147 - acc: 0.92 - ETA: 44s - loss: 0.2145 - acc: 0.92 - ETA: 44s - loss: 0.2139 - acc: 0.92 - ETA: 43s - loss: 0.2140 - acc: 0.92 - ETA: 43s - loss: 0.2136 - acc: 0.92 - ETA: 43s - loss: 0.2134 - acc: 0.92 - ETA: 43s - loss: 0.2129 - acc: 0.92 - ETA: 42s - loss: 0.2124 - acc: 0.92 - ETA: 42s - loss: 0.2137 - acc: 0.92 - ETA: 42s - loss: 0.2133 - acc: 0.92 - ETA: 42s - loss: 0.2130 - acc: 0.92 - ETA: 41s - loss: 0.2131 - acc: 0.92 - ETA: 41s - loss: 0.2134 - acc: 0.92 - ETA: 41s - loss: 0.2129 - acc: 0.92 - ETA: 41s - loss: 0.2124 - acc: 0.92 - ETA: 40s - loss: 0.2120 - acc: 0.92 - ETA: 40s - loss: 0.2119 - acc: 0.92 - ETA: 40s - loss: 0.2119 - acc: 0.92 - ETA: 40s - loss: 0.2137 - acc: 0.92 - ETA: 39s - loss: 0.2152 - acc: 0.92 - ETA: 39s - loss: 0.2153 - acc: 0.92 - ETA: 39s - loss: 0.2154 - acc: 0.92 - ETA: 39s - loss: 0.2159 - acc: 0.92 - ETA: 38s - loss: 0.2165 - acc: 0.92 - ETA: 38s - loss: 0.2167 - acc: 0.92 - ETA: 38s - loss: 0.2166 - acc: 0.92 - ETA: 38s - loss: 0.2163 - acc: 0.92 - ETA: 37s - loss: 0.2160 - acc: 0.92 - ETA: 37s - loss: 0.2157 - acc: 0.92 - ETA: 37s - loss: 0.2156 - acc: 0.92 - ETA: 37s - loss: 0.2152 - acc: 0.92 - ETA: 36s - loss: 0.2154 - acc: 0.92 - ETA: 36s - loss: 0.2154 - acc: 0.92 - ETA: 36s - loss: 0.2149 - acc: 0.92 - ETA: 36s - loss: 0.2151 - acc: 0.92 - ETA: 35s - loss: 0.2164 - acc: 0.92 - ETA: 35s - loss: 0.2161 - acc: 0.92 - ETA: 35s - loss: 0.2169 - acc: 0.92 - ETA: 35s - loss: 0.2164 - acc: 0.92 - ETA: 34s - loss: 0.2169 - acc: 0.92 - ETA: 34s - loss: 0.2167 - acc: 0.92 - ETA: 34s - loss: 0.2161 - acc: 0.92 - ETA: 34s - loss: 0.2163 - acc: 0.92 - ETA: 33s - loss: 0.2165 - acc: 0.92 - ETA: 33s - loss: 0.2167 - acc: 0.92 - ETA: 33s - loss: 0.2169 - acc: 0.92 - ETA: 32s - loss: 0.2169 - acc: 0.92 - ETA: 32s - loss: 0.2173 - acc: 0.92 - ETA: 32s - loss: 0.2172 - acc: 0.92 - ETA: 32s - loss: 0.2179 - acc: 0.92 - ETA: 31s - loss: 0.2174 - acc: 0.92 - ETA: 31s - loss: 0.2172 - acc: 0.92 - ETA: 31s - loss: 0.2171 - acc: 0.92 - ETA: 31s - loss: 0.2169 - acc: 0.92 - ETA: 30s - loss: 0.2168 - acc: 0.92 - ETA: 30s - loss: 0.2165 - acc: 0.92 - ETA: 30s - loss: 0.2162 - acc: 0.92 - ETA: 30s - loss: 0.2162 - acc: 0.92 - ETA: 29s - loss: 0.2173 - acc: 0.92 - ETA: 29s - loss: 0.2172 - acc: 0.92 - ETA: 29s - loss: 0.2170 - acc: 0.92 - ETA: 29s - loss: 0.2168 - acc: 0.92 - ETA: 28s - loss: 0.2163 - acc: 0.92 - ETA: 28s - loss: 0.2162 - acc: 0.92 - ETA: 28s - loss: 0.2161 - acc: 0.92 - ETA: 28s - loss: 0.2160 - acc: 0.92 - ETA: 27s - loss: 0.2161 - acc: 0.92 - ETA: 27s - loss: 0.2159 - acc: 0.92 - ETA: 27s - loss: 0.2156 - acc: 0.92 - ETA: 27s - loss: 0.2155 - acc: 0.92 - ETA: 26s - loss: 0.2159 - acc: 0.92 - ETA: 26s - loss: 0.2159 - acc: 0.92 - ETA: 26s - loss: 0.2159 - acc: 0.92 - ETA: 26s - loss: 0.2160 - acc: 0.92 - ETA: 25s - loss: 0.2155 - acc: 0.92 - ETA: 25s - loss: 0.2152 - acc: 0.92 - ETA: 25s - loss: 0.2159 - acc: 0.92 - ETA: 25s - loss: 0.2166 - acc: 0.92 - ETA: 24s - loss: 0.2164 - acc: 0.92 - ETA: 24s - loss: 0.2170 - acc: 0.92 - ETA: 24s - loss: 0.2167 - acc: 0.92 - ETA: 23s - loss: 0.2164 - acc: 0.92 - ETA: 23s - loss: 0.2164 - acc: 0.92 - ETA: 23s - loss: 0.2168 - acc: 0.92 - ETA: 23s - loss: 0.2167 - acc: 0.92 - ETA: 22s - loss: 0.2163 - acc: 0.92 - ETA: 22s - loss: 0.2161 - acc: 0.92 - ETA: 22s - loss: 0.2158 - acc: 0.92 - ETA: 22s - loss: 0.2157 - acc: 0.92 - ETA: 21s - loss: 0.2154 - acc: 0.92 - ETA: 21s - loss: 0.2152 - acc: 0.92 - ETA: 21s - loss: 0.2148 - acc: 0.92 - ETA: 21s - loss: 0.2145 - acc: 0.92 - ETA: 20s - loss: 0.2142 - acc: 0.92 - ETA: 20s - loss: 0.2138 - acc: 0.92 - ETA: 20s - loss: 0.2141 - acc: 0.92 - ETA: 20s - loss: 0.2138 - acc: 0.92 - ETA: 19s - loss: 0.2136 - acc: 0.92 - ETA: 19s - loss: 0.2135 - acc: 0.92 - ETA: 19s - loss: 0.2133 - acc: 0.92 - ETA: 19s - loss: 0.2129 - acc: 0.92 - ETA: 18s - loss: 0.2132 - acc: 0.92 - ETA: 18s - loss: 0.2134 - acc: 0.92 - ETA: 18s - loss: 0.2131 - acc: 0.92 - ETA: 18s - loss: 0.2129 - acc: 0.92 - ETA: 17s - loss: 0.2125 - acc: 0.92 - ETA: 17s - loss: 0.2126 - acc: 0.92 - ETA: 17s - loss: 0.2128 - acc: 0.92 - ETA: 17s - loss: 0.2129 - acc: 0.92 - ETA: 16s - loss: 0.2137 - acc: 0.92 - ETA: 16s - loss: 0.2133 - acc: 0.92 - ETA: 16s - loss: 0.2132 - acc: 0.92 - ETA: 16s - loss: 0.2132 - acc: 0.92 - ETA: 15s - loss: 0.2129 - acc: 0.92 - ETA: 15s - loss: 0.2131 - acc: 0.92 - ETA: 15s - loss: 0.2129 - acc: 0.92 - ETA: 15s - loss: 0.2125 - acc: 0.92 - ETA: 14s - loss: 0.2130 - acc: 0.92 - ETA: 14s - loss: 0.2127 - acc: 0.92 - ETA: 14s - loss: 0.2127 - acc: 0.92 - ETA: 14s - loss: 0.2127 - acc: 0.92 - ETA: 13s - loss: 0.2124 - acc: 0.92 - ETA: 13s - loss: 0.2125 - acc: 0.92 - ETA: 13s - loss: 0.2123 - acc: 0.92 - ETA: 13s - loss: 0.2125 - acc: 0.92 - ETA: 12s - loss: 0.2127 - acc: 0.92 - ETA: 12s - loss: 0.2128 - acc: 0.92 - ETA: 12s - loss: 0.2127 - acc: 0.92 - ETA: 11s - loss: 0.2129 - acc: 0.92 - ETA: 11s - loss: 0.2131 - acc: 0.92 - ETA: 11s - loss: 0.2133 - acc: 0.92 - ETA: 11s - loss: 0.2133 - acc: 0.92 - ETA: 10s - loss: 0.2129 - acc: 0.92 - ETA: 10s - loss: 0.2127 - acc: 0.92 - ETA: 10s - loss: 0.2128 - acc: 0.92 - ETA: 10s - loss: 0.2126 - acc: 0.92 - ETA: 9s - loss: 0.2122 - acc: 0.9252 - ETA: 9s - loss: 0.2120 - acc: 0.925 - ETA: 9s - loss: 0.2115 - acc: 0.925 - ETA: 9s - loss: 0.2114 - acc: 0.925 - ETA: 8s - loss: 0.2115 - acc: 0.925 - ETA: 8s - loss: 0.2115 - acc: 0.925 - ETA: 8s - loss: 0.2112 - acc: 0.925 - ETA: 8s - loss: 0.2111 - acc: 0.925 - ETA: 7s - loss: 0.2110 - acc: 0.925 - ETA: 7s - loss: 0.2109 - acc: 0.925 - ETA: 7s - loss: 0.2115 - acc: 0.925 - ETA: 7s - loss: 0.2117 - acc: 0.925 - ETA: 6s - loss: 0.2117 - acc: 0.925 - ETA: 6s - loss: 0.2119 - acc: 0.925 - ETA: 6s - loss: 0.2118 - acc: 0.925 - ETA: 6s - loss: 0.2117 - acc: 0.925 - ETA: 5s - loss: 0.2119 - acc: 0.925 - ETA: 5s - loss: 0.2116 - acc: 0.925 - ETA: 5s - loss: 0.2117 - acc: 0.925 - ETA: 5s - loss: 0.2116 - acc: 0.925 - ETA: 4s - loss: 0.2119 - acc: 0.925 - ETA: 4s - loss: 0.2117 - acc: 0.925 - ETA: 4s - loss: 0.2116 - acc: 0.925 - ETA: 4s - loss: 0.2114 - acc: 0.925 - ETA: 3s - loss: 0.2116 - acc: 0.925 - ETA: 3s - loss: 0.2115 - acc: 0.925 - ETA: 3s - loss: 0.2113 - acc: 0.925 - ETA: 3s - loss: 0.2115 - acc: 0.925 - ETA: 2s - loss: 0.2118 - acc: 0.925 - ETA: 2s - loss: 0.2120 - acc: 0.925 - ETA: 2s - loss: 0.2118 - acc: 0.925 - ETA: 2s - loss: 0.2114 - acc: 0.925 - ETA: 1s - loss: 0.2112 - acc: 0.9256426/427 [============================>.] - ETA: 1s - loss: 0.2110 - acc: 0.925 - ETA: 1s - loss: 0.2108 - acc: 0.925 - ETA: 1s - loss: 0.2104 - acc: 0.926 - ETA: 0s - loss: 0.2103 - acc: 0.926 - ETA: 0s - loss: 0.2101 - acc: 0.926 - ETA: 0s - loss: 0.2101 - acc: 0.9261\n",
      "Epoch 00007: val_loss improved from 0.40438 to 0.39959, saving model to saved_models/weights.aug.best.hdf5\n",
      "427/427 [==============================] - 111s 259ms/step - loss: 0.2099 - acc: 0.9263 - val_loss: 0.3996 - val_acc: 0.8519\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 2:14 - loss: 0.0710 - acc: 1.000 - ETA: 1:32 - loss: 0.0501 - acc: 1.000 - ETA: 1:46 - loss: 0.1203 - acc: 0.966 - ETA: 1:48 - loss: 0.1378 - acc: 0.962 - ETA: 1:48 - loss: 0.1287 - acc: 0.970 - ETA: 1:47 - loss: 0.1281 - acc: 0.966 - ETA: 1:46 - loss: 0.1315 - acc: 0.957 - ETA: 1:46 - loss: 0.1339 - acc: 0.956 - ETA: 1:46 - loss: 0.1401 - acc: 0.955 - ETA: 1:39 - loss: 0.1341 - acc: 0.960 - ETA: 1:39 - loss: 0.1392 - acc: 0.959 - ETA: 1:39 - loss: 0.1439 - acc: 0.958 - ETA: 1:40 - loss: 0.1574 - acc: 0.950 - ETA: 1:40 - loss: 0.1605 - acc: 0.946 - ETA: 1:39 - loss: 0.1629 - acc: 0.940 - ETA: 1:39 - loss: 0.1749 - acc: 0.934 - ETA: 1:39 - loss: 0.1838 - acc: 0.932 - ETA: 1:39 - loss: 0.1759 - acc: 0.936 - ETA: 1:39 - loss: 0.1693 - acc: 0.939 - ETA: 1:39 - loss: 0.1899 - acc: 0.927 - ETA: 1:39 - loss: 0.1951 - acc: 0.923 - ETA: 1:38 - loss: 0.1983 - acc: 0.922 - ETA: 1:38 - loss: 0.2029 - acc: 0.921 - ETA: 1:39 - loss: 0.2061 - acc: 0.918 - ETA: 1:40 - loss: 0.2020 - acc: 0.920 - ETA: 1:40 - loss: 0.2109 - acc: 0.915 - ETA: 1:41 - loss: 0.2085 - acc: 0.918 - ETA: 1:38 - loss: 0.2047 - acc: 0.921 - ETA: 1:38 - loss: 0.2061 - acc: 0.920 - ETA: 1:38 - loss: 0.2083 - acc: 0.918 - ETA: 1:38 - loss: 0.2129 - acc: 0.916 - ETA: 1:37 - loss: 0.2145 - acc: 0.917 - ETA: 1:37 - loss: 0.2128 - acc: 0.918 - ETA: 1:37 - loss: 0.2083 - acc: 0.919 - ETA: 1:37 - loss: 0.2039 - acc: 0.921 - ETA: 1:37 - loss: 0.2009 - acc: 0.922 - ETA: 1:37 - loss: 0.1979 - acc: 0.924 - ETA: 1:37 - loss: 0.1960 - acc: 0.925 - ETA: 1:37 - loss: 0.1934 - acc: 0.926 - ETA: 1:37 - loss: 0.1939 - acc: 0.926 - ETA: 1:37 - loss: 0.1946 - acc: 0.926 - ETA: 1:36 - loss: 0.1963 - acc: 0.926 - ETA: 1:36 - loss: 0.1951 - acc: 0.926 - ETA: 1:36 - loss: 0.2027 - acc: 0.925 - ETA: 1:36 - loss: 0.2120 - acc: 0.921 - ETA: 1:36 - loss: 0.2116 - acc: 0.920 - ETA: 1:36 - loss: 0.2080 - acc: 0.922 - ETA: 1:36 - loss: 0.2060 - acc: 0.921 - ETA: 1:36 - loss: 0.2042 - acc: 0.922 - ETA: 1:36 - loss: 0.2022 - acc: 0.923 - ETA: 1:36 - loss: 0.2027 - acc: 0.923 - ETA: 1:36 - loss: 0.2015 - acc: 0.924 - ETA: 1:36 - loss: 0.2005 - acc: 0.924 - ETA: 1:34 - loss: 0.2002 - acc: 0.925 - ETA: 1:34 - loss: 0.2002 - acc: 0.924 - ETA: 1:34 - loss: 0.2000 - acc: 0.925 - ETA: 1:34 - loss: 0.1978 - acc: 0.926 - ETA: 1:33 - loss: 0.1992 - acc: 0.925 - ETA: 1:33 - loss: 0.1971 - acc: 0.927 - ETA: 1:33 - loss: 0.2029 - acc: 0.925 - ETA: 1:32 - loss: 0.2062 - acc: 0.922 - ETA: 1:32 - loss: 0.2078 - acc: 0.921 - ETA: 1:32 - loss: 0.2049 - acc: 0.923 - ETA: 1:31 - loss: 0.2044 - acc: 0.922 - ETA: 1:31 - loss: 0.2079 - acc: 0.920 - ETA: 1:31 - loss: 0.2074 - acc: 0.921 - ETA: 1:31 - loss: 0.2082 - acc: 0.920 - ETA: 1:30 - loss: 0.2078 - acc: 0.919 - ETA: 1:30 - loss: 0.2087 - acc: 0.918 - ETA: 1:30 - loss: 0.2084 - acc: 0.918 - ETA: 1:30 - loss: 0.2088 - acc: 0.918 - ETA: 1:30 - loss: 0.2081 - acc: 0.919 - ETA: 1:30 - loss: 0.2068 - acc: 0.919 - ETA: 1:30 - loss: 0.2076 - acc: 0.919 - ETA: 1:29 - loss: 0.2056 - acc: 0.920 - ETA: 1:29 - loss: 0.2066 - acc: 0.921 - ETA: 1:28 - loss: 0.2065 - acc: 0.921 - ETA: 1:28 - loss: 0.2060 - acc: 0.921 - ETA: 1:28 - loss: 0.2058 - acc: 0.921 - ETA: 1:28 - loss: 0.2079 - acc: 0.920 - ETA: 1:28 - loss: 0.2067 - acc: 0.921 - ETA: 1:27 - loss: 0.2051 - acc: 0.922 - ETA: 1:27 - loss: 0.2047 - acc: 0.922 - ETA: 1:27 - loss: 0.2046 - acc: 0.922 - ETA: 1:27 - loss: 0.2032 - acc: 0.922 - ETA: 1:26 - loss: 0.2027 - acc: 0.923 - ETA: 1:26 - loss: 0.2016 - acc: 0.923 - ETA: 1:26 - loss: 0.2021 - acc: 0.923 - ETA: 1:25 - loss: 0.2042 - acc: 0.922 - ETA: 1:25 - loss: 0.2031 - acc: 0.922 - ETA: 1:25 - loss: 0.2036 - acc: 0.923 - ETA: 1:25 - loss: 0.2024 - acc: 0.923 - ETA: 1:24 - loss: 0.2012 - acc: 0.924 - ETA: 1:24 - loss: 0.2005 - acc: 0.924 - ETA: 1:24 - loss: 0.1995 - acc: 0.924 - ETA: 1:24 - loss: 0.1981 - acc: 0.925 - ETA: 1:24 - loss: 0.1989 - acc: 0.925 - ETA: 1:24 - loss: 0.1998 - acc: 0.925 - ETA: 1:23 - loss: 0.2017 - acc: 0.924 - ETA: 1:23 - loss: 0.2000 - acc: 0.925 - ETA: 1:23 - loss: 0.1990 - acc: 0.925 - ETA: 1:22 - loss: 0.1986 - acc: 0.926 - ETA: 1:22 - loss: 0.1991 - acc: 0.925 - ETA: 1:22 - loss: 0.2003 - acc: 0.924 - ETA: 1:22 - loss: 0.2007 - acc: 0.923 - ETA: 1:21 - loss: 0.2040 - acc: 0.922 - ETA: 1:21 - loss: 0.2037 - acc: 0.922 - ETA: 1:21 - loss: 0.2034 - acc: 0.923 - ETA: 1:21 - loss: 0.2033 - acc: 0.922 - ETA: 1:21 - loss: 0.2033 - acc: 0.922 - ETA: 1:20 - loss: 0.2021 - acc: 0.923 - ETA: 1:20 - loss: 0.2022 - acc: 0.923 - ETA: 1:20 - loss: 0.2010 - acc: 0.923 - ETA: 1:20 - loss: 0.1997 - acc: 0.924 - ETA: 1:19 - loss: 0.1985 - acc: 0.925 - ETA: 1:19 - loss: 0.1978 - acc: 0.925 - ETA: 1:19 - loss: 0.1977 - acc: 0.925 - ETA: 1:19 - loss: 0.1989 - acc: 0.925 - ETA: 1:19 - loss: 0.1982 - acc: 0.925 - ETA: 1:18 - loss: 0.1991 - acc: 0.925 - ETA: 1:18 - loss: 0.1991 - acc: 0.925 - ETA: 1:18 - loss: 0.1987 - acc: 0.925 - ETA: 1:18 - loss: 0.1982 - acc: 0.926 - ETA: 1:17 - loss: 0.1990 - acc: 0.926 - ETA: 1:17 - loss: 0.2014 - acc: 0.925 - ETA: 1:17 - loss: 0.2009 - acc: 0.925 - ETA: 1:17 - loss: 0.2001 - acc: 0.926 - ETA: 1:16 - loss: 0.1999 - acc: 0.926 - ETA: 1:16 - loss: 0.1988 - acc: 0.926 - ETA: 1:16 - loss: 0.1990 - acc: 0.926 - ETA: 1:15 - loss: 0.1999 - acc: 0.926 - ETA: 1:15 - loss: 0.1989 - acc: 0.926 - ETA: 1:15 - loss: 0.1992 - acc: 0.926 - ETA: 1:14 - loss: 0.1996 - acc: 0.926 - ETA: 1:14 - loss: 0.1988 - acc: 0.926 - ETA: 1:14 - loss: 0.1987 - acc: 0.926 - ETA: 1:14 - loss: 0.2003 - acc: 0.926 - ETA: 1:13 - loss: 0.1993 - acc: 0.926 - ETA: 1:13 - loss: 0.2015 - acc: 0.926 - ETA: 1:13 - loss: 0.2015 - acc: 0.926 - ETA: 1:13 - loss: 0.2015 - acc: 0.926 - ETA: 1:12 - loss: 0.2017 - acc: 0.926 - ETA: 1:12 - loss: 0.2010 - acc: 0.926 - ETA: 1:12 - loss: 0.2005 - acc: 0.926 - ETA: 1:12 - loss: 0.1996 - acc: 0.926 - ETA: 1:12 - loss: 0.2013 - acc: 0.926 - ETA: 1:11 - loss: 0.2018 - acc: 0.926 - ETA: 1:11 - loss: 0.2010 - acc: 0.927 - ETA: 1:11 - loss: 0.2012 - acc: 0.926 - ETA: 1:11 - loss: 0.2007 - acc: 0.927 - ETA: 1:10 - loss: 0.2000 - acc: 0.927 - ETA: 1:10 - loss: 0.1991 - acc: 0.927 - ETA: 1:10 - loss: 0.1992 - acc: 0.927 - ETA: 1:09 - loss: 0.2000 - acc: 0.926 - ETA: 1:09 - loss: 0.2003 - acc: 0.926 - ETA: 1:09 - loss: 0.1995 - acc: 0.927 - ETA: 1:09 - loss: 0.1987 - acc: 0.927 - ETA: 1:09 - loss: 0.1993 - acc: 0.926 - ETA: 1:08 - loss: 0.1990 - acc: 0.926 - ETA: 1:08 - loss: 0.1986 - acc: 0.926 - ETA: 1:08 - loss: 0.1991 - acc: 0.926 - ETA: 1:08 - loss: 0.1981 - acc: 0.926 - ETA: 1:08 - loss: 0.2004 - acc: 0.926 - ETA: 1:08 - loss: 0.2002 - acc: 0.926 - ETA: 1:07 - loss: 0.1999 - acc: 0.926 - ETA: 1:07 - loss: 0.1995 - acc: 0.927 - ETA: 1:07 - loss: 0.1991 - acc: 0.927 - ETA: 1:07 - loss: 0.1985 - acc: 0.927 - ETA: 1:07 - loss: 0.1980 - acc: 0.927 - ETA: 1:06 - loss: 0.1983 - acc: 0.927 - ETA: 1:06 - loss: 0.2004 - acc: 0.926 - ETA: 1:06 - loss: 0.2009 - acc: 0.926 - ETA: 1:05 - loss: 0.2018 - acc: 0.925 - ETA: 1:05 - loss: 0.2011 - acc: 0.926 - ETA: 1:05 - loss: 0.2008 - acc: 0.926 - ETA: 1:05 - loss: 0.2004 - acc: 0.926 - ETA: 1:04 - loss: 0.1997 - acc: 0.926 - ETA: 1:04 - loss: 0.2004 - acc: 0.926 - ETA: 1:04 - loss: 0.2001 - acc: 0.926 - ETA: 1:03 - loss: 0.2000 - acc: 0.926 - ETA: 1:03 - loss: 0.2010 - acc: 0.925 - ETA: 1:03 - loss: 0.2007 - acc: 0.925 - ETA: 1:03 - loss: 0.2000 - acc: 0.926 - ETA: 1:02 - loss: 0.1996 - acc: 0.926 - ETA: 1:02 - loss: 0.1994 - acc: 0.926 - ETA: 1:02 - loss: 0.2000 - acc: 0.925 - ETA: 1:02 - loss: 0.2014 - acc: 0.925 - ETA: 1:01 - loss: 0.2016 - acc: 0.925 - ETA: 1:01 - loss: 0.2009 - acc: 0.925 - ETA: 1:01 - loss: 0.2015 - acc: 0.925 - ETA: 1:01 - loss: 0.2012 - acc: 0.925 - ETA: 1:00 - loss: 0.2019 - acc: 0.925 - ETA: 1:00 - loss: 0.2023 - acc: 0.925 - ETA: 1:00 - loss: 0.2018 - acc: 0.925 - ETA: 1:00 - loss: 0.2019 - acc: 0.926 - ETA: 59s - loss: 0.2025 - acc: 0.925 - ETA: 59s - loss: 0.2019 - acc: 0.92 - ETA: 59s - loss: 0.2012 - acc: 0.92 - ETA: 58s - loss: 0.2008 - acc: 0.92 - ETA: 58s - loss: 0.2003 - acc: 0.92 - ETA: 58s - loss: 0.2008 - acc: 0.92 - ETA: 58s - loss: 0.2005 - acc: 0.92 - ETA: 57s - loss: 0.2000 - acc: 0.92 - ETA: 57s - loss: 0.1992 - acc: 0.92 - ETA: 57s - loss: 0.1988 - acc: 0.9277420/427 [============================>.] - ETA: 56s - loss: 0.1984 - acc: 0.92 - ETA: 56s - loss: 0.1986 - acc: 0.92 - ETA: 56s - loss: 0.1983 - acc: 0.92 - ETA: 56s - loss: 0.1983 - acc: 0.92 - ETA: 55s - loss: 0.1981 - acc: 0.92 - ETA: 55s - loss: 0.1990 - acc: 0.92 - ETA: 55s - loss: 0.1998 - acc: 0.92 - ETA: 55s - loss: 0.2010 - acc: 0.92 - ETA: 54s - loss: 0.2008 - acc: 0.92 - ETA: 54s - loss: 0.2006 - acc: 0.92 - ETA: 54s - loss: 0.2001 - acc: 0.92 - ETA: 54s - loss: 0.2003 - acc: 0.92 - ETA: 53s - loss: 0.1999 - acc: 0.92 - ETA: 53s - loss: 0.2002 - acc: 0.92 - ETA: 53s - loss: 0.1997 - acc: 0.92 - ETA: 53s - loss: 0.2027 - acc: 0.92 - ETA: 52s - loss: 0.2022 - acc: 0.92 - ETA: 52s - loss: 0.2023 - acc: 0.92 - ETA: 52s - loss: 0.2024 - acc: 0.92 - ETA: 52s - loss: 0.2030 - acc: 0.92 - ETA: 51s - loss: 0.2023 - acc: 0.92 - ETA: 51s - loss: 0.2023 - acc: 0.92 - ETA: 51s - loss: 0.2022 - acc: 0.92 - ETA: 51s - loss: 0.2027 - acc: 0.92 - ETA: 50s - loss: 0.2023 - acc: 0.92 - ETA: 50s - loss: 0.2018 - acc: 0.92 - ETA: 50s - loss: 0.2013 - acc: 0.92 - ETA: 50s - loss: 0.2020 - acc: 0.92 - ETA: 49s - loss: 0.2029 - acc: 0.92 - ETA: 49s - loss: 0.2037 - acc: 0.92 - ETA: 49s - loss: 0.2039 - acc: 0.92 - ETA: 49s - loss: 0.2037 - acc: 0.92 - ETA: 48s - loss: 0.2033 - acc: 0.92 - ETA: 48s - loss: 0.2028 - acc: 0.92 - ETA: 48s - loss: 0.2023 - acc: 0.92 - ETA: 48s - loss: 0.2024 - acc: 0.92 - ETA: 47s - loss: 0.2022 - acc: 0.92 - ETA: 47s - loss: 0.2019 - acc: 0.92 - ETA: 47s - loss: 0.2014 - acc: 0.92 - ETA: 47s - loss: 0.2010 - acc: 0.92 - ETA: 46s - loss: 0.2018 - acc: 0.92 - ETA: 46s - loss: 0.2027 - acc: 0.92 - ETA: 46s - loss: 0.2023 - acc: 0.92 - ETA: 45s - loss: 0.2025 - acc: 0.92 - ETA: 45s - loss: 0.2019 - acc: 0.92 - ETA: 45s - loss: 0.2016 - acc: 0.92 - ETA: 45s - loss: 0.2012 - acc: 0.92 - ETA: 44s - loss: 0.2010 - acc: 0.92 - ETA: 44s - loss: 0.2009 - acc: 0.92 - ETA: 44s - loss: 0.2003 - acc: 0.92 - ETA: 44s - loss: 0.2001 - acc: 0.92 - ETA: 43s - loss: 0.1996 - acc: 0.92 - ETA: 43s - loss: 0.1991 - acc: 0.92 - ETA: 43s - loss: 0.1986 - acc: 0.92 - ETA: 43s - loss: 0.1981 - acc: 0.92 - ETA: 42s - loss: 0.1978 - acc: 0.92 - ETA: 42s - loss: 0.1974 - acc: 0.92 - ETA: 42s - loss: 0.1977 - acc: 0.92 - ETA: 42s - loss: 0.1972 - acc: 0.92 - ETA: 41s - loss: 0.1968 - acc: 0.92 - ETA: 41s - loss: 0.1964 - acc: 0.93 - ETA: 41s - loss: 0.1971 - acc: 0.92 - ETA: 41s - loss: 0.1969 - acc: 0.92 - ETA: 40s - loss: 0.1965 - acc: 0.93 - ETA: 40s - loss: 0.1962 - acc: 0.93 - ETA: 40s - loss: 0.1958 - acc: 0.93 - ETA: 39s - loss: 0.1958 - acc: 0.93 - ETA: 39s - loss: 0.1955 - acc: 0.93 - ETA: 39s - loss: 0.1956 - acc: 0.93 - ETA: 39s - loss: 0.1958 - acc: 0.93 - ETA: 38s - loss: 0.1961 - acc: 0.93 - ETA: 38s - loss: 0.1966 - acc: 0.93 - ETA: 38s - loss: 0.1967 - acc: 0.92 - ETA: 38s - loss: 0.1970 - acc: 0.92 - ETA: 37s - loss: 0.1974 - acc: 0.92 - ETA: 37s - loss: 0.1976 - acc: 0.92 - ETA: 37s - loss: 0.1974 - acc: 0.92 - ETA: 37s - loss: 0.1975 - acc: 0.92 - ETA: 36s - loss: 0.1981 - acc: 0.92 - ETA: 36s - loss: 0.1978 - acc: 0.92 - ETA: 36s - loss: 0.1984 - acc: 0.92 - ETA: 36s - loss: 0.1988 - acc: 0.92 - ETA: 35s - loss: 0.1987 - acc: 0.92 - ETA: 35s - loss: 0.1983 - acc: 0.92 - ETA: 35s - loss: 0.1983 - acc: 0.92 - ETA: 35s - loss: 0.1985 - acc: 0.92 - ETA: 34s - loss: 0.1980 - acc: 0.92 - ETA: 34s - loss: 0.1976 - acc: 0.92 - ETA: 34s - loss: 0.1974 - acc: 0.92 - ETA: 34s - loss: 0.1971 - acc: 0.92 - ETA: 33s - loss: 0.1970 - acc: 0.92 - ETA: 33s - loss: 0.1971 - acc: 0.92 - ETA: 33s - loss: 0.1967 - acc: 0.92 - ETA: 33s - loss: 0.1963 - acc: 0.93 - ETA: 32s - loss: 0.1960 - acc: 0.93 - ETA: 32s - loss: 0.1956 - acc: 0.93 - ETA: 32s - loss: 0.1952 - acc: 0.93 - ETA: 31s - loss: 0.1948 - acc: 0.93 - ETA: 31s - loss: 0.1946 - acc: 0.93 - ETA: 31s - loss: 0.1960 - acc: 0.93 - ETA: 31s - loss: 0.1956 - acc: 0.93 - ETA: 30s - loss: 0.1952 - acc: 0.93 - ETA: 30s - loss: 0.1949 - acc: 0.93 - ETA: 30s - loss: 0.1954 - acc: 0.93 - ETA: 30s - loss: 0.1951 - acc: 0.93 - ETA: 29s - loss: 0.1950 - acc: 0.93 - ETA: 29s - loss: 0.1956 - acc: 0.93 - ETA: 29s - loss: 0.1953 - acc: 0.93 - ETA: 29s - loss: 0.1956 - acc: 0.93 - ETA: 28s - loss: 0.1959 - acc: 0.93 - ETA: 28s - loss: 0.1954 - acc: 0.93 - ETA: 28s - loss: 0.1954 - acc: 0.93 - ETA: 28s - loss: 0.1953 - acc: 0.93 - ETA: 27s - loss: 0.1957 - acc: 0.93 - ETA: 27s - loss: 0.1959 - acc: 0.93 - ETA: 27s - loss: 0.1956 - acc: 0.93 - ETA: 27s - loss: 0.1953 - acc: 0.93 - ETA: 26s - loss: 0.1950 - acc: 0.93 - ETA: 26s - loss: 0.1949 - acc: 0.93 - ETA: 26s - loss: 0.1951 - acc: 0.93 - ETA: 26s - loss: 0.1951 - acc: 0.93 - ETA: 25s - loss: 0.1952 - acc: 0.93 - ETA: 25s - loss: 0.1951 - acc: 0.93 - ETA: 25s - loss: 0.1950 - acc: 0.93 - ETA: 24s - loss: 0.1948 - acc: 0.93 - ETA: 24s - loss: 0.1950 - acc: 0.93 - ETA: 24s - loss: 0.1949 - acc: 0.93 - ETA: 24s - loss: 0.1947 - acc: 0.93 - ETA: 23s - loss: 0.1945 - acc: 0.93 - ETA: 23s - loss: 0.1948 - acc: 0.93 - ETA: 23s - loss: 0.1947 - acc: 0.93 - ETA: 23s - loss: 0.1944 - acc: 0.93 - ETA: 22s - loss: 0.1940 - acc: 0.93 - ETA: 22s - loss: 0.1941 - acc: 0.93 - ETA: 22s - loss: 0.1938 - acc: 0.93 - ETA: 22s - loss: 0.1938 - acc: 0.93 - ETA: 21s - loss: 0.1935 - acc: 0.93 - ETA: 21s - loss: 0.1932 - acc: 0.93 - ETA: 21s - loss: 0.1935 - acc: 0.93 - ETA: 21s - loss: 0.1943 - acc: 0.93 - ETA: 20s - loss: 0.1942 - acc: 0.93 - ETA: 20s - loss: 0.1944 - acc: 0.93 - ETA: 20s - loss: 0.1943 - acc: 0.93 - ETA: 20s - loss: 0.1944 - acc: 0.93 - ETA: 19s - loss: 0.1941 - acc: 0.93 - ETA: 19s - loss: 0.1938 - acc: 0.93 - ETA: 19s - loss: 0.1935 - acc: 0.93 - ETA: 19s - loss: 0.1934 - acc: 0.93 - ETA: 18s - loss: 0.1931 - acc: 0.93 - ETA: 18s - loss: 0.1938 - acc: 0.93 - ETA: 18s - loss: 0.1940 - acc: 0.93 - ETA: 18s - loss: 0.1937 - acc: 0.93 - ETA: 17s - loss: 0.1935 - acc: 0.93 - ETA: 17s - loss: 0.1936 - acc: 0.93 - ETA: 17s - loss: 0.1935 - acc: 0.93 - ETA: 17s - loss: 0.1933 - acc: 0.93 - ETA: 16s - loss: 0.1938 - acc: 0.93 - ETA: 16s - loss: 0.1937 - acc: 0.93 - ETA: 16s - loss: 0.1942 - acc: 0.93 - ETA: 15s - loss: 0.1939 - acc: 0.93 - ETA: 15s - loss: 0.1937 - acc: 0.93 - ETA: 15s - loss: 0.1935 - acc: 0.93 - ETA: 15s - loss: 0.1931 - acc: 0.93 - ETA: 14s - loss: 0.1933 - acc: 0.93 - ETA: 14s - loss: 0.1938 - acc: 0.93 - ETA: 14s - loss: 0.1936 - acc: 0.93 - ETA: 14s - loss: 0.1934 - acc: 0.93 - ETA: 13s - loss: 0.1935 - acc: 0.93 - ETA: 13s - loss: 0.1933 - acc: 0.93 - ETA: 13s - loss: 0.1934 - acc: 0.93 - ETA: 13s - loss: 0.1935 - acc: 0.93 - ETA: 12s - loss: 0.1940 - acc: 0.93 - ETA: 12s - loss: 0.1943 - acc: 0.93 - ETA: 12s - loss: 0.1943 - acc: 0.93 - ETA: 12s - loss: 0.1941 - acc: 0.93 - ETA: 11s - loss: 0.1938 - acc: 0.93 - ETA: 11s - loss: 0.1937 - acc: 0.93 - ETA: 11s - loss: 0.1938 - acc: 0.93 - ETA: 11s - loss: 0.1938 - acc: 0.93 - ETA: 10s - loss: 0.1939 - acc: 0.93 - ETA: 10s - loss: 0.1937 - acc: 0.93 - ETA: 10s - loss: 0.1945 - acc: 0.93 - ETA: 10s - loss: 0.1945 - acc: 0.93 - ETA: 9s - loss: 0.1945 - acc: 0.9320 - ETA: 9s - loss: 0.1945 - acc: 0.931 - ETA: 9s - loss: 0.1942 - acc: 0.932 - ETA: 9s - loss: 0.1943 - acc: 0.932 - ETA: 8s - loss: 0.1941 - acc: 0.932 - ETA: 8s - loss: 0.1940 - acc: 0.932 - ETA: 8s - loss: 0.1944 - acc: 0.932 - ETA: 7s - loss: 0.1943 - acc: 0.931 - ETA: 7s - loss: 0.1946 - acc: 0.931 - ETA: 7s - loss: 0.1950 - acc: 0.931 - ETA: 7s - loss: 0.1947 - acc: 0.931 - ETA: 6s - loss: 0.1947 - acc: 0.931 - ETA: 6s - loss: 0.1944 - acc: 0.931 - ETA: 6s - loss: 0.1942 - acc: 0.932 - ETA: 6s - loss: 0.1942 - acc: 0.931 - ETA: 5s - loss: 0.1940 - acc: 0.931 - ETA: 5s - loss: 0.1942 - acc: 0.931 - ETA: 5s - loss: 0.1943 - acc: 0.931 - ETA: 5s - loss: 0.1947 - acc: 0.931 - ETA: 4s - loss: 0.1945 - acc: 0.931 - ETA: 4s - loss: 0.1947 - acc: 0.931 - ETA: 4s - loss: 0.1944 - acc: 0.932 - ETA: 4s - loss: 0.1942 - acc: 0.932 - ETA: 3s - loss: 0.1944 - acc: 0.931 - ETA: 3s - loss: 0.1945 - acc: 0.931 - ETA: 3s - loss: 0.1947 - acc: 0.931 - ETA: 3s - loss: 0.1945 - acc: 0.931 - ETA: 2s - loss: 0.1947 - acc: 0.931 - ETA: 2s - loss: 0.1949 - acc: 0.931 - ETA: 2s - loss: 0.1949 - acc: 0.931 - ETA: 2s - loss: 0.1951 - acc: 0.931 - ETA: 1s - loss: 0.1951 - acc: 0.9315"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/427 [============================>.] - ETA: 1s - loss: 0.1950 - acc: 0.931 - ETA: 1s - loss: 0.1947 - acc: 0.931 - ETA: 1s - loss: 0.1945 - acc: 0.931 - ETA: 0s - loss: 0.1946 - acc: 0.931 - ETA: 0s - loss: 0.1950 - acc: 0.931 - ETA: 0s - loss: 0.1953 - acc: 0.9316\n",
      "Epoch 00008: val_loss did not improve\n",
      "427/427 [==============================] - 112s 261ms/step - loss: 0.1951 - acc: 0.9316 - val_loss: 0.4101 - val_acc: 0.8575\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:44 - loss: 0.2212 - acc: 0.900 - ETA: 1:46 - loss: 0.2184 - acc: 0.900 - ETA: 1:25 - loss: 0.2917 - acc: 0.885 - ETA: 1:29 - loss: 0.2498 - acc: 0.901 - ETA: 1:33 - loss: 0.2291 - acc: 0.911 - ETA: 1:35 - loss: 0.2338 - acc: 0.909 - ETA: 1:36 - loss: 0.2232 - acc: 0.915 - ETA: 1:37 - loss: 0.2140 - acc: 0.919 - ETA: 1:37 - loss: 0.1958 - acc: 0.928 - ETA: 1:38 - loss: 0.1992 - acc: 0.930 - ETA: 1:38 - loss: 0.1911 - acc: 0.932 - ETA: 1:38 - loss: 0.1798 - acc: 0.938 - ETA: 1:39 - loss: 0.1780 - acc: 0.942 - ETA: 1:39 - loss: 0.1824 - acc: 0.939 - ETA: 1:38 - loss: 0.1863 - acc: 0.940 - ETA: 1:40 - loss: 0.1900 - acc: 0.937 - ETA: 1:41 - loss: 0.1862 - acc: 0.938 - ETA: 1:41 - loss: 0.1813 - acc: 0.939 - ETA: 1:42 - loss: 0.1795 - acc: 0.937 - ETA: 1:42 - loss: 0.1730 - acc: 0.940 - ETA: 1:41 - loss: 0.1688 - acc: 0.940 - ETA: 1:41 - loss: 0.1664 - acc: 0.943 - ETA: 1:41 - loss: 0.1699 - acc: 0.943 - ETA: 1:38 - loss: 0.2038 - acc: 0.940 - ETA: 1:38 - loss: 0.2165 - acc: 0.936 - ETA: 1:38 - loss: 0.2171 - acc: 0.937 - ETA: 1:38 - loss: 0.2157 - acc: 0.937 - ETA: 1:38 - loss: 0.2127 - acc: 0.939 - ETA: 1:37 - loss: 0.2147 - acc: 0.936 - ETA: 1:37 - loss: 0.2139 - acc: 0.935 - ETA: 1:37 - loss: 0.2140 - acc: 0.934 - ETA: 1:37 - loss: 0.2115 - acc: 0.934 - ETA: 1:36 - loss: 0.2169 - acc: 0.932 - ETA: 1:36 - loss: 0.2144 - acc: 0.934 - ETA: 1:36 - loss: 0.2145 - acc: 0.934 - ETA: 1:36 - loss: 0.2117 - acc: 0.935 - ETA: 1:36 - loss: 0.2068 - acc: 0.936 - ETA: 1:36 - loss: 0.2054 - acc: 0.937 - ETA: 1:36 - loss: 0.2098 - acc: 0.936 - ETA: 1:37 - loss: 0.2089 - acc: 0.936 - ETA: 1:37 - loss: 0.2071 - acc: 0.936 - ETA: 1:37 - loss: 0.2076 - acc: 0.937 - ETA: 1:37 - loss: 0.2048 - acc: 0.938 - ETA: 1:37 - loss: 0.2069 - acc: 0.937 - ETA: 1:37 - loss: 0.2081 - acc: 0.935 - ETA: 1:37 - loss: 0.2060 - acc: 0.937 - ETA: 1:37 - loss: 0.2049 - acc: 0.937 - ETA: 1:37 - loss: 0.2046 - acc: 0.936 - ETA: 1:37 - loss: 0.2023 - acc: 0.937 - ETA: 1:36 - loss: 0.2050 - acc: 0.936 - ETA: 1:35 - loss: 0.2062 - acc: 0.934 - ETA: 1:35 - loss: 0.2055 - acc: 0.935 - ETA: 1:34 - loss: 0.2065 - acc: 0.935 - ETA: 1:34 - loss: 0.2051 - acc: 0.935 - ETA: 1:34 - loss: 0.2090 - acc: 0.934 - ETA: 1:34 - loss: 0.2078 - acc: 0.934 - ETA: 1:33 - loss: 0.2064 - acc: 0.934 - ETA: 1:33 - loss: 0.2052 - acc: 0.934 - ETA: 1:33 - loss: 0.2041 - acc: 0.936 - ETA: 1:33 - loss: 0.2015 - acc: 0.937 - ETA: 1:32 - loss: 0.1989 - acc: 0.938 - ETA: 1:32 - loss: 0.1982 - acc: 0.937 - ETA: 1:32 - loss: 0.1978 - acc: 0.937 - ETA: 1:32 - loss: 0.1957 - acc: 0.938 - ETA: 1:32 - loss: 0.1944 - acc: 0.939 - ETA: 1:32 - loss: 0.1927 - acc: 0.940 - ETA: 1:32 - loss: 0.1927 - acc: 0.939 - ETA: 1:31 - loss: 0.1918 - acc: 0.940 - ETA: 1:31 - loss: 0.1942 - acc: 0.940 - ETA: 1:31 - loss: 0.1935 - acc: 0.941 - ETA: 1:31 - loss: 0.1951 - acc: 0.940 - ETA: 1:30 - loss: 0.1959 - acc: 0.939 - ETA: 1:29 - loss: 0.1949 - acc: 0.940 - ETA: 1:29 - loss: 0.1961 - acc: 0.939 - ETA: 1:29 - loss: 0.1969 - acc: 0.939 - ETA: 1:28 - loss: 0.1957 - acc: 0.939 - ETA: 1:28 - loss: 0.1938 - acc: 0.940 - ETA: 1:28 - loss: 0.1934 - acc: 0.939 - ETA: 1:28 - loss: 0.1919 - acc: 0.940 - ETA: 1:27 - loss: 0.1924 - acc: 0.939 - ETA: 1:27 - loss: 0.1913 - acc: 0.940 - ETA: 1:27 - loss: 0.1893 - acc: 0.941 - ETA: 1:27 - loss: 0.1915 - acc: 0.940 - ETA: 1:26 - loss: 0.1904 - acc: 0.940 - ETA: 1:26 - loss: 0.1891 - acc: 0.940 - ETA: 1:26 - loss: 0.1884 - acc: 0.941 - ETA: 1:26 - loss: 0.1880 - acc: 0.941 - ETA: 1:26 - loss: 0.1870 - acc: 0.941 - ETA: 1:26 - loss: 0.1881 - acc: 0.941 - ETA: 1:25 - loss: 0.1874 - acc: 0.941 - ETA: 1:25 - loss: 0.1869 - acc: 0.942 - ETA: 1:25 - loss: 0.1857 - acc: 0.942 - ETA: 1:24 - loss: 0.1844 - acc: 0.943 - ETA: 1:24 - loss: 0.1833 - acc: 0.943 - ETA: 1:23 - loss: 0.1838 - acc: 0.943 - ETA: 1:23 - loss: 0.1828 - acc: 0.944 - ETA: 1:23 - loss: 0.1832 - acc: 0.944 - ETA: 1:23 - loss: 0.1830 - acc: 0.944 - ETA: 1:22 - loss: 0.1822 - acc: 0.944 - ETA: 1:22 - loss: 0.1822 - acc: 0.943 - ETA: 1:22 - loss: 0.1832 - acc: 0.942 - ETA: 1:22 - loss: 0.1839 - acc: 0.941 - ETA: 1:22 - loss: 0.1847 - acc: 0.941 - ETA: 1:22 - loss: 0.1848 - acc: 0.941 - ETA: 1:21 - loss: 0.1841 - acc: 0.941 - ETA: 1:21 - loss: 0.1841 - acc: 0.941 - ETA: 1:21 - loss: 0.1830 - acc: 0.941 - ETA: 1:21 - loss: 0.1832 - acc: 0.941 - ETA: 1:20 - loss: 0.1823 - acc: 0.942 - ETA: 1:20 - loss: 0.1829 - acc: 0.942 - ETA: 1:20 - loss: 0.1830 - acc: 0.941 - ETA: 1:20 - loss: 0.1821 - acc: 0.942 - ETA: 1:20 - loss: 0.1821 - acc: 0.941 - ETA: 1:20 - loss: 0.1830 - acc: 0.941 - ETA: 1:19 - loss: 0.1821 - acc: 0.941 - ETA: 1:19 - loss: 0.1817 - acc: 0.941 - ETA: 1:19 - loss: 0.1812 - acc: 0.941 - ETA: 1:19 - loss: 0.1808 - acc: 0.941 - ETA: 1:18 - loss: 0.1816 - acc: 0.941 - ETA: 1:18 - loss: 0.1813 - acc: 0.941 - ETA: 1:17 - loss: 0.1823 - acc: 0.941 - ETA: 1:17 - loss: 0.1815 - acc: 0.942 - ETA: 1:17 - loss: 0.1809 - acc: 0.942 - ETA: 1:17 - loss: 0.1805 - acc: 0.942 - ETA: 1:16 - loss: 0.1805 - acc: 0.942 - ETA: 1:16 - loss: 0.1806 - acc: 0.941 - ETA: 1:16 - loss: 0.1798 - acc: 0.941 - ETA: 1:16 - loss: 0.1812 - acc: 0.941 - ETA: 1:15 - loss: 0.1807 - acc: 0.941 - ETA: 1:15 - loss: 0.1810 - acc: 0.941 - ETA: 1:15 - loss: 0.1811 - acc: 0.940 - ETA: 1:14 - loss: 0.1806 - acc: 0.940 - ETA: 1:14 - loss: 0.1798 - acc: 0.941 - ETA: 1:14 - loss: 0.1797 - acc: 0.941 - ETA: 1:14 - loss: 0.1807 - acc: 0.940 - ETA: 1:14 - loss: 0.1819 - acc: 0.940 - ETA: 1:13 - loss: 0.1818 - acc: 0.940 - ETA: 1:13 - loss: 0.1816 - acc: 0.939 - ETA: 1:13 - loss: 0.1810 - acc: 0.939 - ETA: 1:13 - loss: 0.1800 - acc: 0.940 - ETA: 1:12 - loss: 0.1801 - acc: 0.940 - ETA: 1:12 - loss: 0.1804 - acc: 0.940 - ETA: 1:12 - loss: 0.1806 - acc: 0.940 - ETA: 1:11 - loss: 0.1813 - acc: 0.939 - ETA: 1:11 - loss: 0.1807 - acc: 0.940 - ETA: 1:11 - loss: 0.1805 - acc: 0.940 - ETA: 1:11 - loss: 0.1796 - acc: 0.940 - ETA: 1:10 - loss: 0.1801 - acc: 0.940 - ETA: 1:10 - loss: 0.1799 - acc: 0.940 - ETA: 1:10 - loss: 0.1798 - acc: 0.940 - ETA: 1:10 - loss: 0.1801 - acc: 0.940 - ETA: 1:09 - loss: 0.1795 - acc: 0.940 - ETA: 1:09 - loss: 0.1795 - acc: 0.940 - ETA: 1:09 - loss: 0.1797 - acc: 0.940 - ETA: 1:09 - loss: 0.1794 - acc: 0.940 - ETA: 1:08 - loss: 0.1789 - acc: 0.940 - ETA: 1:08 - loss: 0.1793 - acc: 0.940 - ETA: 1:08 - loss: 0.1792 - acc: 0.940 - ETA: 1:08 - loss: 0.1783 - acc: 0.940 - ETA: 1:08 - loss: 0.1782 - acc: 0.940 - ETA: 1:07 - loss: 0.1793 - acc: 0.940 - ETA: 1:07 - loss: 0.1799 - acc: 0.939 - ETA: 1:07 - loss: 0.1815 - acc: 0.938 - ETA: 1:07 - loss: 0.1820 - acc: 0.938 - ETA: 1:06 - loss: 0.1816 - acc: 0.938 - ETA: 1:06 - loss: 0.1809 - acc: 0.939 - ETA: 1:06 - loss: 0.1810 - acc: 0.938 - ETA: 1:05 - loss: 0.1810 - acc: 0.938 - ETA: 1:05 - loss: 0.1804 - acc: 0.939 - ETA: 1:05 - loss: 0.1808 - acc: 0.938 - ETA: 1:05 - loss: 0.1814 - acc: 0.938 - ETA: 1:05 - loss: 0.1807 - acc: 0.938 - ETA: 1:04 - loss: 0.1805 - acc: 0.938 - ETA: 1:04 - loss: 0.1808 - acc: 0.938 - ETA: 1:04 - loss: 0.1804 - acc: 0.939 - ETA: 1:04 - loss: 0.1800 - acc: 0.939 - ETA: 1:03 - loss: 0.1795 - acc: 0.939 - ETA: 1:03 - loss: 0.1801 - acc: 0.939 - ETA: 1:03 - loss: 0.1796 - acc: 0.939 - ETA: 1:03 - loss: 0.1789 - acc: 0.939 - ETA: 1:02 - loss: 0.1790 - acc: 0.939 - ETA: 1:02 - loss: 0.1785 - acc: 0.940 - ETA: 1:02 - loss: 0.1782 - acc: 0.940 - ETA: 1:02 - loss: 0.1776 - acc: 0.940 - ETA: 1:01 - loss: 0.1771 - acc: 0.940 - ETA: 1:01 - loss: 0.1764 - acc: 0.941 - ETA: 1:01 - loss: 0.1765 - acc: 0.940 - ETA: 1:00 - loss: 0.1765 - acc: 0.940 - ETA: 1:00 - loss: 0.1767 - acc: 0.940 - ETA: 1:00 - loss: 0.1764 - acc: 0.940 - ETA: 1:00 - loss: 0.1757 - acc: 0.940 - ETA: 59s - loss: 0.1768 - acc: 0.940 - ETA: 59s - loss: 0.1762 - acc: 0.94 - ETA: 59s - loss: 0.1761 - acc: 0.94 - ETA: 59s - loss: 0.1765 - acc: 0.94 - ETA: 58s - loss: 0.1761 - acc: 0.94 - ETA: 58s - loss: 0.1755 - acc: 0.94 - ETA: 58s - loss: 0.1753 - acc: 0.94 - ETA: 57s - loss: 0.1759 - acc: 0.94 - ETA: 57s - loss: 0.1772 - acc: 0.94 - ETA: 57s - loss: 0.1770 - acc: 0.94 - ETA: 57s - loss: 0.1767 - acc: 0.94 - ETA: 57s - loss: 0.1764 - acc: 0.94 - ETA: 56s - loss: 0.1763 - acc: 0.94 - ETA: 56s - loss: 0.1761 - acc: 0.9407420/427 [============================>.] - ETA: 56s - loss: 0.1758 - acc: 0.94 - ETA: 56s - loss: 0.1761 - acc: 0.94 - ETA: 55s - loss: 0.1759 - acc: 0.94 - ETA: 55s - loss: 0.1771 - acc: 0.93 - ETA: 55s - loss: 0.1782 - acc: 0.93 - ETA: 55s - loss: 0.1779 - acc: 0.93 - ETA: 54s - loss: 0.1777 - acc: 0.93 - ETA: 54s - loss: 0.1778 - acc: 0.93 - ETA: 54s - loss: 0.1779 - acc: 0.93 - ETA: 54s - loss: 0.1778 - acc: 0.93 - ETA: 53s - loss: 0.1772 - acc: 0.93 - ETA: 53s - loss: 0.1774 - acc: 0.93 - ETA: 53s - loss: 0.1775 - acc: 0.93 - ETA: 53s - loss: 0.1776 - acc: 0.93 - ETA: 52s - loss: 0.1788 - acc: 0.93 - ETA: 52s - loss: 0.1789 - acc: 0.93 - ETA: 52s - loss: 0.1789 - acc: 0.93 - ETA: 52s - loss: 0.1789 - acc: 0.93 - ETA: 51s - loss: 0.1787 - acc: 0.93 - ETA: 51s - loss: 0.1788 - acc: 0.93 - ETA: 51s - loss: 0.1787 - acc: 0.93 - ETA: 50s - loss: 0.1786 - acc: 0.93 - ETA: 50s - loss: 0.1792 - acc: 0.93 - ETA: 50s - loss: 0.1788 - acc: 0.93 - ETA: 50s - loss: 0.1790 - acc: 0.93 - ETA: 50s - loss: 0.1788 - acc: 0.93 - ETA: 49s - loss: 0.1787 - acc: 0.93 - ETA: 49s - loss: 0.1786 - acc: 0.93 - ETA: 49s - loss: 0.1784 - acc: 0.93 - ETA: 49s - loss: 0.1779 - acc: 0.93 - ETA: 48s - loss: 0.1783 - acc: 0.93 - ETA: 48s - loss: 0.1779 - acc: 0.93 - ETA: 48s - loss: 0.1784 - acc: 0.93 - ETA: 48s - loss: 0.1786 - acc: 0.93 - ETA: 47s - loss: 0.1783 - acc: 0.93 - ETA: 47s - loss: 0.1784 - acc: 0.93 - ETA: 47s - loss: 0.1801 - acc: 0.93 - ETA: 47s - loss: 0.1804 - acc: 0.93 - ETA: 46s - loss: 0.1807 - acc: 0.93 - ETA: 46s - loss: 0.1803 - acc: 0.93 - ETA: 46s - loss: 0.1798 - acc: 0.93 - ETA: 46s - loss: 0.1793 - acc: 0.93 - ETA: 45s - loss: 0.1793 - acc: 0.93 - ETA: 45s - loss: 0.1790 - acc: 0.93 - ETA: 45s - loss: 0.1785 - acc: 0.93 - ETA: 45s - loss: 0.1784 - acc: 0.93 - ETA: 44s - loss: 0.1790 - acc: 0.93 - ETA: 44s - loss: 0.1787 - acc: 0.93 - ETA: 44s - loss: 0.1800 - acc: 0.93 - ETA: 43s - loss: 0.1799 - acc: 0.93 - ETA: 43s - loss: 0.1800 - acc: 0.93 - ETA: 43s - loss: 0.1800 - acc: 0.93 - ETA: 43s - loss: 0.1799 - acc: 0.93 - ETA: 42s - loss: 0.1804 - acc: 0.93 - ETA: 42s - loss: 0.1802 - acc: 0.93 - ETA: 42s - loss: 0.1802 - acc: 0.93 - ETA: 42s - loss: 0.1804 - acc: 0.93 - ETA: 41s - loss: 0.1801 - acc: 0.93 - ETA: 41s - loss: 0.1804 - acc: 0.93 - ETA: 41s - loss: 0.1801 - acc: 0.93 - ETA: 41s - loss: 0.1805 - acc: 0.93 - ETA: 40s - loss: 0.1804 - acc: 0.93 - ETA: 40s - loss: 0.1807 - acc: 0.93 - ETA: 40s - loss: 0.1813 - acc: 0.93 - ETA: 40s - loss: 0.1811 - acc: 0.93 - ETA: 39s - loss: 0.1806 - acc: 0.93 - ETA: 39s - loss: 0.1807 - acc: 0.93 - ETA: 39s - loss: 0.1811 - acc: 0.93 - ETA: 39s - loss: 0.1810 - acc: 0.93 - ETA: 38s - loss: 0.1818 - acc: 0.93 - ETA: 38s - loss: 0.1817 - acc: 0.93 - ETA: 38s - loss: 0.1823 - acc: 0.93 - ETA: 38s - loss: 0.1824 - acc: 0.93 - ETA: 37s - loss: 0.1821 - acc: 0.93 - ETA: 37s - loss: 0.1829 - acc: 0.93 - ETA: 37s - loss: 0.1828 - acc: 0.93 - ETA: 37s - loss: 0.1835 - acc: 0.93 - ETA: 36s - loss: 0.1834 - acc: 0.93 - ETA: 36s - loss: 0.1834 - acc: 0.93 - ETA: 36s - loss: 0.1831 - acc: 0.93 - ETA: 36s - loss: 0.1834 - acc: 0.93 - ETA: 35s - loss: 0.1833 - acc: 0.93 - ETA: 35s - loss: 0.1845 - acc: 0.93 - ETA: 35s - loss: 0.1859 - acc: 0.93 - ETA: 34s - loss: 0.1860 - acc: 0.93 - ETA: 34s - loss: 0.1860 - acc: 0.93 - ETA: 34s - loss: 0.1859 - acc: 0.93 - ETA: 34s - loss: 0.1858 - acc: 0.93 - ETA: 33s - loss: 0.1862 - acc: 0.93 - ETA: 33s - loss: 0.1862 - acc: 0.93 - ETA: 33s - loss: 0.1864 - acc: 0.93 - ETA: 33s - loss: 0.1861 - acc: 0.93 - ETA: 32s - loss: 0.1858 - acc: 0.93 - ETA: 32s - loss: 0.1864 - acc: 0.93 - ETA: 32s - loss: 0.1859 - acc: 0.93 - ETA: 32s - loss: 0.1859 - acc: 0.93 - ETA: 31s - loss: 0.1862 - acc: 0.93 - ETA: 31s - loss: 0.1858 - acc: 0.93 - ETA: 31s - loss: 0.1854 - acc: 0.93 - ETA: 31s - loss: 0.1849 - acc: 0.93 - ETA: 30s - loss: 0.1852 - acc: 0.93 - ETA: 30s - loss: 0.1848 - acc: 0.93 - ETA: 30s - loss: 0.1856 - acc: 0.93 - ETA: 30s - loss: 0.1865 - acc: 0.93 - ETA: 29s - loss: 0.1864 - acc: 0.93 - ETA: 29s - loss: 0.1863 - acc: 0.93 - ETA: 29s - loss: 0.1868 - acc: 0.93 - ETA: 29s - loss: 0.1871 - acc: 0.93 - ETA: 28s - loss: 0.1867 - acc: 0.93 - ETA: 28s - loss: 0.1863 - acc: 0.93 - ETA: 28s - loss: 0.1865 - acc: 0.93 - ETA: 28s - loss: 0.1866 - acc: 0.93 - ETA: 27s - loss: 0.1862 - acc: 0.93 - ETA: 27s - loss: 0.1860 - acc: 0.93 - ETA: 27s - loss: 0.1856 - acc: 0.93 - ETA: 27s - loss: 0.1855 - acc: 0.93 - ETA: 26s - loss: 0.1852 - acc: 0.93 - ETA: 26s - loss: 0.1851 - acc: 0.93 - ETA: 26s - loss: 0.1849 - acc: 0.93 - ETA: 26s - loss: 0.1848 - acc: 0.93 - ETA: 25s - loss: 0.1845 - acc: 0.93 - ETA: 25s - loss: 0.1842 - acc: 0.93 - ETA: 25s - loss: 0.1844 - acc: 0.93 - ETA: 25s - loss: 0.1841 - acc: 0.93 - ETA: 24s - loss: 0.1839 - acc: 0.93 - ETA: 24s - loss: 0.1842 - acc: 0.93 - ETA: 24s - loss: 0.1842 - acc: 0.93 - ETA: 24s - loss: 0.1847 - acc: 0.93 - ETA: 23s - loss: 0.1847 - acc: 0.93 - ETA: 23s - loss: 0.1849 - acc: 0.93 - ETA: 23s - loss: 0.1849 - acc: 0.93 - ETA: 22s - loss: 0.1846 - acc: 0.93 - ETA: 22s - loss: 0.1842 - acc: 0.93 - ETA: 22s - loss: 0.1842 - acc: 0.93 - ETA: 22s - loss: 0.1841 - acc: 0.93 - ETA: 21s - loss: 0.1847 - acc: 0.93 - ETA: 21s - loss: 0.1848 - acc: 0.93 - ETA: 21s - loss: 0.1851 - acc: 0.93 - ETA: 21s - loss: 0.1847 - acc: 0.93 - ETA: 20s - loss: 0.1853 - acc: 0.93 - ETA: 20s - loss: 0.1858 - acc: 0.93 - ETA: 20s - loss: 0.1857 - acc: 0.93 - ETA: 20s - loss: 0.1857 - acc: 0.93 - ETA: 19s - loss: 0.1857 - acc: 0.93 - ETA: 19s - loss: 0.1861 - acc: 0.93 - ETA: 19s - loss: 0.1867 - acc: 0.93 - ETA: 19s - loss: 0.1871 - acc: 0.93 - ETA: 18s - loss: 0.1868 - acc: 0.93 - ETA: 18s - loss: 0.1867 - acc: 0.93 - ETA: 18s - loss: 0.1868 - acc: 0.93 - ETA: 18s - loss: 0.1866 - acc: 0.93 - ETA: 17s - loss: 0.1863 - acc: 0.93 - ETA: 17s - loss: 0.1860 - acc: 0.93 - ETA: 17s - loss: 0.1858 - acc: 0.93 - ETA: 17s - loss: 0.1855 - acc: 0.93 - ETA: 16s - loss: 0.1858 - acc: 0.93 - ETA: 16s - loss: 0.1859 - acc: 0.93 - ETA: 16s - loss: 0.1857 - acc: 0.93 - ETA: 16s - loss: 0.1857 - acc: 0.93 - ETA: 15s - loss: 0.1858 - acc: 0.93 - ETA: 15s - loss: 0.1859 - acc: 0.93 - ETA: 15s - loss: 0.1855 - acc: 0.93 - ETA: 15s - loss: 0.1852 - acc: 0.93 - ETA: 14s - loss: 0.1853 - acc: 0.93 - ETA: 14s - loss: 0.1850 - acc: 0.93 - ETA: 14s - loss: 0.1853 - acc: 0.93 - ETA: 14s - loss: 0.1852 - acc: 0.93 - ETA: 13s - loss: 0.1851 - acc: 0.93 - ETA: 13s - loss: 0.1849 - acc: 0.93 - ETA: 13s - loss: 0.1849 - acc: 0.93 - ETA: 13s - loss: 0.1849 - acc: 0.93 - ETA: 12s - loss: 0.1847 - acc: 0.93 - ETA: 12s - loss: 0.1848 - acc: 0.93 - ETA: 12s - loss: 0.1844 - acc: 0.93 - ETA: 12s - loss: 0.1842 - acc: 0.93 - ETA: 11s - loss: 0.1842 - acc: 0.93 - ETA: 11s - loss: 0.1845 - acc: 0.93 - ETA: 11s - loss: 0.1841 - acc: 0.93 - ETA: 10s - loss: 0.1837 - acc: 0.93 - ETA: 10s - loss: 0.1839 - acc: 0.93 - ETA: 10s - loss: 0.1835 - acc: 0.93 - ETA: 10s - loss: 0.1834 - acc: 0.93 - ETA: 9s - loss: 0.1832 - acc: 0.9342 - ETA: 9s - loss: 0.1829 - acc: 0.934 - ETA: 9s - loss: 0.1829 - acc: 0.934 - ETA: 9s - loss: 0.1828 - acc: 0.934 - ETA: 8s - loss: 0.1838 - acc: 0.934 - ETA: 8s - loss: 0.1837 - acc: 0.934 - ETA: 8s - loss: 0.1838 - acc: 0.934 - ETA: 8s - loss: 0.1835 - acc: 0.934 - ETA: 7s - loss: 0.1837 - acc: 0.934 - ETA: 7s - loss: 0.1838 - acc: 0.933 - ETA: 7s - loss: 0.1835 - acc: 0.934 - ETA: 7s - loss: 0.1833 - acc: 0.934 - ETA: 6s - loss: 0.1830 - acc: 0.934 - ETA: 6s - loss: 0.1831 - acc: 0.934 - ETA: 6s - loss: 0.1833 - acc: 0.934 - ETA: 6s - loss: 0.1838 - acc: 0.934 - ETA: 5s - loss: 0.1835 - acc: 0.934 - ETA: 5s - loss: 0.1834 - acc: 0.934 - ETA: 5s - loss: 0.1840 - acc: 0.933 - ETA: 5s - loss: 0.1840 - acc: 0.933 - ETA: 4s - loss: 0.1837 - acc: 0.933 - ETA: 4s - loss: 0.1834 - acc: 0.933 - ETA: 4s - loss: 0.1832 - acc: 0.933 - ETA: 4s - loss: 0.1830 - acc: 0.933 - ETA: 3s - loss: 0.1831 - acc: 0.933 - ETA: 3s - loss: 0.1830 - acc: 0.933 - ETA: 3s - loss: 0.1831 - acc: 0.933 - ETA: 3s - loss: 0.1831 - acc: 0.933 - ETA: 2s - loss: 0.1831 - acc: 0.933 - ETA: 2s - loss: 0.1828 - acc: 0.933 - ETA: 2s - loss: 0.1826 - acc: 0.933 - ETA: 2s - loss: 0.1831 - acc: 0.933 - ETA: 1s - loss: 0.1827 - acc: 0.9339426/427 [============================>.] - ETA: 1s - loss: 0.1823 - acc: 0.934 - ETA: 1s - loss: 0.1821 - acc: 0.934 - ETA: 1s - loss: 0.1823 - acc: 0.934 - ETA: 0s - loss: 0.1824 - acc: 0.933 - ETA: 0s - loss: 0.1822 - acc: 0.934 - ETA: 0s - loss: 0.1824 - acc: 0.9340\n",
      "Epoch 00009: val_loss did not improve\n",
      "427/427 [==============================] - 111s 260ms/step - loss: 0.1821 - acc: 0.9342 - val_loss: 0.4830 - val_acc: 0.8462\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:48 - loss: 0.3150 - acc: 0.900 - ETA: 1:46 - loss: 0.1895 - acc: 0.925 - ETA: 1:45 - loss: 0.1592 - acc: 0.933 - ETA: 1:45 - loss: 0.1481 - acc: 0.937 - ETA: 1:45 - loss: 0.1626 - acc: 0.940 - ETA: 1:46 - loss: 0.1748 - acc: 0.941 - ETA: 1:49 - loss: 0.2120 - acc: 0.928 - ETA: 1:51 - loss: 0.1936 - acc: 0.937 - ETA: 1:52 - loss: 0.1843 - acc: 0.938 - ETA: 1:51 - loss: 0.1731 - acc: 0.945 - ETA: 1:51 - loss: 0.1680 - acc: 0.945 - ETA: 1:50 - loss: 0.1759 - acc: 0.941 - ETA: 1:49 - loss: 0.1731 - acc: 0.942 - ETA: 1:48 - loss: 0.1646 - acc: 0.946 - ETA: 1:48 - loss: 0.1623 - acc: 0.946 - ETA: 1:47 - loss: 0.1645 - acc: 0.946 - ETA: 1:47 - loss: 0.1626 - acc: 0.950 - ETA: 1:46 - loss: 0.1718 - acc: 0.947 - ETA: 1:46 - loss: 0.1678 - acc: 0.947 - ETA: 1:45 - loss: 0.1738 - acc: 0.945 - ETA: 1:46 - loss: 0.1792 - acc: 0.940 - ETA: 1:45 - loss: 0.1759 - acc: 0.940 - ETA: 1:45 - loss: 0.1741 - acc: 0.941 - ETA: 1:45 - loss: 0.1781 - acc: 0.941 - ETA: 1:45 - loss: 0.1867 - acc: 0.942 - ETA: 1:45 - loss: 0.1818 - acc: 0.944 - ETA: 1:45 - loss: 0.1877 - acc: 0.942 - ETA: 1:45 - loss: 0.1865 - acc: 0.944 - ETA: 1:42 - loss: 0.1931 - acc: 0.936 - ETA: 1:43 - loss: 0.1917 - acc: 0.937 - ETA: 1:43 - loss: 0.1894 - acc: 0.937 - ETA: 1:43 - loss: 0.1893 - acc: 0.937 - ETA: 1:43 - loss: 0.1872 - acc: 0.938 - ETA: 1:42 - loss: 0.1862 - acc: 0.938 - ETA: 1:40 - loss: 0.1904 - acc: 0.936 - ETA: 1:40 - loss: 0.1951 - acc: 0.933 - ETA: 1:40 - loss: 0.1979 - acc: 0.933 - ETA: 1:40 - loss: 0.1983 - acc: 0.933 - ETA: 1:40 - loss: 0.1985 - acc: 0.933 - ETA: 1:39 - loss: 0.2026 - acc: 0.931 - ETA: 1:39 - loss: 0.2008 - acc: 0.933 - ETA: 1:39 - loss: 0.1976 - acc: 0.935 - ETA: 1:39 - loss: 0.1955 - acc: 0.935 - ETA: 1:39 - loss: 0.1917 - acc: 0.936 - ETA: 1:39 - loss: 0.1920 - acc: 0.937 - ETA: 1:38 - loss: 0.1901 - acc: 0.938 - ETA: 1:38 - loss: 0.1913 - acc: 0.938 - ETA: 1:38 - loss: 0.1880 - acc: 0.940 - ETA: 1:38 - loss: 0.1866 - acc: 0.940 - ETA: 1:38 - loss: 0.1873 - acc: 0.940 - ETA: 1:38 - loss: 0.1885 - acc: 0.939 - ETA: 1:38 - loss: 0.1886 - acc: 0.939 - ETA: 1:38 - loss: 0.1893 - acc: 0.939 - ETA: 1:38 - loss: 0.1891 - acc: 0.938 - ETA: 1:38 - loss: 0.1934 - acc: 0.936 - ETA: 1:38 - loss: 0.1919 - acc: 0.937 - ETA: 1:38 - loss: 0.1904 - acc: 0.937 - ETA: 1:37 - loss: 0.1884 - acc: 0.938 - ETA: 1:36 - loss: 0.1934 - acc: 0.936 - ETA: 1:36 - loss: 0.1923 - acc: 0.938 - ETA: 1:36 - loss: 0.1907 - acc: 0.938 - ETA: 1:35 - loss: 0.1898 - acc: 0.938 - ETA: 1:35 - loss: 0.1912 - acc: 0.937 - ETA: 1:35 - loss: 0.1979 - acc: 0.936 - ETA: 1:34 - loss: 0.1960 - acc: 0.937 - ETA: 1:34 - loss: 0.1945 - acc: 0.938 - ETA: 1:34 - loss: 0.1941 - acc: 0.937 - ETA: 1:34 - loss: 0.1937 - acc: 0.937 - ETA: 1:33 - loss: 0.1931 - acc: 0.937 - ETA: 1:33 - loss: 0.1915 - acc: 0.938 - ETA: 1:33 - loss: 0.1902 - acc: 0.939 - ETA: 1:32 - loss: 0.1897 - acc: 0.940 - ETA: 1:32 - loss: 0.1880 - acc: 0.940 - ETA: 1:32 - loss: 0.1870 - acc: 0.940 - ETA: 1:32 - loss: 0.1862 - acc: 0.939 - ETA: 1:31 - loss: 0.1893 - acc: 0.938 - ETA: 1:31 - loss: 0.1891 - acc: 0.938 - ETA: 1:31 - loss: 0.1892 - acc: 0.938 - ETA: 1:31 - loss: 0.1885 - acc: 0.939 - ETA: 1:31 - loss: 0.1906 - acc: 0.939 - ETA: 1:30 - loss: 0.1918 - acc: 0.939 - ETA: 1:30 - loss: 0.1911 - acc: 0.938 - ETA: 1:30 - loss: 0.1915 - acc: 0.938 - ETA: 1:30 - loss: 0.1899 - acc: 0.939 - ETA: 1:29 - loss: 0.1905 - acc: 0.938 - ETA: 1:29 - loss: 0.1895 - acc: 0.938 - ETA: 1:29 - loss: 0.1887 - acc: 0.938 - ETA: 1:28 - loss: 0.1908 - acc: 0.937 - ETA: 1:27 - loss: 0.1901 - acc: 0.938 - ETA: 1:27 - loss: 0.1911 - acc: 0.937 - ETA: 1:27 - loss: 0.1941 - acc: 0.936 - ETA: 1:26 - loss: 0.1930 - acc: 0.937 - ETA: 1:26 - loss: 0.1923 - acc: 0.938 - ETA: 1:26 - loss: 0.1921 - acc: 0.938 - ETA: 1:26 - loss: 0.1910 - acc: 0.938 - ETA: 1:25 - loss: 0.1894 - acc: 0.939 - ETA: 1:25 - loss: 0.1888 - acc: 0.939 - ETA: 1:25 - loss: 0.1886 - acc: 0.938 - ETA: 1:25 - loss: 0.1901 - acc: 0.937 - ETA: 1:24 - loss: 0.1907 - acc: 0.936 - ETA: 1:24 - loss: 0.1910 - acc: 0.936 - ETA: 1:24 - loss: 0.1910 - acc: 0.936 - ETA: 1:24 - loss: 0.1912 - acc: 0.936 - ETA: 1:23 - loss: 0.1904 - acc: 0.937 - ETA: 1:23 - loss: 0.1901 - acc: 0.937 - ETA: 1:23 - loss: 0.1903 - acc: 0.936 - ETA: 1:23 - loss: 0.1894 - acc: 0.937 - ETA: 1:22 - loss: 0.1905 - acc: 0.936 - ETA: 1:22 - loss: 0.1892 - acc: 0.936 - ETA: 1:22 - loss: 0.1878 - acc: 0.937 - ETA: 1:22 - loss: 0.1870 - acc: 0.937 - ETA: 1:22 - loss: 0.1873 - acc: 0.937 - ETA: 1:21 - loss: 0.1871 - acc: 0.938 - ETA: 1:21 - loss: 0.1860 - acc: 0.938 - ETA: 1:21 - loss: 0.1854 - acc: 0.938 - ETA: 1:20 - loss: 0.1853 - acc: 0.938 - ETA: 1:20 - loss: 0.1868 - acc: 0.937 - ETA: 1:20 - loss: 0.1866 - acc: 0.937 - ETA: 1:20 - loss: 0.1859 - acc: 0.937 - ETA: 1:19 - loss: 0.1856 - acc: 0.937 - ETA: 1:19 - loss: 0.1862 - acc: 0.937 - ETA: 1:19 - loss: 0.1858 - acc: 0.937 - ETA: 1:19 - loss: 0.1854 - acc: 0.937 - ETA: 1:19 - loss: 0.1852 - acc: 0.937 - ETA: 1:18 - loss: 0.1873 - acc: 0.936 - ETA: 1:18 - loss: 0.1867 - acc: 0.936 - ETA: 1:17 - loss: 0.1855 - acc: 0.937 - ETA: 1:17 - loss: 0.1850 - acc: 0.937 - ETA: 1:17 - loss: 0.1848 - acc: 0.937 - ETA: 1:17 - loss: 0.1854 - acc: 0.936 - ETA: 1:16 - loss: 0.1856 - acc: 0.936 - ETA: 1:16 - loss: 0.1847 - acc: 0.936 - ETA: 1:16 - loss: 0.1839 - acc: 0.937 - ETA: 1:16 - loss: 0.1843 - acc: 0.937 - ETA: 1:15 - loss: 0.1851 - acc: 0.937 - ETA: 1:15 - loss: 0.1845 - acc: 0.937 - ETA: 1:15 - loss: 0.1846 - acc: 0.937 - ETA: 1:14 - loss: 0.1839 - acc: 0.937 - ETA: 1:14 - loss: 0.1831 - acc: 0.938 - ETA: 1:14 - loss: 0.1822 - acc: 0.938 - ETA: 1:14 - loss: 0.1817 - acc: 0.938 - ETA: 1:13 - loss: 0.1814 - acc: 0.938 - ETA: 1:13 - loss: 0.1808 - acc: 0.938 - ETA: 1:13 - loss: 0.1808 - acc: 0.938 - ETA: 1:13 - loss: 0.1813 - acc: 0.937 - ETA: 1:12 - loss: 0.1833 - acc: 0.936 - ETA: 1:12 - loss: 0.1835 - acc: 0.936 - ETA: 1:12 - loss: 0.1838 - acc: 0.936 - ETA: 1:12 - loss: 0.1831 - acc: 0.936 - ETA: 1:12 - loss: 0.1823 - acc: 0.937 - ETA: 1:11 - loss: 0.1819 - acc: 0.937 - ETA: 1:11 - loss: 0.1826 - acc: 0.936 - ETA: 1:11 - loss: 0.1818 - acc: 0.937 - ETA: 1:11 - loss: 0.1819 - acc: 0.937 - ETA: 1:10 - loss: 0.1826 - acc: 0.936 - ETA: 1:10 - loss: 0.1824 - acc: 0.937 - ETA: 1:10 - loss: 0.1822 - acc: 0.937 - ETA: 1:09 - loss: 0.1824 - acc: 0.937 - ETA: 1:09 - loss: 0.1824 - acc: 0.936 - ETA: 1:09 - loss: 0.1839 - acc: 0.936 - ETA: 1:09 - loss: 0.1846 - acc: 0.936 - ETA: 1:08 - loss: 0.1856 - acc: 0.936 - ETA: 1:08 - loss: 0.1858 - acc: 0.935 - ETA: 1:08 - loss: 0.1856 - acc: 0.935 - ETA: 1:08 - loss: 0.1853 - acc: 0.936 - ETA: 1:07 - loss: 0.1850 - acc: 0.936 - ETA: 1:07 - loss: 0.1850 - acc: 0.936 - ETA: 1:07 - loss: 0.1847 - acc: 0.936 - ETA: 1:07 - loss: 0.1848 - acc: 0.936 - ETA: 1:06 - loss: 0.1840 - acc: 0.937 - ETA: 1:06 - loss: 0.1834 - acc: 0.937 - ETA: 1:06 - loss: 0.1842 - acc: 0.937 - ETA: 1:06 - loss: 0.1845 - acc: 0.937 - ETA: 1:05 - loss: 0.1838 - acc: 0.937 - ETA: 1:05 - loss: 0.1834 - acc: 0.937 - ETA: 1:05 - loss: 0.1826 - acc: 0.937 - ETA: 1:05 - loss: 0.1822 - acc: 0.937 - ETA: 1:04 - loss: 0.1823 - acc: 0.937 - ETA: 1:04 - loss: 0.1820 - acc: 0.937 - ETA: 1:04 - loss: 0.1824 - acc: 0.937 - ETA: 1:03 - loss: 0.1823 - acc: 0.937 - ETA: 1:03 - loss: 0.1824 - acc: 0.937 - ETA: 1:03 - loss: 0.1816 - acc: 0.937 - ETA: 1:03 - loss: 0.1825 - acc: 0.937 - ETA: 1:02 - loss: 0.1822 - acc: 0.937 - ETA: 1:02 - loss: 0.1818 - acc: 0.937 - ETA: 1:02 - loss: 0.1811 - acc: 0.938 - ETA: 1:02 - loss: 0.1806 - acc: 0.938 - ETA: 1:01 - loss: 0.1807 - acc: 0.938 - ETA: 1:01 - loss: 0.1808 - acc: 0.938 - ETA: 1:01 - loss: 0.1802 - acc: 0.938 - ETA: 1:01 - loss: 0.1806 - acc: 0.938 - ETA: 1:00 - loss: 0.1801 - acc: 0.939 - ETA: 1:00 - loss: 0.1823 - acc: 0.938 - ETA: 1:00 - loss: 0.1817 - acc: 0.938 - ETA: 1:00 - loss: 0.1810 - acc: 0.939 - ETA: 59s - loss: 0.1807 - acc: 0.938 - ETA: 59s - loss: 0.1806 - acc: 0.93 - ETA: 59s - loss: 0.1800 - acc: 0.93 - ETA: 58s - loss: 0.1809 - acc: 0.93 - ETA: 58s - loss: 0.1809 - acc: 0.93 - ETA: 58s - loss: 0.1814 - acc: 0.93 - ETA: 58s - loss: 0.1820 - acc: 0.93 - ETA: 57s - loss: 0.1819 - acc: 0.93 - ETA: 57s - loss: 0.1813 - acc: 0.9383420/427 [============================>.] - ETA: 57s - loss: 0.1817 - acc: 0.93 - ETA: 57s - loss: 0.1811 - acc: 0.93 - ETA: 56s - loss: 0.1810 - acc: 0.93 - ETA: 56s - loss: 0.1817 - acc: 0.93 - ETA: 56s - loss: 0.1814 - acc: 0.93 - ETA: 55s - loss: 0.1819 - acc: 0.93 - ETA: 55s - loss: 0.1813 - acc: 0.93 - ETA: 55s - loss: 0.1810 - acc: 0.93 - ETA: 55s - loss: 0.1805 - acc: 0.93 - ETA: 54s - loss: 0.1803 - acc: 0.93 - ETA: 54s - loss: 0.1802 - acc: 0.93 - ETA: 54s - loss: 0.1804 - acc: 0.93 - ETA: 54s - loss: 0.1798 - acc: 0.93 - ETA: 53s - loss: 0.1797 - acc: 0.93 - ETA: 53s - loss: 0.1796 - acc: 0.93 - ETA: 53s - loss: 0.1797 - acc: 0.93 - ETA: 53s - loss: 0.1795 - acc: 0.93 - ETA: 52s - loss: 0.1791 - acc: 0.93 - ETA: 52s - loss: 0.1791 - acc: 0.93 - ETA: 52s - loss: 0.1795 - acc: 0.93 - ETA: 52s - loss: 0.1796 - acc: 0.93 - ETA: 51s - loss: 0.1792 - acc: 0.93 - ETA: 51s - loss: 0.1797 - acc: 0.93 - ETA: 51s - loss: 0.1803 - acc: 0.93 - ETA: 51s - loss: 0.1802 - acc: 0.93 - ETA: 50s - loss: 0.1803 - acc: 0.93 - ETA: 50s - loss: 0.1802 - acc: 0.93 - ETA: 50s - loss: 0.1798 - acc: 0.93 - ETA: 50s - loss: 0.1802 - acc: 0.93 - ETA: 49s - loss: 0.1803 - acc: 0.93 - ETA: 49s - loss: 0.1818 - acc: 0.93 - ETA: 49s - loss: 0.1813 - acc: 0.93 - ETA: 49s - loss: 0.1807 - acc: 0.93 - ETA: 48s - loss: 0.1802 - acc: 0.93 - ETA: 48s - loss: 0.1804 - acc: 0.93 - ETA: 48s - loss: 0.1798 - acc: 0.93 - ETA: 48s - loss: 0.1794 - acc: 0.93 - ETA: 47s - loss: 0.1791 - acc: 0.93 - ETA: 47s - loss: 0.1799 - acc: 0.93 - ETA: 47s - loss: 0.1795 - acc: 0.93 - ETA: 47s - loss: 0.1803 - acc: 0.93 - ETA: 46s - loss: 0.1800 - acc: 0.93 - ETA: 46s - loss: 0.1796 - acc: 0.93 - ETA: 46s - loss: 0.1803 - acc: 0.93 - ETA: 45s - loss: 0.1799 - acc: 0.93 - ETA: 45s - loss: 0.1797 - acc: 0.93 - ETA: 45s - loss: 0.1794 - acc: 0.93 - ETA: 45s - loss: 0.1790 - acc: 0.93 - ETA: 44s - loss: 0.1803 - acc: 0.93 - ETA: 44s - loss: 0.1799 - acc: 0.93 - ETA: 44s - loss: 0.1796 - acc: 0.93 - ETA: 44s - loss: 0.1794 - acc: 0.93 - ETA: 43s - loss: 0.1789 - acc: 0.93 - ETA: 43s - loss: 0.1795 - acc: 0.93 - ETA: 43s - loss: 0.1795 - acc: 0.93 - ETA: 42s - loss: 0.1792 - acc: 0.93 - ETA: 42s - loss: 0.1793 - acc: 0.93 - ETA: 42s - loss: 0.1797 - acc: 0.93 - ETA: 42s - loss: 0.1794 - acc: 0.93 - ETA: 41s - loss: 0.1792 - acc: 0.93 - ETA: 41s - loss: 0.1794 - acc: 0.93 - ETA: 41s - loss: 0.1788 - acc: 0.93 - ETA: 41s - loss: 0.1784 - acc: 0.93 - ETA: 40s - loss: 0.1782 - acc: 0.93 - ETA: 40s - loss: 0.1780 - acc: 0.93 - ETA: 40s - loss: 0.1787 - acc: 0.93 - ETA: 40s - loss: 0.1785 - acc: 0.93 - ETA: 39s - loss: 0.1786 - acc: 0.93 - ETA: 39s - loss: 0.1784 - acc: 0.93 - ETA: 39s - loss: 0.1779 - acc: 0.93 - ETA: 39s - loss: 0.1782 - acc: 0.93 - ETA: 38s - loss: 0.1780 - acc: 0.93 - ETA: 38s - loss: 0.1780 - acc: 0.93 - ETA: 38s - loss: 0.1781 - acc: 0.93 - ETA: 38s - loss: 0.1784 - acc: 0.93 - ETA: 37s - loss: 0.1786 - acc: 0.93 - ETA: 37s - loss: 0.1799 - acc: 0.93 - ETA: 37s - loss: 0.1796 - acc: 0.93 - ETA: 36s - loss: 0.1793 - acc: 0.93 - ETA: 36s - loss: 0.1794 - acc: 0.93 - ETA: 36s - loss: 0.1792 - acc: 0.93 - ETA: 36s - loss: 0.1800 - acc: 0.93 - ETA: 35s - loss: 0.1798 - acc: 0.93 - ETA: 35s - loss: 0.1798 - acc: 0.93 - ETA: 35s - loss: 0.1794 - acc: 0.93 - ETA: 35s - loss: 0.1790 - acc: 0.93 - ETA: 34s - loss: 0.1786 - acc: 0.93 - ETA: 34s - loss: 0.1782 - acc: 0.93 - ETA: 34s - loss: 0.1779 - acc: 0.93 - ETA: 34s - loss: 0.1782 - acc: 0.93 - ETA: 33s - loss: 0.1779 - acc: 0.93 - ETA: 33s - loss: 0.1776 - acc: 0.93 - ETA: 33s - loss: 0.1777 - acc: 0.93 - ETA: 33s - loss: 0.1778 - acc: 0.93 - ETA: 32s - loss: 0.1780 - acc: 0.93 - ETA: 32s - loss: 0.1789 - acc: 0.93 - ETA: 32s - loss: 0.1786 - acc: 0.93 - ETA: 32s - loss: 0.1788 - acc: 0.93 - ETA: 31s - loss: 0.1784 - acc: 0.93 - ETA: 31s - loss: 0.1781 - acc: 0.93 - ETA: 31s - loss: 0.1782 - acc: 0.93 - ETA: 31s - loss: 0.1784 - acc: 0.93 - ETA: 30s - loss: 0.1779 - acc: 0.93 - ETA: 30s - loss: 0.1777 - acc: 0.93 - ETA: 30s - loss: 0.1778 - acc: 0.93 - ETA: 30s - loss: 0.1784 - acc: 0.93 - ETA: 29s - loss: 0.1784 - acc: 0.93 - ETA: 29s - loss: 0.1788 - acc: 0.93 - ETA: 29s - loss: 0.1783 - acc: 0.93 - ETA: 29s - loss: 0.1781 - acc: 0.93 - ETA: 28s - loss: 0.1781 - acc: 0.93 - ETA: 28s - loss: 0.1780 - acc: 0.93 - ETA: 28s - loss: 0.1777 - acc: 0.93 - ETA: 27s - loss: 0.1779 - acc: 0.93 - ETA: 27s - loss: 0.1780 - acc: 0.93 - ETA: 27s - loss: 0.1777 - acc: 0.93 - ETA: 27s - loss: 0.1777 - acc: 0.93 - ETA: 26s - loss: 0.1776 - acc: 0.93 - ETA: 26s - loss: 0.1774 - acc: 0.93 - ETA: 26s - loss: 0.1772 - acc: 0.93 - ETA: 26s - loss: 0.1769 - acc: 0.93 - ETA: 25s - loss: 0.1773 - acc: 0.93 - ETA: 25s - loss: 0.1774 - acc: 0.93 - ETA: 25s - loss: 0.1771 - acc: 0.93 - ETA: 25s - loss: 0.1780 - acc: 0.93 - ETA: 24s - loss: 0.1781 - acc: 0.93 - ETA: 24s - loss: 0.1780 - acc: 0.93 - ETA: 24s - loss: 0.1777 - acc: 0.93 - ETA: 24s - loss: 0.1776 - acc: 0.93 - ETA: 23s - loss: 0.1778 - acc: 0.93 - ETA: 23s - loss: 0.1780 - acc: 0.93 - ETA: 23s - loss: 0.1777 - acc: 0.93 - ETA: 23s - loss: 0.1775 - acc: 0.93 - ETA: 22s - loss: 0.1772 - acc: 0.93 - ETA: 22s - loss: 0.1774 - acc: 0.93 - ETA: 22s - loss: 0.1772 - acc: 0.93 - ETA: 21s - loss: 0.1772 - acc: 0.93 - ETA: 21s - loss: 0.1770 - acc: 0.93 - ETA: 21s - loss: 0.1771 - acc: 0.93 - ETA: 21s - loss: 0.1771 - acc: 0.93 - ETA: 20s - loss: 0.1770 - acc: 0.93 - ETA: 20s - loss: 0.1766 - acc: 0.93 - ETA: 20s - loss: 0.1769 - acc: 0.93 - ETA: 20s - loss: 0.1767 - acc: 0.93 - ETA: 19s - loss: 0.1764 - acc: 0.93 - ETA: 19s - loss: 0.1765 - acc: 0.93 - ETA: 19s - loss: 0.1766 - acc: 0.93 - ETA: 19s - loss: 0.1766 - acc: 0.93 - ETA: 18s - loss: 0.1769 - acc: 0.93 - ETA: 18s - loss: 0.1768 - acc: 0.93 - ETA: 18s - loss: 0.1765 - acc: 0.93 - ETA: 18s - loss: 0.1766 - acc: 0.93 - ETA: 17s - loss: 0.1764 - acc: 0.93 - ETA: 17s - loss: 0.1770 - acc: 0.93 - ETA: 17s - loss: 0.1770 - acc: 0.93 - ETA: 17s - loss: 0.1768 - acc: 0.93 - ETA: 16s - loss: 0.1764 - acc: 0.93 - ETA: 16s - loss: 0.1761 - acc: 0.93 - ETA: 16s - loss: 0.1764 - acc: 0.93 - ETA: 16s - loss: 0.1764 - acc: 0.93 - ETA: 15s - loss: 0.1767 - acc: 0.93 - ETA: 15s - loss: 0.1764 - acc: 0.93 - ETA: 15s - loss: 0.1762 - acc: 0.93 - ETA: 15s - loss: 0.1759 - acc: 0.93 - ETA: 14s - loss: 0.1758 - acc: 0.93 - ETA: 14s - loss: 0.1756 - acc: 0.93 - ETA: 14s - loss: 0.1755 - acc: 0.93 - ETA: 13s - loss: 0.1756 - acc: 0.93 - ETA: 13s - loss: 0.1753 - acc: 0.93 - ETA: 13s - loss: 0.1756 - acc: 0.93 - ETA: 13s - loss: 0.1755 - acc: 0.93 - ETA: 12s - loss: 0.1755 - acc: 0.93 - ETA: 12s - loss: 0.1752 - acc: 0.93 - ETA: 12s - loss: 0.1754 - acc: 0.93 - ETA: 12s - loss: 0.1757 - acc: 0.93 - ETA: 11s - loss: 0.1757 - acc: 0.93 - ETA: 11s - loss: 0.1763 - acc: 0.93 - ETA: 11s - loss: 0.1760 - acc: 0.93 - ETA: 11s - loss: 0.1761 - acc: 0.93 - ETA: 10s - loss: 0.1761 - acc: 0.93 - ETA: 10s - loss: 0.1757 - acc: 0.93 - ETA: 10s - loss: 0.1759 - acc: 0.93 - ETA: 10s - loss: 0.1757 - acc: 0.93 - ETA: 9s - loss: 0.1758 - acc: 0.9381 - ETA: 9s - loss: 0.1757 - acc: 0.938 - ETA: 9s - loss: 0.1764 - acc: 0.937 - ETA: 9s - loss: 0.1768 - acc: 0.937 - ETA: 8s - loss: 0.1765 - acc: 0.937 - ETA: 8s - loss: 0.1763 - acc: 0.937 - ETA: 8s - loss: 0.1762 - acc: 0.937 - ETA: 8s - loss: 0.1764 - acc: 0.937 - ETA: 7s - loss: 0.1763 - acc: 0.937 - ETA: 7s - loss: 0.1760 - acc: 0.938 - ETA: 7s - loss: 0.1757 - acc: 0.938 - ETA: 6s - loss: 0.1754 - acc: 0.938 - ETA: 6s - loss: 0.1761 - acc: 0.938 - ETA: 6s - loss: 0.1764 - acc: 0.937 - ETA: 6s - loss: 0.1763 - acc: 0.937 - ETA: 5s - loss: 0.1765 - acc: 0.937 - ETA: 5s - loss: 0.1767 - acc: 0.937 - ETA: 5s - loss: 0.1767 - acc: 0.937 - ETA: 5s - loss: 0.1763 - acc: 0.937 - ETA: 4s - loss: 0.1760 - acc: 0.937 - ETA: 4s - loss: 0.1762 - acc: 0.937 - ETA: 4s - loss: 0.1759 - acc: 0.937 - ETA: 4s - loss: 0.1757 - acc: 0.937 - ETA: 3s - loss: 0.1754 - acc: 0.938 - ETA: 3s - loss: 0.1752 - acc: 0.938 - ETA: 3s - loss: 0.1754 - acc: 0.937 - ETA: 3s - loss: 0.1753 - acc: 0.938 - ETA: 2s - loss: 0.1755 - acc: 0.937 - ETA: 2s - loss: 0.1755 - acc: 0.937 - ETA: 2s - loss: 0.1756 - acc: 0.937 - ETA: 2s - loss: 0.1753 - acc: 0.937 - ETA: 1s - loss: 0.1760 - acc: 0.9378"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/427 [============================>.] - ETA: 1s - loss: 0.1782 - acc: 0.936 - ETA: 1s - loss: 0.1782 - acc: 0.936 - ETA: 1s - loss: 0.1780 - acc: 0.936 - ETA: 0s - loss: 0.1779 - acc: 0.936 - ETA: 0s - loss: 0.1775 - acc: 0.936 - ETA: 0s - loss: 0.1773 - acc: 0.9370\n",
      "Epoch 00010: val_loss did not improve\n",
      "427/427 [==============================] - 112s 262ms/step - loss: 0.1773 - acc: 0.9368 - val_loss: 0.4378 - val_acc: 0.8547\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:49 - loss: 0.1628 - acc: 0.950 - ETA: 1:49 - loss: 0.1294 - acc: 0.975 - ETA: 1:48 - loss: 0.1221 - acc: 0.966 - ETA: 1:48 - loss: 0.1180 - acc: 0.962 - ETA: 1:47 - loss: 0.1268 - acc: 0.960 - ETA: 1:47 - loss: 0.1277 - acc: 0.958 - ETA: 1:46 - loss: 0.1321 - acc: 0.950 - ETA: 1:46 - loss: 0.1348 - acc: 0.943 - ETA: 1:46 - loss: 0.1380 - acc: 0.944 - ETA: 1:45 - loss: 0.1270 - acc: 0.950 - ETA: 1:45 - loss: 0.1182 - acc: 0.954 - ETA: 1:44 - loss: 0.1150 - acc: 0.958 - ETA: 1:44 - loss: 0.1128 - acc: 0.957 - ETA: 1:44 - loss: 0.1130 - acc: 0.957 - ETA: 1:43 - loss: 0.1100 - acc: 0.960 - ETA: 1:43 - loss: 0.1081 - acc: 0.962 - ETA: 1:43 - loss: 0.1085 - acc: 0.961 - ETA: 1:43 - loss: 0.1183 - acc: 0.955 - ETA: 1:44 - loss: 0.1301 - acc: 0.950 - ETA: 1:45 - loss: 0.1403 - acc: 0.947 - ETA: 1:45 - loss: 0.1396 - acc: 0.947 - ETA: 1:44 - loss: 0.1541 - acc: 0.943 - ETA: 1:44 - loss: 0.1524 - acc: 0.943 - ETA: 1:44 - loss: 0.1493 - acc: 0.945 - ETA: 1:44 - loss: 0.1522 - acc: 0.944 - ETA: 1:44 - loss: 0.1529 - acc: 0.944 - ETA: 1:44 - loss: 0.1510 - acc: 0.944 - ETA: 1:43 - loss: 0.1500 - acc: 0.942 - ETA: 1:43 - loss: 0.1490 - acc: 0.943 - ETA: 1:43 - loss: 0.1476 - acc: 0.945 - ETA: 1:42 - loss: 0.1456 - acc: 0.946 - ETA: 1:42 - loss: 0.1492 - acc: 0.946 - ETA: 1:42 - loss: 0.1483 - acc: 0.948 - ETA: 1:41 - loss: 0.1473 - acc: 0.948 - ETA: 1:41 - loss: 0.1506 - acc: 0.945 - ETA: 1:41 - loss: 0.1537 - acc: 0.945 - ETA: 1:40 - loss: 0.1508 - acc: 0.947 - ETA: 1:38 - loss: 0.1479 - acc: 0.948 - ETA: 1:38 - loss: 0.1511 - acc: 0.948 - ETA: 1:38 - loss: 0.1503 - acc: 0.948 - ETA: 1:38 - loss: 0.1518 - acc: 0.947 - ETA: 1:38 - loss: 0.1520 - acc: 0.947 - ETA: 1:39 - loss: 0.1523 - acc: 0.948 - ETA: 1:39 - loss: 0.1512 - acc: 0.950 - ETA: 1:39 - loss: 0.1506 - acc: 0.951 - ETA: 1:38 - loss: 0.1499 - acc: 0.951 - ETA: 1:38 - loss: 0.1480 - acc: 0.952 - ETA: 1:38 - loss: 0.1502 - acc: 0.952 - ETA: 1:38 - loss: 0.1502 - acc: 0.951 - ETA: 1:38 - loss: 0.1497 - acc: 0.951 - ETA: 1:37 - loss: 0.1508 - acc: 0.951 - ETA: 1:36 - loss: 0.1492 - acc: 0.951 - ETA: 1:36 - loss: 0.1496 - acc: 0.951 - ETA: 1:36 - loss: 0.1490 - acc: 0.951 - ETA: 1:36 - loss: 0.1504 - acc: 0.951 - ETA: 1:35 - loss: 0.1504 - acc: 0.951 - ETA: 1:35 - loss: 0.1546 - acc: 0.950 - ETA: 1:35 - loss: 0.1537 - acc: 0.950 - ETA: 1:34 - loss: 0.1523 - acc: 0.950 - ETA: 1:34 - loss: 0.1512 - acc: 0.950 - ETA: 1:34 - loss: 0.1522 - acc: 0.950 - ETA: 1:33 - loss: 0.1513 - acc: 0.951 - ETA: 1:33 - loss: 0.1496 - acc: 0.952 - ETA: 1:33 - loss: 0.1477 - acc: 0.953 - ETA: 1:33 - loss: 0.1473 - acc: 0.953 - ETA: 1:33 - loss: 0.1458 - acc: 0.953 - ETA: 1:33 - loss: 0.1455 - acc: 0.953 - ETA: 1:33 - loss: 0.1446 - acc: 0.954 - ETA: 1:32 - loss: 0.1438 - acc: 0.954 - ETA: 1:32 - loss: 0.1442 - acc: 0.954 - ETA: 1:32 - loss: 0.1465 - acc: 0.952 - ETA: 1:31 - loss: 0.1492 - acc: 0.952 - ETA: 1:31 - loss: 0.1538 - acc: 0.951 - ETA: 1:31 - loss: 0.1544 - acc: 0.950 - ETA: 1:31 - loss: 0.1540 - acc: 0.951 - ETA: 1:30 - loss: 0.1536 - acc: 0.951 - ETA: 1:30 - loss: 0.1553 - acc: 0.951 - ETA: 1:30 - loss: 0.1541 - acc: 0.951 - ETA: 1:29 - loss: 0.1549 - acc: 0.951 - ETA: 1:29 - loss: 0.1560 - acc: 0.951 - ETA: 1:29 - loss: 0.1549 - acc: 0.951 - ETA: 1:29 - loss: 0.1571 - acc: 0.950 - ETA: 1:28 - loss: 0.1584 - acc: 0.950 - ETA: 1:27 - loss: 0.1584 - acc: 0.950 - ETA: 1:27 - loss: 0.1573 - acc: 0.951 - ETA: 1:27 - loss: 0.1593 - acc: 0.950 - ETA: 1:27 - loss: 0.1594 - acc: 0.950 - ETA: 1:27 - loss: 0.1600 - acc: 0.948 - ETA: 1:26 - loss: 0.1621 - acc: 0.948 - ETA: 1:26 - loss: 0.1621 - acc: 0.948 - ETA: 1:26 - loss: 0.1638 - acc: 0.947 - ETA: 1:26 - loss: 0.1630 - acc: 0.948 - ETA: 1:26 - loss: 0.1646 - acc: 0.947 - ETA: 1:25 - loss: 0.1655 - acc: 0.947 - ETA: 1:25 - loss: 0.1658 - acc: 0.946 - ETA: 1:25 - loss: 0.1671 - acc: 0.945 - ETA: 1:25 - loss: 0.1668 - acc: 0.945 - ETA: 1:24 - loss: 0.1656 - acc: 0.946 - ETA: 1:23 - loss: 0.1672 - acc: 0.945 - ETA: 1:23 - loss: 0.1675 - acc: 0.945 - ETA: 1:23 - loss: 0.1664 - acc: 0.945 - ETA: 1:23 - loss: 0.1674 - acc: 0.945 - ETA: 1:23 - loss: 0.1665 - acc: 0.945 - ETA: 1:22 - loss: 0.1667 - acc: 0.945 - ETA: 1:22 - loss: 0.1657 - acc: 0.945 - ETA: 1:22 - loss: 0.1667 - acc: 0.944 - ETA: 1:22 - loss: 0.1662 - acc: 0.944 - ETA: 1:22 - loss: 0.1662 - acc: 0.945 - ETA: 1:21 - loss: 0.1663 - acc: 0.944 - ETA: 1:21 - loss: 0.1669 - acc: 0.944 - ETA: 1:21 - loss: 0.1739 - acc: 0.942 - ETA: 1:20 - loss: 0.1741 - acc: 0.942 - ETA: 1:20 - loss: 0.1736 - acc: 0.942 - ETA: 1:20 - loss: 0.1732 - acc: 0.942 - ETA: 1:20 - loss: 0.1736 - acc: 0.942 - ETA: 1:20 - loss: 0.1735 - acc: 0.942 - ETA: 1:20 - loss: 0.1728 - acc: 0.942 - ETA: 1:19 - loss: 0.1717 - acc: 0.943 - ETA: 1:19 - loss: 0.1709 - acc: 0.943 - ETA: 1:19 - loss: 0.1727 - acc: 0.943 - ETA: 1:18 - loss: 0.1716 - acc: 0.944 - ETA: 1:18 - loss: 0.1710 - acc: 0.944 - ETA: 1:18 - loss: 0.1717 - acc: 0.944 - ETA: 1:18 - loss: 0.1738 - acc: 0.942 - ETA: 1:17 - loss: 0.1742 - acc: 0.942 - ETA: 1:17 - loss: 0.1739 - acc: 0.942 - ETA: 1:17 - loss: 0.1743 - acc: 0.941 - ETA: 1:16 - loss: 0.1732 - acc: 0.942 - ETA: 1:16 - loss: 0.1723 - acc: 0.942 - ETA: 1:16 - loss: 0.1711 - acc: 0.943 - ETA: 1:16 - loss: 0.1702 - acc: 0.943 - ETA: 1:15 - loss: 0.1706 - acc: 0.943 - ETA: 1:15 - loss: 0.1706 - acc: 0.943 - ETA: 1:15 - loss: 0.1701 - acc: 0.943 - ETA: 1:15 - loss: 0.1702 - acc: 0.943 - ETA: 1:15 - loss: 0.1694 - acc: 0.944 - ETA: 1:14 - loss: 0.1690 - acc: 0.944 - ETA: 1:14 - loss: 0.1682 - acc: 0.944 - ETA: 1:14 - loss: 0.1677 - acc: 0.944 - ETA: 1:14 - loss: 0.1683 - acc: 0.944 - ETA: 1:13 - loss: 0.1683 - acc: 0.944 - ETA: 1:13 - loss: 0.1683 - acc: 0.944 - ETA: 1:13 - loss: 0.1687 - acc: 0.944 - ETA: 1:13 - loss: 0.1686 - acc: 0.944 - ETA: 1:12 - loss: 0.1679 - acc: 0.944 - ETA: 1:12 - loss: 0.1677 - acc: 0.944 - ETA: 1:12 - loss: 0.1694 - acc: 0.944 - ETA: 1:11 - loss: 0.1701 - acc: 0.944 - ETA: 1:11 - loss: 0.1696 - acc: 0.944 - ETA: 1:11 - loss: 0.1687 - acc: 0.944 - ETA: 1:10 - loss: 0.1683 - acc: 0.944 - ETA: 1:10 - loss: 0.1689 - acc: 0.944 - ETA: 1:10 - loss: 0.1688 - acc: 0.944 - ETA: 1:10 - loss: 0.1692 - acc: 0.944 - ETA: 1:09 - loss: 0.1683 - acc: 0.944 - ETA: 1:09 - loss: 0.1696 - acc: 0.944 - ETA: 1:09 - loss: 0.1700 - acc: 0.944 - ETA: 1:09 - loss: 0.1697 - acc: 0.944 - ETA: 1:08 - loss: 0.1700 - acc: 0.943 - ETA: 1:08 - loss: 0.1696 - acc: 0.943 - ETA: 1:08 - loss: 0.1689 - acc: 0.944 - ETA: 1:08 - loss: 0.1687 - acc: 0.944 - ETA: 1:08 - loss: 0.1687 - acc: 0.944 - ETA: 1:07 - loss: 0.1682 - acc: 0.944 - ETA: 1:07 - loss: 0.1705 - acc: 0.943 - ETA: 1:07 - loss: 0.1703 - acc: 0.943 - ETA: 1:07 - loss: 0.1700 - acc: 0.943 - ETA: 1:06 - loss: 0.1704 - acc: 0.943 - ETA: 1:06 - loss: 0.1698 - acc: 0.943 - ETA: 1:06 - loss: 0.1691 - acc: 0.943 - ETA: 1:05 - loss: 0.1684 - acc: 0.944 - ETA: 1:05 - loss: 0.1688 - acc: 0.943 - ETA: 1:05 - loss: 0.1687 - acc: 0.943 - ETA: 1:05 - loss: 0.1680 - acc: 0.944 - ETA: 1:04 - loss: 0.1681 - acc: 0.943 - ETA: 1:04 - loss: 0.1677 - acc: 0.944 - ETA: 1:04 - loss: 0.1671 - acc: 0.944 - ETA: 1:04 - loss: 0.1670 - acc: 0.943 - ETA: 1:03 - loss: 0.1663 - acc: 0.944 - ETA: 1:03 - loss: 0.1661 - acc: 0.944 - ETA: 1:03 - loss: 0.1658 - acc: 0.944 - ETA: 1:03 - loss: 0.1659 - acc: 0.944 - ETA: 1:02 - loss: 0.1670 - acc: 0.943 - ETA: 1:02 - loss: 0.1667 - acc: 0.943 - ETA: 1:02 - loss: 0.1669 - acc: 0.943 - ETA: 1:02 - loss: 0.1667 - acc: 0.943 - ETA: 1:01 - loss: 0.1674 - acc: 0.943 - ETA: 1:01 - loss: 0.1672 - acc: 0.943 - ETA: 1:01 - loss: 0.1672 - acc: 0.942 - ETA: 1:00 - loss: 0.1668 - acc: 0.942 - ETA: 1:00 - loss: 0.1665 - acc: 0.942 - ETA: 1:00 - loss: 0.1665 - acc: 0.942 - ETA: 1:00 - loss: 0.1665 - acc: 0.942 - ETA: 59s - loss: 0.1660 - acc: 0.942 - ETA: 59s - loss: 0.1662 - acc: 0.94 - ETA: 59s - loss: 0.1668 - acc: 0.94 - ETA: 59s - loss: 0.1665 - acc: 0.94 - ETA: 58s - loss: 0.1665 - acc: 0.94 - ETA: 58s - loss: 0.1674 - acc: 0.94 - ETA: 58s - loss: 0.1671 - acc: 0.94 - ETA: 58s - loss: 0.1678 - acc: 0.94 - ETA: 57s - loss: 0.1681 - acc: 0.94 - ETA: 57s - loss: 0.1678 - acc: 0.94 - ETA: 57s - loss: 0.1679 - acc: 0.94 - ETA: 57s - loss: 0.1674 - acc: 0.9418420/427 [============================>.] - ETA: 56s - loss: 0.1678 - acc: 0.94 - ETA: 56s - loss: 0.1673 - acc: 0.94 - ETA: 56s - loss: 0.1671 - acc: 0.94 - ETA: 56s - loss: 0.1671 - acc: 0.94 - ETA: 55s - loss: 0.1693 - acc: 0.94 - ETA: 55s - loss: 0.1699 - acc: 0.94 - ETA: 55s - loss: 0.1695 - acc: 0.94 - ETA: 54s - loss: 0.1690 - acc: 0.94 - ETA: 54s - loss: 0.1692 - acc: 0.94 - ETA: 54s - loss: 0.1688 - acc: 0.94 - ETA: 54s - loss: 0.1682 - acc: 0.94 - ETA: 53s - loss: 0.1681 - acc: 0.94 - ETA: 53s - loss: 0.1689 - acc: 0.94 - ETA: 53s - loss: 0.1688 - acc: 0.94 - ETA: 53s - loss: 0.1684 - acc: 0.94 - ETA: 52s - loss: 0.1683 - acc: 0.94 - ETA: 52s - loss: 0.1679 - acc: 0.94 - ETA: 52s - loss: 0.1677 - acc: 0.94 - ETA: 52s - loss: 0.1673 - acc: 0.94 - ETA: 51s - loss: 0.1675 - acc: 0.94 - ETA: 51s - loss: 0.1675 - acc: 0.94 - ETA: 51s - loss: 0.1673 - acc: 0.94 - ETA: 51s - loss: 0.1676 - acc: 0.94 - ETA: 50s - loss: 0.1677 - acc: 0.94 - ETA: 50s - loss: 0.1679 - acc: 0.94 - ETA: 50s - loss: 0.1676 - acc: 0.94 - ETA: 50s - loss: 0.1672 - acc: 0.94 - ETA: 49s - loss: 0.1680 - acc: 0.94 - ETA: 49s - loss: 0.1678 - acc: 0.94 - ETA: 49s - loss: 0.1678 - acc: 0.94 - ETA: 49s - loss: 0.1677 - acc: 0.94 - ETA: 48s - loss: 0.1677 - acc: 0.94 - ETA: 48s - loss: 0.1673 - acc: 0.94 - ETA: 48s - loss: 0.1671 - acc: 0.94 - ETA: 48s - loss: 0.1672 - acc: 0.94 - ETA: 47s - loss: 0.1669 - acc: 0.94 - ETA: 47s - loss: 0.1667 - acc: 0.94 - ETA: 47s - loss: 0.1661 - acc: 0.94 - ETA: 47s - loss: 0.1660 - acc: 0.94 - ETA: 46s - loss: 0.1655 - acc: 0.94 - ETA: 46s - loss: 0.1653 - acc: 0.94 - ETA: 46s - loss: 0.1649 - acc: 0.94 - ETA: 46s - loss: 0.1651 - acc: 0.94 - ETA: 45s - loss: 0.1654 - acc: 0.94 - ETA: 45s - loss: 0.1657 - acc: 0.94 - ETA: 45s - loss: 0.1652 - acc: 0.94 - ETA: 45s - loss: 0.1656 - acc: 0.94 - ETA: 44s - loss: 0.1657 - acc: 0.94 - ETA: 44s - loss: 0.1652 - acc: 0.94 - ETA: 44s - loss: 0.1651 - acc: 0.94 - ETA: 44s - loss: 0.1654 - acc: 0.94 - ETA: 43s - loss: 0.1665 - acc: 0.94 - ETA: 43s - loss: 0.1674 - acc: 0.94 - ETA: 43s - loss: 0.1671 - acc: 0.94 - ETA: 42s - loss: 0.1668 - acc: 0.94 - ETA: 42s - loss: 0.1671 - acc: 0.94 - ETA: 42s - loss: 0.1668 - acc: 0.94 - ETA: 42s - loss: 0.1664 - acc: 0.94 - ETA: 41s - loss: 0.1671 - acc: 0.94 - ETA: 41s - loss: 0.1677 - acc: 0.94 - ETA: 41s - loss: 0.1676 - acc: 0.94 - ETA: 41s - loss: 0.1672 - acc: 0.94 - ETA: 40s - loss: 0.1669 - acc: 0.94 - ETA: 40s - loss: 0.1667 - acc: 0.94 - ETA: 40s - loss: 0.1668 - acc: 0.94 - ETA: 39s - loss: 0.1672 - acc: 0.94 - ETA: 39s - loss: 0.1669 - acc: 0.94 - ETA: 39s - loss: 0.1674 - acc: 0.94 - ETA: 39s - loss: 0.1672 - acc: 0.94 - ETA: 38s - loss: 0.1671 - acc: 0.94 - ETA: 38s - loss: 0.1678 - acc: 0.94 - ETA: 38s - loss: 0.1679 - acc: 0.94 - ETA: 38s - loss: 0.1677 - acc: 0.94 - ETA: 37s - loss: 0.1677 - acc: 0.94 - ETA: 37s - loss: 0.1674 - acc: 0.94 - ETA: 37s - loss: 0.1670 - acc: 0.94 - ETA: 37s - loss: 0.1666 - acc: 0.94 - ETA: 36s - loss: 0.1666 - acc: 0.94 - ETA: 36s - loss: 0.1668 - acc: 0.94 - ETA: 36s - loss: 0.1666 - acc: 0.94 - ETA: 36s - loss: 0.1670 - acc: 0.94 - ETA: 35s - loss: 0.1669 - acc: 0.94 - ETA: 35s - loss: 0.1677 - acc: 0.94 - ETA: 35s - loss: 0.1677 - acc: 0.94 - ETA: 35s - loss: 0.1676 - acc: 0.94 - ETA: 34s - loss: 0.1676 - acc: 0.94 - ETA: 34s - loss: 0.1676 - acc: 0.94 - ETA: 34s - loss: 0.1672 - acc: 0.94 - ETA: 34s - loss: 0.1668 - acc: 0.94 - ETA: 33s - loss: 0.1666 - acc: 0.94 - ETA: 33s - loss: 0.1663 - acc: 0.94 - ETA: 33s - loss: 0.1664 - acc: 0.94 - ETA: 33s - loss: 0.1671 - acc: 0.94 - ETA: 32s - loss: 0.1667 - acc: 0.94 - ETA: 32s - loss: 0.1669 - acc: 0.94 - ETA: 32s - loss: 0.1665 - acc: 0.94 - ETA: 32s - loss: 0.1667 - acc: 0.94 - ETA: 31s - loss: 0.1663 - acc: 0.94 - ETA: 31s - loss: 0.1660 - acc: 0.94 - ETA: 31s - loss: 0.1662 - acc: 0.94 - ETA: 31s - loss: 0.1658 - acc: 0.94 - ETA: 30s - loss: 0.1664 - acc: 0.94 - ETA: 30s - loss: 0.1664 - acc: 0.94 - ETA: 30s - loss: 0.1660 - acc: 0.94 - ETA: 30s - loss: 0.1659 - acc: 0.94 - ETA: 29s - loss: 0.1656 - acc: 0.94 - ETA: 29s - loss: 0.1652 - acc: 0.94 - ETA: 29s - loss: 0.1649 - acc: 0.94 - ETA: 29s - loss: 0.1647 - acc: 0.94 - ETA: 28s - loss: 0.1647 - acc: 0.94 - ETA: 28s - loss: 0.1645 - acc: 0.94 - ETA: 28s - loss: 0.1644 - acc: 0.94 - ETA: 28s - loss: 0.1649 - acc: 0.94 - ETA: 27s - loss: 0.1655 - acc: 0.94 - ETA: 27s - loss: 0.1653 - acc: 0.94 - ETA: 27s - loss: 0.1653 - acc: 0.94 - ETA: 26s - loss: 0.1648 - acc: 0.94 - ETA: 26s - loss: 0.1645 - acc: 0.94 - ETA: 26s - loss: 0.1641 - acc: 0.94 - ETA: 26s - loss: 0.1642 - acc: 0.94 - ETA: 25s - loss: 0.1640 - acc: 0.94 - ETA: 25s - loss: 0.1639 - acc: 0.94 - ETA: 25s - loss: 0.1638 - acc: 0.94 - ETA: 25s - loss: 0.1636 - acc: 0.94 - ETA: 24s - loss: 0.1636 - acc: 0.94 - ETA: 24s - loss: 0.1638 - acc: 0.94 - ETA: 24s - loss: 0.1637 - acc: 0.94 - ETA: 24s - loss: 0.1634 - acc: 0.94 - ETA: 23s - loss: 0.1635 - acc: 0.94 - ETA: 23s - loss: 0.1645 - acc: 0.94 - ETA: 23s - loss: 0.1642 - acc: 0.94 - ETA: 23s - loss: 0.1642 - acc: 0.94 - ETA: 22s - loss: 0.1644 - acc: 0.94 - ETA: 22s - loss: 0.1645 - acc: 0.94 - ETA: 22s - loss: 0.1647 - acc: 0.94 - ETA: 22s - loss: 0.1646 - acc: 0.94 - ETA: 21s - loss: 0.1647 - acc: 0.94 - ETA: 21s - loss: 0.1647 - acc: 0.94 - ETA: 21s - loss: 0.1645 - acc: 0.94 - ETA: 21s - loss: 0.1646 - acc: 0.94 - ETA: 20s - loss: 0.1644 - acc: 0.94 - ETA: 20s - loss: 0.1643 - acc: 0.94 - ETA: 20s - loss: 0.1644 - acc: 0.94 - ETA: 20s - loss: 0.1640 - acc: 0.94 - ETA: 19s - loss: 0.1638 - acc: 0.94 - ETA: 19s - loss: 0.1640 - acc: 0.94 - ETA: 19s - loss: 0.1639 - acc: 0.94 - ETA: 18s - loss: 0.1640 - acc: 0.94 - ETA: 18s - loss: 0.1642 - acc: 0.94 - ETA: 18s - loss: 0.1639 - acc: 0.94 - ETA: 18s - loss: 0.1637 - acc: 0.94 - ETA: 17s - loss: 0.1640 - acc: 0.94 - ETA: 17s - loss: 0.1636 - acc: 0.94 - ETA: 17s - loss: 0.1636 - acc: 0.94 - ETA: 17s - loss: 0.1634 - acc: 0.94 - ETA: 16s - loss: 0.1636 - acc: 0.94 - ETA: 16s - loss: 0.1645 - acc: 0.94 - ETA: 16s - loss: 0.1645 - acc: 0.94 - ETA: 16s - loss: 0.1644 - acc: 0.94 - ETA: 15s - loss: 0.1651 - acc: 0.94 - ETA: 15s - loss: 0.1653 - acc: 0.94 - ETA: 15s - loss: 0.1651 - acc: 0.94 - ETA: 15s - loss: 0.1650 - acc: 0.94 - ETA: 14s - loss: 0.1651 - acc: 0.94 - ETA: 14s - loss: 0.1650 - acc: 0.94 - ETA: 14s - loss: 0.1648 - acc: 0.94 - ETA: 14s - loss: 0.1650 - acc: 0.94 - ETA: 13s - loss: 0.1649 - acc: 0.94 - ETA: 13s - loss: 0.1648 - acc: 0.94 - ETA: 13s - loss: 0.1648 - acc: 0.94 - ETA: 13s - loss: 0.1645 - acc: 0.94 - ETA: 12s - loss: 0.1649 - acc: 0.94 - ETA: 12s - loss: 0.1646 - acc: 0.94 - ETA: 12s - loss: 0.1644 - acc: 0.94 - ETA: 12s - loss: 0.1649 - acc: 0.94 - ETA: 11s - loss: 0.1646 - acc: 0.94 - ETA: 11s - loss: 0.1649 - acc: 0.94 - ETA: 11s - loss: 0.1650 - acc: 0.94 - ETA: 11s - loss: 0.1648 - acc: 0.94 - ETA: 10s - loss: 0.1647 - acc: 0.94 - ETA: 10s - loss: 0.1648 - acc: 0.94 - ETA: 10s - loss: 0.1645 - acc: 0.94 - ETA: 10s - loss: 0.1644 - acc: 0.94 - ETA: 9s - loss: 0.1650 - acc: 0.9439 - ETA: 9s - loss: 0.1672 - acc: 0.943 - ETA: 9s - loss: 0.1671 - acc: 0.943 - ETA: 8s - loss: 0.1674 - acc: 0.943 - ETA: 8s - loss: 0.1670 - acc: 0.943 - ETA: 8s - loss: 0.1668 - acc: 0.943 - ETA: 8s - loss: 0.1666 - acc: 0.943 - ETA: 7s - loss: 0.1663 - acc: 0.944 - ETA: 7s - loss: 0.1664 - acc: 0.944 - ETA: 7s - loss: 0.1663 - acc: 0.944 - ETA: 7s - loss: 0.1662 - acc: 0.944 - ETA: 6s - loss: 0.1662 - acc: 0.943 - ETA: 6s - loss: 0.1661 - acc: 0.943 - ETA: 6s - loss: 0.1657 - acc: 0.944 - ETA: 6s - loss: 0.1658 - acc: 0.944 - ETA: 5s - loss: 0.1655 - acc: 0.944 - ETA: 5s - loss: 0.1661 - acc: 0.943 - ETA: 5s - loss: 0.1660 - acc: 0.943 - ETA: 5s - loss: 0.1658 - acc: 0.943 - ETA: 4s - loss: 0.1656 - acc: 0.943 - ETA: 4s - loss: 0.1654 - acc: 0.944 - ETA: 4s - loss: 0.1651 - acc: 0.944 - ETA: 4s - loss: 0.1654 - acc: 0.944 - ETA: 3s - loss: 0.1653 - acc: 0.944 - ETA: 3s - loss: 0.1650 - acc: 0.944 - ETA: 3s - loss: 0.1649 - acc: 0.944 - ETA: 3s - loss: 0.1648 - acc: 0.944 - ETA: 2s - loss: 0.1645 - acc: 0.944 - ETA: 2s - loss: 0.1645 - acc: 0.944 - ETA: 2s - loss: 0.1642 - acc: 0.944 - ETA: 2s - loss: 0.1648 - acc: 0.944 - ETA: 1s - loss: 0.1646 - acc: 0.9446426/427 [============================>.] - ETA: 1s - loss: 0.1648 - acc: 0.944 - ETA: 1s - loss: 0.1645 - acc: 0.944 - ETA: 1s - loss: 0.1654 - acc: 0.944 - ETA: 0s - loss: 0.1652 - acc: 0.944 - ETA: 0s - loss: 0.1650 - acc: 0.944 - ETA: 0s - loss: 0.1647 - acc: 0.9449\n",
      "Epoch 00011: val_loss did not improve\n",
      "427/427 [==============================] - 111s 260ms/step - loss: 0.1646 - acc: 0.9448 - val_loss: 0.4310 - val_acc: 0.8348\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:46 - loss: 0.2075 - acc: 0.950 - ETA: 1:46 - loss: 0.1955 - acc: 0.950 - ETA: 1:46 - loss: 0.1738 - acc: 0.950 - ETA: 1:46 - loss: 0.1802 - acc: 0.937 - ETA: 1:47 - loss: 0.1640 - acc: 0.940 - ETA: 1:49 - loss: 0.1580 - acc: 0.941 - ETA: 1:50 - loss: 0.1470 - acc: 0.950 - ETA: 1:50 - loss: 0.1387 - acc: 0.956 - ETA: 1:51 - loss: 0.1483 - acc: 0.950 - ETA: 1:49 - loss: 0.1641 - acc: 0.945 - ETA: 1:50 - loss: 0.1620 - acc: 0.945 - ETA: 1:49 - loss: 0.1548 - acc: 0.950 - ETA: 1:49 - loss: 0.1489 - acc: 0.953 - ETA: 1:48 - loss: 0.1465 - acc: 0.953 - ETA: 1:48 - loss: 0.1483 - acc: 0.953 - ETA: 1:47 - loss: 0.1413 - acc: 0.956 - ETA: 1:47 - loss: 0.1565 - acc: 0.955 - ETA: 1:46 - loss: 0.1532 - acc: 0.958 - ETA: 1:46 - loss: 0.1500 - acc: 0.957 - ETA: 1:45 - loss: 0.1523 - acc: 0.957 - ETA: 1:45 - loss: 0.1480 - acc: 0.959 - ETA: 1:45 - loss: 0.1474 - acc: 0.959 - ETA: 1:44 - loss: 0.1437 - acc: 0.960 - ETA: 1:44 - loss: 0.1442 - acc: 0.960 - ETA: 1:43 - loss: 0.1423 - acc: 0.962 - ETA: 1:43 - loss: 0.1391 - acc: 0.963 - ETA: 1:43 - loss: 0.1382 - acc: 0.963 - ETA: 1:42 - loss: 0.1368 - acc: 0.964 - ETA: 1:43 - loss: 0.1346 - acc: 0.965 - ETA: 1:43 - loss: 0.1323 - acc: 0.966 - ETA: 1:40 - loss: 0.1304 - acc: 0.967 - ETA: 1:40 - loss: 0.1275 - acc: 0.968 - ETA: 1:41 - loss: 0.1290 - acc: 0.968 - ETA: 1:40 - loss: 0.1321 - acc: 0.966 - ETA: 1:40 - loss: 0.1292 - acc: 0.967 - ETA: 1:40 - loss: 0.1288 - acc: 0.966 - ETA: 1:40 - loss: 0.1257 - acc: 0.967 - ETA: 1:39 - loss: 0.1254 - acc: 0.967 - ETA: 1:39 - loss: 0.1345 - acc: 0.961 - ETA: 1:39 - loss: 0.1331 - acc: 0.961 - ETA: 1:38 - loss: 0.1305 - acc: 0.962 - ETA: 1:38 - loss: 0.1348 - acc: 0.959 - ETA: 1:38 - loss: 0.1339 - acc: 0.959 - ETA: 1:38 - loss: 0.1316 - acc: 0.960 - ETA: 1:38 - loss: 0.1314 - acc: 0.960 - ETA: 1:37 - loss: 0.1303 - acc: 0.959 - ETA: 1:37 - loss: 0.1299 - acc: 0.959 - ETA: 1:37 - loss: 0.1293 - acc: 0.960 - ETA: 1:37 - loss: 0.1303 - acc: 0.959 - ETA: 1:37 - loss: 0.1305 - acc: 0.959 - ETA: 1:35 - loss: 0.1293 - acc: 0.959 - ETA: 1:35 - loss: 0.1304 - acc: 0.957 - ETA: 1:35 - loss: 0.1316 - acc: 0.957 - ETA: 1:35 - loss: 0.1328 - acc: 0.957 - ETA: 1:35 - loss: 0.1360 - acc: 0.956 - ETA: 1:35 - loss: 0.1361 - acc: 0.956 - ETA: 1:35 - loss: 0.1341 - acc: 0.957 - ETA: 1:35 - loss: 0.1323 - acc: 0.957 - ETA: 1:35 - loss: 0.1319 - acc: 0.958 - ETA: 1:34 - loss: 0.1350 - acc: 0.956 - ETA: 1:33 - loss: 0.1334 - acc: 0.957 - ETA: 1:33 - loss: 0.1339 - acc: 0.956 - ETA: 1:33 - loss: 0.1357 - acc: 0.955 - ETA: 1:32 - loss: 0.1357 - acc: 0.955 - ETA: 1:32 - loss: 0.1362 - acc: 0.955 - ETA: 1:32 - loss: 0.1359 - acc: 0.955 - ETA: 1:32 - loss: 0.1361 - acc: 0.954 - ETA: 1:31 - loss: 0.1393 - acc: 0.953 - ETA: 1:31 - loss: 0.1378 - acc: 0.954 - ETA: 1:31 - loss: 0.1371 - acc: 0.955 - ETA: 1:31 - loss: 0.1380 - acc: 0.954 - ETA: 1:30 - loss: 0.1393 - acc: 0.953 - ETA: 1:30 - loss: 0.1395 - acc: 0.953 - ETA: 1:30 - loss: 0.1417 - acc: 0.952 - ETA: 1:30 - loss: 0.1406 - acc: 0.953 - ETA: 1:29 - loss: 0.1414 - acc: 0.953 - ETA: 1:29 - loss: 0.1401 - acc: 0.954 - ETA: 1:29 - loss: 0.1398 - acc: 0.953 - ETA: 1:29 - loss: 0.1391 - acc: 0.954 - ETA: 1:29 - loss: 0.1381 - acc: 0.955 - ETA: 1:29 - loss: 0.1382 - acc: 0.954 - ETA: 1:28 - loss: 0.1379 - acc: 0.954 - ETA: 1:28 - loss: 0.1375 - acc: 0.954 - ETA: 1:28 - loss: 0.1374 - acc: 0.954 - ETA: 1:28 - loss: 0.1375 - acc: 0.954 - ETA: 1:27 - loss: 0.1415 - acc: 0.952 - ETA: 1:27 - loss: 0.1411 - acc: 0.952 - ETA: 1:27 - loss: 0.1458 - acc: 0.950 - ETA: 1:27 - loss: 0.1450 - acc: 0.951 - ETA: 1:26 - loss: 0.1455 - acc: 0.950 - ETA: 1:26 - loss: 0.1472 - acc: 0.950 - ETA: 1:26 - loss: 0.1467 - acc: 0.950 - ETA: 1:25 - loss: 0.1482 - acc: 0.949 - ETA: 1:25 - loss: 0.1475 - acc: 0.950 - ETA: 1:24 - loss: 0.1528 - acc: 0.947 - ETA: 1:24 - loss: 0.1532 - acc: 0.947 - ETA: 1:24 - loss: 0.1522 - acc: 0.947 - ETA: 1:23 - loss: 0.1521 - acc: 0.947 - ETA: 1:23 - loss: 0.1520 - acc: 0.947 - ETA: 1:23 - loss: 0.1524 - acc: 0.947 - ETA: 1:23 - loss: 0.1537 - acc: 0.946 - ETA: 1:22 - loss: 0.1528 - acc: 0.947 - ETA: 1:22 - loss: 0.1542 - acc: 0.946 - ETA: 1:22 - loss: 0.1537 - acc: 0.946 - ETA: 1:22 - loss: 0.1526 - acc: 0.946 - ETA: 1:22 - loss: 0.1520 - acc: 0.947 - ETA: 1:21 - loss: 0.1512 - acc: 0.947 - ETA: 1:21 - loss: 0.1509 - acc: 0.947 - ETA: 1:21 - loss: 0.1511 - acc: 0.947 - ETA: 1:21 - loss: 0.1511 - acc: 0.947 - ETA: 1:21 - loss: 0.1527 - acc: 0.946 - ETA: 1:20 - loss: 0.1517 - acc: 0.946 - ETA: 1:20 - loss: 0.1516 - acc: 0.946 - ETA: 1:20 - loss: 0.1519 - acc: 0.946 - ETA: 1:20 - loss: 0.1513 - acc: 0.946 - ETA: 1:19 - loss: 0.1508 - acc: 0.946 - ETA: 1:19 - loss: 0.1502 - acc: 0.947 - ETA: 1:19 - loss: 0.1514 - acc: 0.946 - ETA: 1:19 - loss: 0.1504 - acc: 0.947 - ETA: 1:18 - loss: 0.1537 - acc: 0.946 - ETA: 1:18 - loss: 0.1548 - acc: 0.945 - ETA: 1:18 - loss: 0.1548 - acc: 0.945 - ETA: 1:18 - loss: 0.1554 - acc: 0.945 - ETA: 1:18 - loss: 0.1551 - acc: 0.945 - ETA: 1:18 - loss: 0.1542 - acc: 0.946 - ETA: 1:17 - loss: 0.1560 - acc: 0.945 - ETA: 1:17 - loss: 0.1555 - acc: 0.946 - ETA: 1:17 - loss: 0.1552 - acc: 0.946 - ETA: 1:16 - loss: 0.1552 - acc: 0.946 - ETA: 1:16 - loss: 0.1548 - acc: 0.946 - ETA: 1:16 - loss: 0.1543 - acc: 0.946 - ETA: 1:16 - loss: 0.1536 - acc: 0.947 - ETA: 1:15 - loss: 0.1548 - acc: 0.946 - ETA: 1:15 - loss: 0.1548 - acc: 0.946 - ETA: 1:15 - loss: 0.1547 - acc: 0.946 - ETA: 1:15 - loss: 0.1563 - acc: 0.945 - ETA: 1:14 - loss: 0.1561 - acc: 0.945 - ETA: 1:14 - loss: 0.1578 - acc: 0.945 - ETA: 1:14 - loss: 0.1584 - acc: 0.945 - ETA: 1:14 - loss: 0.1589 - acc: 0.945 - ETA: 1:13 - loss: 0.1582 - acc: 0.945 - ETA: 1:13 - loss: 0.1576 - acc: 0.946 - ETA: 1:13 - loss: 0.1587 - acc: 0.946 - ETA: 1:12 - loss: 0.1580 - acc: 0.946 - ETA: 1:12 - loss: 0.1582 - acc: 0.946 - ETA: 1:12 - loss: 0.1583 - acc: 0.946 - ETA: 1:11 - loss: 0.1582 - acc: 0.946 - ETA: 1:11 - loss: 0.1583 - acc: 0.946 - ETA: 1:11 - loss: 0.1575 - acc: 0.946 - ETA: 1:11 - loss: 0.1590 - acc: 0.946 - ETA: 1:10 - loss: 0.1582 - acc: 0.946 - ETA: 1:10 - loss: 0.1578 - acc: 0.946 - ETA: 1:10 - loss: 0.1571 - acc: 0.947 - ETA: 1:10 - loss: 0.1575 - acc: 0.947 - ETA: 1:09 - loss: 0.1568 - acc: 0.947 - ETA: 1:09 - loss: 0.1564 - acc: 0.947 - ETA: 1:09 - loss: 0.1567 - acc: 0.947 - ETA: 1:09 - loss: 0.1560 - acc: 0.948 - ETA: 1:08 - loss: 0.1552 - acc: 0.948 - ETA: 1:08 - loss: 0.1546 - acc: 0.948 - ETA: 1:08 - loss: 0.1539 - acc: 0.948 - ETA: 1:08 - loss: 0.1533 - acc: 0.948 - ETA: 1:07 - loss: 0.1528 - acc: 0.948 - ETA: 1:07 - loss: 0.1531 - acc: 0.948 - ETA: 1:07 - loss: 0.1541 - acc: 0.948 - ETA: 1:07 - loss: 0.1538 - acc: 0.948 - ETA: 1:06 - loss: 0.1532 - acc: 0.948 - ETA: 1:06 - loss: 0.1540 - acc: 0.948 - ETA: 1:06 - loss: 0.1540 - acc: 0.948 - ETA: 1:06 - loss: 0.1533 - acc: 0.948 - ETA: 1:06 - loss: 0.1528 - acc: 0.948 - ETA: 1:05 - loss: 0.1522 - acc: 0.949 - ETA: 1:05 - loss: 0.1535 - acc: 0.948 - ETA: 1:05 - loss: 0.1534 - acc: 0.947 - ETA: 1:05 - loss: 0.1540 - acc: 0.947 - ETA: 1:04 - loss: 0.1536 - acc: 0.947 - ETA: 1:04 - loss: 0.1529 - acc: 0.948 - ETA: 1:04 - loss: 0.1545 - acc: 0.947 - ETA: 1:03 - loss: 0.1545 - acc: 0.948 - ETA: 1:03 - loss: 0.1542 - acc: 0.948 - ETA: 1:03 - loss: 0.1537 - acc: 0.948 - ETA: 1:03 - loss: 0.1545 - acc: 0.948 - ETA: 1:02 - loss: 0.1542 - acc: 0.948 - ETA: 1:02 - loss: 0.1542 - acc: 0.948 - ETA: 1:02 - loss: 0.1537 - acc: 0.948 - ETA: 1:02 - loss: 0.1539 - acc: 0.948 - ETA: 1:01 - loss: 0.1537 - acc: 0.948 - ETA: 1:01 - loss: 0.1531 - acc: 0.948 - ETA: 1:01 - loss: 0.1537 - acc: 0.948 - ETA: 1:01 - loss: 0.1546 - acc: 0.948 - ETA: 1:00 - loss: 0.1544 - acc: 0.948 - ETA: 1:00 - loss: 0.1553 - acc: 0.947 - ETA: 1:00 - loss: 0.1551 - acc: 0.947 - ETA: 1:00 - loss: 0.1548 - acc: 0.947 - ETA: 59s - loss: 0.1546 - acc: 0.947 - ETA: 59s - loss: 0.1556 - acc: 0.94 - ETA: 59s - loss: 0.1595 - acc: 0.94 - ETA: 59s - loss: 0.1598 - acc: 0.94 - ETA: 58s - loss: 0.1599 - acc: 0.94 - ETA: 58s - loss: 0.1597 - acc: 0.94 - ETA: 58s - loss: 0.1596 - acc: 0.94 - ETA: 57s - loss: 0.1592 - acc: 0.94 - ETA: 57s - loss: 0.1590 - acc: 0.94 - ETA: 57s - loss: 0.1588 - acc: 0.94 - ETA: 57s - loss: 0.1585 - acc: 0.9466420/427 [============================>.] - ETA: 56s - loss: 0.1581 - acc: 0.94 - ETA: 56s - loss: 0.1581 - acc: 0.94 - ETA: 56s - loss: 0.1576 - acc: 0.94 - ETA: 56s - loss: 0.1573 - acc: 0.94 - ETA: 55s - loss: 0.1570 - acc: 0.94 - ETA: 55s - loss: 0.1571 - acc: 0.94 - ETA: 55s - loss: 0.1571 - acc: 0.94 - ETA: 55s - loss: 0.1574 - acc: 0.94 - ETA: 54s - loss: 0.1575 - acc: 0.94 - ETA: 54s - loss: 0.1583 - acc: 0.94 - ETA: 54s - loss: 0.1581 - acc: 0.94 - ETA: 54s - loss: 0.1580 - acc: 0.94 - ETA: 53s - loss: 0.1579 - acc: 0.94 - ETA: 53s - loss: 0.1587 - acc: 0.94 - ETA: 53s - loss: 0.1582 - acc: 0.94 - ETA: 53s - loss: 0.1577 - acc: 0.94 - ETA: 52s - loss: 0.1577 - acc: 0.94 - ETA: 52s - loss: 0.1578 - acc: 0.94 - ETA: 52s - loss: 0.1575 - acc: 0.94 - ETA: 52s - loss: 0.1576 - acc: 0.94 - ETA: 51s - loss: 0.1583 - acc: 0.94 - ETA: 51s - loss: 0.1580 - acc: 0.94 - ETA: 51s - loss: 0.1595 - acc: 0.94 - ETA: 51s - loss: 0.1600 - acc: 0.94 - ETA: 50s - loss: 0.1640 - acc: 0.94 - ETA: 50s - loss: 0.1636 - acc: 0.94 - ETA: 50s - loss: 0.1634 - acc: 0.94 - ETA: 49s - loss: 0.1630 - acc: 0.94 - ETA: 49s - loss: 0.1625 - acc: 0.94 - ETA: 49s - loss: 0.1623 - acc: 0.94 - ETA: 49s - loss: 0.1630 - acc: 0.94 - ETA: 49s - loss: 0.1631 - acc: 0.94 - ETA: 48s - loss: 0.1628 - acc: 0.94 - ETA: 48s - loss: 0.1625 - acc: 0.94 - ETA: 48s - loss: 0.1622 - acc: 0.94 - ETA: 48s - loss: 0.1617 - acc: 0.94 - ETA: 47s - loss: 0.1620 - acc: 0.94 - ETA: 47s - loss: 0.1619 - acc: 0.94 - ETA: 47s - loss: 0.1627 - acc: 0.94 - ETA: 47s - loss: 0.1634 - acc: 0.94 - ETA: 46s - loss: 0.1633 - acc: 0.94 - ETA: 46s - loss: 0.1642 - acc: 0.94 - ETA: 46s - loss: 0.1655 - acc: 0.94 - ETA: 46s - loss: 0.1655 - acc: 0.94 - ETA: 45s - loss: 0.1651 - acc: 0.94 - ETA: 45s - loss: 0.1645 - acc: 0.94 - ETA: 45s - loss: 0.1647 - acc: 0.94 - ETA: 45s - loss: 0.1646 - acc: 0.94 - ETA: 44s - loss: 0.1645 - acc: 0.94 - ETA: 44s - loss: 0.1645 - acc: 0.94 - ETA: 44s - loss: 0.1645 - acc: 0.94 - ETA: 44s - loss: 0.1644 - acc: 0.94 - ETA: 43s - loss: 0.1643 - acc: 0.94 - ETA: 43s - loss: 0.1641 - acc: 0.94 - ETA: 43s - loss: 0.1641 - acc: 0.94 - ETA: 43s - loss: 0.1643 - acc: 0.94 - ETA: 42s - loss: 0.1651 - acc: 0.94 - ETA: 42s - loss: 0.1646 - acc: 0.94 - ETA: 42s - loss: 0.1642 - acc: 0.94 - ETA: 41s - loss: 0.1638 - acc: 0.94 - ETA: 41s - loss: 0.1639 - acc: 0.94 - ETA: 41s - loss: 0.1637 - acc: 0.94 - ETA: 41s - loss: 0.1633 - acc: 0.94 - ETA: 40s - loss: 0.1633 - acc: 0.94 - ETA: 40s - loss: 0.1630 - acc: 0.94 - ETA: 40s - loss: 0.1629 - acc: 0.94 - ETA: 40s - loss: 0.1631 - acc: 0.94 - ETA: 39s - loss: 0.1629 - acc: 0.94 - ETA: 39s - loss: 0.1628 - acc: 0.94 - ETA: 39s - loss: 0.1624 - acc: 0.94 - ETA: 39s - loss: 0.1624 - acc: 0.94 - ETA: 38s - loss: 0.1626 - acc: 0.94 - ETA: 38s - loss: 0.1623 - acc: 0.94 - ETA: 38s - loss: 0.1625 - acc: 0.94 - ETA: 38s - loss: 0.1622 - acc: 0.94 - ETA: 37s - loss: 0.1620 - acc: 0.94 - ETA: 37s - loss: 0.1625 - acc: 0.94 - ETA: 37s - loss: 0.1629 - acc: 0.94 - ETA: 37s - loss: 0.1629 - acc: 0.94 - ETA: 36s - loss: 0.1631 - acc: 0.94 - ETA: 36s - loss: 0.1627 - acc: 0.94 - ETA: 36s - loss: 0.1624 - acc: 0.94 - ETA: 36s - loss: 0.1620 - acc: 0.94 - ETA: 35s - loss: 0.1616 - acc: 0.94 - ETA: 35s - loss: 0.1613 - acc: 0.94 - ETA: 35s - loss: 0.1609 - acc: 0.94 - ETA: 35s - loss: 0.1608 - acc: 0.94 - ETA: 34s - loss: 0.1608 - acc: 0.94 - ETA: 34s - loss: 0.1608 - acc: 0.94 - ETA: 34s - loss: 0.1605 - acc: 0.94 - ETA: 34s - loss: 0.1617 - acc: 0.94 - ETA: 33s - loss: 0.1628 - acc: 0.94 - ETA: 33s - loss: 0.1627 - acc: 0.94 - ETA: 33s - loss: 0.1626 - acc: 0.94 - ETA: 33s - loss: 0.1623 - acc: 0.94 - ETA: 32s - loss: 0.1623 - acc: 0.94 - ETA: 32s - loss: 0.1619 - acc: 0.94 - ETA: 32s - loss: 0.1616 - acc: 0.94 - ETA: 32s - loss: 0.1614 - acc: 0.94 - ETA: 31s - loss: 0.1610 - acc: 0.94 - ETA: 31s - loss: 0.1605 - acc: 0.94 - ETA: 31s - loss: 0.1603 - acc: 0.94 - ETA: 31s - loss: 0.1613 - acc: 0.94 - ETA: 30s - loss: 0.1618 - acc: 0.94 - ETA: 30s - loss: 0.1615 - acc: 0.94 - ETA: 30s - loss: 0.1615 - acc: 0.94 - ETA: 30s - loss: 0.1610 - acc: 0.94 - ETA: 29s - loss: 0.1611 - acc: 0.94 - ETA: 29s - loss: 0.1607 - acc: 0.94 - ETA: 29s - loss: 0.1612 - acc: 0.94 - ETA: 28s - loss: 0.1614 - acc: 0.94 - ETA: 28s - loss: 0.1611 - acc: 0.94 - ETA: 28s - loss: 0.1613 - acc: 0.94 - ETA: 28s - loss: 0.1612 - acc: 0.94 - ETA: 27s - loss: 0.1611 - acc: 0.94 - ETA: 27s - loss: 0.1612 - acc: 0.94 - ETA: 27s - loss: 0.1608 - acc: 0.94 - ETA: 27s - loss: 0.1605 - acc: 0.94 - ETA: 26s - loss: 0.1602 - acc: 0.94 - ETA: 26s - loss: 0.1607 - acc: 0.94 - ETA: 26s - loss: 0.1603 - acc: 0.94 - ETA: 26s - loss: 0.1600 - acc: 0.94 - ETA: 25s - loss: 0.1599 - acc: 0.94 - ETA: 25s - loss: 0.1597 - acc: 0.94 - ETA: 25s - loss: 0.1593 - acc: 0.94 - ETA: 25s - loss: 0.1591 - acc: 0.94 - ETA: 24s - loss: 0.1588 - acc: 0.94 - ETA: 24s - loss: 0.1585 - acc: 0.94 - ETA: 24s - loss: 0.1586 - acc: 0.94 - ETA: 24s - loss: 0.1583 - acc: 0.94 - ETA: 23s - loss: 0.1579 - acc: 0.94 - ETA: 23s - loss: 0.1583 - acc: 0.94 - ETA: 23s - loss: 0.1585 - acc: 0.94 - ETA: 23s - loss: 0.1584 - acc: 0.94 - ETA: 22s - loss: 0.1584 - acc: 0.94 - ETA: 22s - loss: 0.1582 - acc: 0.94 - ETA: 22s - loss: 0.1579 - acc: 0.94 - ETA: 22s - loss: 0.1580 - acc: 0.94 - ETA: 21s - loss: 0.1580 - acc: 0.94 - ETA: 21s - loss: 0.1576 - acc: 0.94 - ETA: 21s - loss: 0.1577 - acc: 0.94 - ETA: 20s - loss: 0.1576 - acc: 0.94 - ETA: 20s - loss: 0.1579 - acc: 0.94 - ETA: 20s - loss: 0.1579 - acc: 0.94 - ETA: 20s - loss: 0.1576 - acc: 0.94 - ETA: 19s - loss: 0.1578 - acc: 0.94 - ETA: 19s - loss: 0.1584 - acc: 0.94 - ETA: 19s - loss: 0.1583 - acc: 0.94 - ETA: 19s - loss: 0.1580 - acc: 0.94 - ETA: 18s - loss: 0.1582 - acc: 0.94 - ETA: 18s - loss: 0.1583 - acc: 0.94 - ETA: 18s - loss: 0.1582 - acc: 0.94 - ETA: 18s - loss: 0.1588 - acc: 0.94 - ETA: 17s - loss: 0.1591 - acc: 0.94 - ETA: 17s - loss: 0.1588 - acc: 0.94 - ETA: 17s - loss: 0.1587 - acc: 0.94 - ETA: 17s - loss: 0.1587 - acc: 0.94 - ETA: 16s - loss: 0.1588 - acc: 0.94 - ETA: 16s - loss: 0.1587 - acc: 0.94 - ETA: 16s - loss: 0.1587 - acc: 0.94 - ETA: 15s - loss: 0.1586 - acc: 0.94 - ETA: 15s - loss: 0.1585 - acc: 0.94 - ETA: 15s - loss: 0.1585 - acc: 0.94 - ETA: 15s - loss: 0.1584 - acc: 0.94 - ETA: 14s - loss: 0.1581 - acc: 0.94 - ETA: 14s - loss: 0.1580 - acc: 0.94 - ETA: 14s - loss: 0.1579 - acc: 0.94 - ETA: 14s - loss: 0.1577 - acc: 0.94 - ETA: 13s - loss: 0.1577 - acc: 0.94 - ETA: 13s - loss: 0.1576 - acc: 0.94 - ETA: 13s - loss: 0.1576 - acc: 0.94 - ETA: 13s - loss: 0.1574 - acc: 0.94 - ETA: 12s - loss: 0.1573 - acc: 0.94 - ETA: 12s - loss: 0.1574 - acc: 0.94 - ETA: 12s - loss: 0.1576 - acc: 0.94 - ETA: 12s - loss: 0.1573 - acc: 0.94 - ETA: 11s - loss: 0.1573 - acc: 0.94 - ETA: 11s - loss: 0.1575 - acc: 0.94 - ETA: 11s - loss: 0.1574 - acc: 0.94 - ETA: 11s - loss: 0.1572 - acc: 0.94 - ETA: 10s - loss: 0.1570 - acc: 0.94 - ETA: 10s - loss: 0.1568 - acc: 0.94 - ETA: 10s - loss: 0.1566 - acc: 0.94 - ETA: 9s - loss: 0.1568 - acc: 0.9474 - ETA: 9s - loss: 0.1570 - acc: 0.947 - ETA: 9s - loss: 0.1568 - acc: 0.947 - ETA: 9s - loss: 0.1568 - acc: 0.947 - ETA: 8s - loss: 0.1567 - acc: 0.947 - ETA: 8s - loss: 0.1566 - acc: 0.947 - ETA: 8s - loss: 0.1563 - acc: 0.947 - ETA: 8s - loss: 0.1563 - acc: 0.947 - ETA: 7s - loss: 0.1568 - acc: 0.947 - ETA: 7s - loss: 0.1569 - acc: 0.947 - ETA: 7s - loss: 0.1570 - acc: 0.947 - ETA: 7s - loss: 0.1571 - acc: 0.947 - ETA: 6s - loss: 0.1569 - acc: 0.947 - ETA: 6s - loss: 0.1568 - acc: 0.947 - ETA: 6s - loss: 0.1566 - acc: 0.947 - ETA: 6s - loss: 0.1567 - acc: 0.947 - ETA: 5s - loss: 0.1565 - acc: 0.947 - ETA: 5s - loss: 0.1566 - acc: 0.947 - ETA: 5s - loss: 0.1564 - acc: 0.947 - ETA: 4s - loss: 0.1562 - acc: 0.947 - ETA: 4s - loss: 0.1561 - acc: 0.947 - ETA: 4s - loss: 0.1559 - acc: 0.948 - ETA: 4s - loss: 0.1561 - acc: 0.947 - ETA: 3s - loss: 0.1565 - acc: 0.947 - ETA: 3s - loss: 0.1568 - acc: 0.947 - ETA: 3s - loss: 0.1566 - acc: 0.947 - ETA: 3s - loss: 0.1565 - acc: 0.947 - ETA: 2s - loss: 0.1563 - acc: 0.947 - ETA: 2s - loss: 0.1561 - acc: 0.947 - ETA: 2s - loss: 0.1560 - acc: 0.947 - ETA: 2s - loss: 0.1557 - acc: 0.947 - ETA: 1s - loss: 0.1554 - acc: 0.9481"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/427 [============================>.] - ETA: 1s - loss: 0.1555 - acc: 0.948 - ETA: 1s - loss: 0.1556 - acc: 0.948 - ETA: 1s - loss: 0.1553 - acc: 0.948 - ETA: 0s - loss: 0.1554 - acc: 0.948 - ETA: 0s - loss: 0.1565 - acc: 0.947 - ETA: 0s - loss: 0.1566 - acc: 0.9475\n",
      "Epoch 00012: val_loss did not improve\n",
      "427/427 [==============================] - 114s 266ms/step - loss: 0.1564 - acc: 0.9476 - val_loss: 0.4259 - val_acc: 0.8718\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/427 [=============>................] - ETA: 1:45 - loss: 0.0766 - acc: 1.000 - ETA: 1:51 - loss: 0.1395 - acc: 0.950 - ETA: 1:51 - loss: 0.1091 - acc: 0.966 - ETA: 1:49 - loss: 0.2002 - acc: 0.950 - ETA: 1:49 - loss: 0.1771 - acc: 0.960 - ETA: 1:52 - loss: 0.1716 - acc: 0.966 - ETA: 1:52 - loss: 0.1769 - acc: 0.964 - ETA: 1:52 - loss: 0.1742 - acc: 0.962 - ETA: 1:55 - loss: 0.1790 - acc: 0.955 - ETA: 1:55 - loss: 0.1800 - acc: 0.950 - ETA: 1:57 - loss: 0.1772 - acc: 0.950 - ETA: 1:56 - loss: 0.1724 - acc: 0.950 - ETA: 1:56 - loss: 0.1829 - acc: 0.942 - ETA: 1:50 - loss: 0.1818 - acc: 0.946 - ETA: 1:50 - loss: 0.1722 - acc: 0.950 - ETA: 1:49 - loss: 0.1714 - acc: 0.950 - ETA: 1:48 - loss: 0.1796 - acc: 0.950 - ETA: 1:48 - loss: 0.1866 - acc: 0.947 - ETA: 1:48 - loss: 0.1861 - acc: 0.950 - ETA: 1:47 - loss: 0.1894 - acc: 0.947 - ETA: 1:47 - loss: 0.1824 - acc: 0.950 - ETA: 1:47 - loss: 0.1896 - acc: 0.943 - ETA: 1:46 - loss: 0.1835 - acc: 0.945 - ETA: 1:46 - loss: 0.1801 - acc: 0.945 - ETA: 1:46 - loss: 0.1742 - acc: 0.948 - ETA: 1:46 - loss: 0.1694 - acc: 0.950 - ETA: 1:46 - loss: 0.1754 - acc: 0.948 - ETA: 1:45 - loss: 0.1712 - acc: 0.950 - ETA: 1:45 - loss: 0.1755 - acc: 0.948 - ETA: 1:45 - loss: 0.1728 - acc: 0.950 - ETA: 1:45 - loss: 0.1769 - acc: 0.948 - ETA: 1:45 - loss: 0.1736 - acc: 0.950 - ETA: 1:45 - loss: 0.1710 - acc: 0.951 - ETA: 1:45 - loss: 0.1751 - acc: 0.951 - ETA: 1:45 - loss: 0.1739 - acc: 0.951 - ETA: 1:45 - loss: 0.1724 - acc: 0.951 - ETA: 1:43 - loss: 0.1776 - acc: 0.945 - ETA: 1:42 - loss: 0.1766 - acc: 0.943 - ETA: 1:42 - loss: 0.1751 - acc: 0.945 - ETA: 1:42 - loss: 0.1743 - acc: 0.945 - ETA: 1:42 - loss: 0.1722 - acc: 0.946 - ETA: 1:41 - loss: 0.1697 - acc: 0.946 - ETA: 1:41 - loss: 0.1727 - acc: 0.945 - ETA: 1:41 - loss: 0.1743 - acc: 0.944 - ETA: 1:41 - loss: 0.1736 - acc: 0.943 - ETA: 1:41 - loss: 0.1737 - acc: 0.943 - ETA: 1:40 - loss: 0.1714 - acc: 0.945 - ETA: 1:40 - loss: 0.1708 - acc: 0.945 - ETA: 1:40 - loss: 0.1749 - acc: 0.943 - ETA: 1:40 - loss: 0.1734 - acc: 0.944 - ETA: 1:40 - loss: 0.1725 - acc: 0.944 - ETA: 1:39 - loss: 0.1708 - acc: 0.944 - ETA: 1:38 - loss: 0.1694 - acc: 0.945 - ETA: 1:38 - loss: 0.1728 - acc: 0.944 - ETA: 1:38 - loss: 0.1712 - acc: 0.945 - ETA: 1:38 - loss: 0.1734 - acc: 0.944 - ETA: 1:38 - loss: 0.1730 - acc: 0.945 - ETA: 1:38 - loss: 0.1746 - acc: 0.943 - ETA: 1:37 - loss: 0.1739 - acc: 0.943 - ETA: 1:37 - loss: 0.1720 - acc: 0.944 - ETA: 1:37 - loss: 0.1706 - acc: 0.945 - ETA: 1:36 - loss: 0.1683 - acc: 0.946 - ETA: 1:36 - loss: 0.1665 - acc: 0.947 - ETA: 1:36 - loss: 0.1662 - acc: 0.946 - ETA: 1:35 - loss: 0.1659 - acc: 0.946 - ETA: 1:35 - loss: 0.1659 - acc: 0.946 - ETA: 1:35 - loss: 0.1655 - acc: 0.946 - ETA: 1:34 - loss: 0.1645 - acc: 0.947 - ETA: 1:34 - loss: 0.1661 - acc: 0.946 - ETA: 1:33 - loss: 0.1681 - acc: 0.945 - ETA: 1:33 - loss: 0.1679 - acc: 0.945 - ETA: 1:32 - loss: 0.1684 - acc: 0.944 - ETA: 1:32 - loss: 0.1672 - acc: 0.945 - ETA: 1:32 - loss: 0.1667 - acc: 0.945 - ETA: 1:32 - loss: 0.1667 - acc: 0.945 - ETA: 1:32 - loss: 0.1694 - acc: 0.943 - ETA: 1:31 - loss: 0.1699 - acc: 0.942 - ETA: 1:31 - loss: 0.1682 - acc: 0.943 - ETA: 1:31 - loss: 0.1685 - acc: 0.943 - ETA: 1:31 - loss: 0.1686 - acc: 0.943 - ETA: 1:31 - loss: 0.1686 - acc: 0.943 - ETA: 1:30 - loss: 0.1692 - acc: 0.942 - ETA: 1:30 - loss: 0.1700 - acc: 0.942 - ETA: 1:30 - loss: 0.1695 - acc: 0.942 - ETA: 1:29 - loss: 0.1691 - acc: 0.942 - ETA: 1:29 - loss: 0.1715 - acc: 0.941 - ETA: 1:29 - loss: 0.1721 - acc: 0.941 - ETA: 1:28 - loss: 0.1720 - acc: 0.940 - ETA: 1:28 - loss: 0.1709 - acc: 0.941 - ETA: 1:28 - loss: 0.1707 - acc: 0.941 - ETA: 1:28 - loss: 0.1697 - acc: 0.942 - ETA: 1:28 - loss: 0.1689 - acc: 0.942 - ETA: 1:27 - loss: 0.1720 - acc: 0.941 - ETA: 1:27 - loss: 0.1734 - acc: 0.940 - ETA: 1:27 - loss: 0.1723 - acc: 0.940 - ETA: 1:26 - loss: 0.1712 - acc: 0.941 - ETA: 1:26 - loss: 0.1723 - acc: 0.940 - ETA: 1:26 - loss: 0.1711 - acc: 0.941 - ETA: 1:26 - loss: 0.1711 - acc: 0.941 - ETA: 1:26 - loss: 0.1710 - acc: 0.941 - ETA: 1:26 - loss: 0.1709 - acc: 0.941 - ETA: 1:26 - loss: 0.1709 - acc: 0.940 - ETA: 1:25 - loss: 0.1696 - acc: 0.941 - ETA: 1:25 - loss: 0.1688 - acc: 0.941 - ETA: 1:25 - loss: 0.1677 - acc: 0.942 - ETA: 1:25 - loss: 0.1673 - acc: 0.942 - ETA: 1:24 - loss: 0.1671 - acc: 0.941 - ETA: 1:24 - loss: 0.1675 - acc: 0.941 - ETA: 1:23 - loss: 0.1666 - acc: 0.942 - ETA: 1:23 - loss: 0.1671 - acc: 0.941 - ETA: 1:23 - loss: 0.1682 - acc: 0.941 - ETA: 1:23 - loss: 0.1671 - acc: 0.941 - ETA: 1:22 - loss: 0.1666 - acc: 0.942 - ETA: 1:22 - loss: 0.1660 - acc: 0.942 - ETA: 1:22 - loss: 0.1651 - acc: 0.942 - ETA: 1:22 - loss: 0.1645 - acc: 0.943 - ETA: 1:21 - loss: 0.1636 - acc: 0.943 - ETA: 1:21 - loss: 0.1638 - acc: 0.943 - ETA: 1:21 - loss: 0.1640 - acc: 0.943 - ETA: 1:21 - loss: 0.1632 - acc: 0.944 - ETA: 1:20 - loss: 0.1631 - acc: 0.943 - ETA: 1:20 - loss: 0.1634 - acc: 0.943 - ETA: 1:20 - loss: 0.1626 - acc: 0.943 - ETA: 1:20 - loss: 0.1622 - acc: 0.944 - ETA: 1:20 - loss: 0.1645 - acc: 0.943 - ETA: 1:19 - loss: 0.1643 - acc: 0.943 - ETA: 1:19 - loss: 0.1637 - acc: 0.943 - ETA: 1:19 - loss: 0.1631 - acc: 0.943 - ETA: 1:18 - loss: 0.1675 - acc: 0.942 - ETA: 1:18 - loss: 0.1671 - acc: 0.942 - ETA: 1:18 - loss: 0.1665 - acc: 0.942 - ETA: 1:17 - loss: 0.1659 - acc: 0.942 - ETA: 1:17 - loss: 0.1660 - acc: 0.942 - ETA: 1:17 - loss: 0.1651 - acc: 0.943 - ETA: 1:17 - loss: 0.1642 - acc: 0.943 - ETA: 1:16 - loss: 0.1635 - acc: 0.944 - ETA: 1:16 - loss: 0.1627 - acc: 0.944 - ETA: 1:16 - loss: 0.1626 - acc: 0.944 - ETA: 1:16 - loss: 0.1617 - acc: 0.944 - ETA: 1:15 - loss: 0.1619 - acc: 0.944 - ETA: 1:15 - loss: 0.1622 - acc: 0.944 - ETA: 1:15 - loss: 0.1616 - acc: 0.945 - ETA: 1:15 - loss: 0.1609 - acc: 0.945 - ETA: 1:14 - loss: 0.1618 - acc: 0.944 - ETA: 1:14 - loss: 0.1614 - acc: 0.944 - ETA: 1:13 - loss: 0.1618 - acc: 0.944 - ETA: 1:13 - loss: 0.1626 - acc: 0.944 - ETA: 1:13 - loss: 0.1617 - acc: 0.944 - ETA: 1:13 - loss: 0.1612 - acc: 0.944 - ETA: 1:13 - loss: 0.1614 - acc: 0.945 - ETA: 1:12 - loss: 0.1614 - acc: 0.945 - ETA: 1:12 - loss: 0.1607 - acc: 0.945 - ETA: 1:12 - loss: 0.1615 - acc: 0.944 - ETA: 1:12 - loss: 0.1606 - acc: 0.945 - ETA: 1:12 - loss: 0.1600 - acc: 0.945 - ETA: 1:11 - loss: 0.1598 - acc: 0.945 - ETA: 1:11 - loss: 0.1603 - acc: 0.945 - ETA: 1:11 - loss: 0.1607 - acc: 0.944 - ETA: 1:11 - loss: 0.1611 - acc: 0.944 - ETA: 1:10 - loss: 0.1637 - acc: 0.943 - ETA: 1:10 - loss: 0.1646 - acc: 0.942 - ETA: 1:10 - loss: 0.1643 - acc: 0.942 - ETA: 1:09 - loss: 0.1641 - acc: 0.942 - ETA: 1:09 - loss: 0.1651 - acc: 0.942 - ETA: 1:09 - loss: 0.1652 - acc: 0.941 - ETA: 1:09 - loss: 0.1647 - acc: 0.942 - ETA: 1:08 - loss: 0.1645 - acc: 0.942 - ETA: 1:08 - loss: 0.1638 - acc: 0.942 - ETA: 1:08 - loss: 0.1635 - acc: 0.942 - ETA: 1:08 - loss: 0.1629 - acc: 0.943 - ETA: 1:07 - loss: 0.1624 - acc: 0.943 - ETA: 1:07 - loss: 0.1618 - acc: 0.943 - ETA: 1:07 - loss: 0.1617 - acc: 0.943 - ETA: 1:07 - loss: 0.1614 - acc: 0.943 - ETA: 1:06 - loss: 0.1609 - acc: 0.944 - ETA: 1:06 - loss: 0.1614 - acc: 0.943 - ETA: 1:06 - loss: 0.1613 - acc: 0.943 - ETA: 1:05 - loss: 0.1622 - acc: 0.943 - ETA: 1:05 - loss: 0.1629 - acc: 0.943 - ETA: 1:05 - loss: 0.1628 - acc: 0.943 - ETA: 1:05 - loss: 0.1630 - acc: 0.943 - ETA: 1:04 - loss: 0.1629 - acc: 0.943 - ETA: 1:04 - loss: 0.1624 - acc: 0.943 - ETA: 1:04 - loss: 0.1631 - acc: 0.943 - ETA: 1:03 - loss: 0.1624 - acc: 0.943 - ETA: 1:03 - loss: 0.1620 - acc: 0.943 - ETA: 1:03 - loss: 0.1615 - acc: 0.943 - ETA: 1:03 - loss: 0.1609 - acc: 0.944 - ETA: 1:02 - loss: 0.1609 - acc: 0.944 - ETA: 1:02 - loss: 0.1619 - acc: 0.944 - ETA: 1:02 - loss: 0.1616 - acc: 0.944 - ETA: 1:02 - loss: 0.1609 - acc: 0.944 - ETA: 1:01 - loss: 0.1606 - acc: 0.944 - ETA: 1:01 - loss: 0.1602 - acc: 0.944 - ETA: 1:01 - loss: 0.1602 - acc: 0.944 - ETA: 1:01 - loss: 0.1597 - acc: 0.945 - ETA: 1:00 - loss: 0.1614 - acc: 0.944 - ETA: 1:00 - loss: 0.1617 - acc: 0.943 - ETA: 59s - loss: 0.1613 - acc: 0.944 - ETA: 59s - loss: 0.1613 - acc: 0.94 - ETA: 59s - loss: 0.1610 - acc: 0.94 - ETA: 59s - loss: 0.1607 - acc: 0.94 - ETA: 58s - loss: 0.1605 - acc: 0.94 - ETA: 58s - loss: 0.1605 - acc: 0.94 - ETA: 58s - loss: 0.1605 - acc: 0.9440420/427 [============================>.] - ETA: 57s - loss: 0.1602 - acc: 0.94 - ETA: 57s - loss: 0.1605 - acc: 0.94 - ETA: 57s - loss: 0.1605 - acc: 0.94 - ETA: 57s - loss: 0.1610 - acc: 0.94 - ETA: 56s - loss: 0.1609 - acc: 0.94 - ETA: 56s - loss: 0.1603 - acc: 0.94 - ETA: 56s - loss: 0.1600 - acc: 0.94 - ETA: 56s - loss: 0.1606 - acc: 0.94 - ETA: 55s - loss: 0.1601 - acc: 0.94 - ETA: 55s - loss: 0.1604 - acc: 0.94 - ETA: 55s - loss: 0.1601 - acc: 0.94 - ETA: 55s - loss: 0.1598 - acc: 0.94 - ETA: 54s - loss: 0.1595 - acc: 0.94 - ETA: 54s - loss: 0.1593 - acc: 0.94 - ETA: 54s - loss: 0.1593 - acc: 0.94 - ETA: 54s - loss: 0.1589 - acc: 0.94 - ETA: 53s - loss: 0.1586 - acc: 0.94 - ETA: 53s - loss: 0.1582 - acc: 0.94 - ETA: 53s - loss: 0.1579 - acc: 0.94 - ETA: 53s - loss: 0.1581 - acc: 0.94 - ETA: 52s - loss: 0.1587 - acc: 0.94 - ETA: 52s - loss: 0.1585 - acc: 0.94 - ETA: 52s - loss: 0.1583 - acc: 0.94 - ETA: 52s - loss: 0.1580 - acc: 0.94 - ETA: 51s - loss: 0.1577 - acc: 0.94 - ETA: 51s - loss: 0.1573 - acc: 0.94 - ETA: 51s - loss: 0.1571 - acc: 0.94 - ETA: 50s - loss: 0.1580 - acc: 0.94 - ETA: 50s - loss: 0.1583 - acc: 0.94 - ETA: 50s - loss: 0.1579 - acc: 0.94 - ETA: 50s - loss: 0.1576 - acc: 0.94 - ETA: 49s - loss: 0.1575 - acc: 0.94 - ETA: 49s - loss: 0.1571 - acc: 0.94 - ETA: 49s - loss: 0.1572 - acc: 0.94 - ETA: 49s - loss: 0.1575 - acc: 0.94 - ETA: 48s - loss: 0.1574 - acc: 0.94 - ETA: 48s - loss: 0.1609 - acc: 0.94 - ETA: 48s - loss: 0.1612 - acc: 0.94 - ETA: 47s - loss: 0.1609 - acc: 0.94 - ETA: 47s - loss: 0.1603 - acc: 0.94 - ETA: 47s - loss: 0.1598 - acc: 0.94 - ETA: 47s - loss: 0.1607 - acc: 0.94 - ETA: 46s - loss: 0.1607 - acc: 0.94 - ETA: 46s - loss: 0.1603 - acc: 0.94 - ETA: 46s - loss: 0.1605 - acc: 0.94 - ETA: 46s - loss: 0.1610 - acc: 0.94 - ETA: 45s - loss: 0.1608 - acc: 0.94 - ETA: 45s - loss: 0.1607 - acc: 0.94 - ETA: 45s - loss: 0.1603 - acc: 0.94 - ETA: 44s - loss: 0.1601 - acc: 0.94 - ETA: 44s - loss: 0.1603 - acc: 0.94 - ETA: 44s - loss: 0.1602 - acc: 0.94 - ETA: 44s - loss: 0.1601 - acc: 0.94 - ETA: 43s - loss: 0.1598 - acc: 0.94 - ETA: 43s - loss: 0.1594 - acc: 0.94 - ETA: 43s - loss: 0.1592 - acc: 0.94 - ETA: 43s - loss: 0.1589 - acc: 0.94 - ETA: 42s - loss: 0.1589 - acc: 0.94 - ETA: 42s - loss: 0.1596 - acc: 0.94 - ETA: 42s - loss: 0.1592 - acc: 0.94 - ETA: 42s - loss: 0.1591 - acc: 0.94 - ETA: 41s - loss: 0.1601 - acc: 0.94 - ETA: 41s - loss: 0.1600 - acc: 0.94 - ETA: 41s - loss: 0.1599 - acc: 0.94 - ETA: 41s - loss: 0.1596 - acc: 0.94 - ETA: 40s - loss: 0.1593 - acc: 0.94 - ETA: 40s - loss: 0.1595 - acc: 0.94 - ETA: 40s - loss: 0.1597 - acc: 0.94 - ETA: 39s - loss: 0.1596 - acc: 0.94 - ETA: 39s - loss: 0.1598 - acc: 0.94 - ETA: 39s - loss: 0.1600 - acc: 0.94 - ETA: 39s - loss: 0.1596 - acc: 0.94 - ETA: 38s - loss: 0.1595 - acc: 0.94 - ETA: 38s - loss: 0.1593 - acc: 0.94 - ETA: 38s - loss: 0.1593 - acc: 0.94 - ETA: 38s - loss: 0.1591 - acc: 0.94 - ETA: 37s - loss: 0.1597 - acc: 0.94 - ETA: 37s - loss: 0.1593 - acc: 0.94 - ETA: 37s - loss: 0.1591 - acc: 0.94 - ETA: 37s - loss: 0.1588 - acc: 0.94 - ETA: 36s - loss: 0.1597 - acc: 0.94 - ETA: 36s - loss: 0.1597 - acc: 0.94 - ETA: 36s - loss: 0.1599 - acc: 0.94 - ETA: 36s - loss: 0.1610 - acc: 0.94 - ETA: 35s - loss: 0.1606 - acc: 0.94 - ETA: 35s - loss: 0.1610 - acc: 0.94 - ETA: 35s - loss: 0.1612 - acc: 0.94 - ETA: 34s - loss: 0.1608 - acc: 0.94 - ETA: 34s - loss: 0.1606 - acc: 0.94 - ETA: 34s - loss: 0.1602 - acc: 0.94 - ETA: 34s - loss: 0.1598 - acc: 0.94 - ETA: 33s - loss: 0.1597 - acc: 0.94 - ETA: 33s - loss: 0.1595 - acc: 0.94 - ETA: 33s - loss: 0.1591 - acc: 0.94 - ETA: 33s - loss: 0.1591 - acc: 0.94 - ETA: 32s - loss: 0.1589 - acc: 0.94 - ETA: 32s - loss: 0.1591 - acc: 0.94 - ETA: 32s - loss: 0.1587 - acc: 0.94 - ETA: 32s - loss: 0.1588 - acc: 0.94 - ETA: 31s - loss: 0.1583 - acc: 0.94 - ETA: 31s - loss: 0.1584 - acc: 0.94 - ETA: 31s - loss: 0.1585 - acc: 0.94 - ETA: 30s - loss: 0.1591 - acc: 0.94 - ETA: 30s - loss: 0.1589 - acc: 0.94 - ETA: 30s - loss: 0.1589 - acc: 0.94 - ETA: 30s - loss: 0.1586 - acc: 0.94 - ETA: 29s - loss: 0.1587 - acc: 0.94 - ETA: 29s - loss: 0.1593 - acc: 0.94 - ETA: 29s - loss: 0.1592 - acc: 0.94 - ETA: 29s - loss: 0.1590 - acc: 0.94 - ETA: 28s - loss: 0.1586 - acc: 0.94 - ETA: 28s - loss: 0.1583 - acc: 0.94 - ETA: 28s - loss: 0.1580 - acc: 0.94 - ETA: 28s - loss: 0.1577 - acc: 0.94 - ETA: 27s - loss: 0.1581 - acc: 0.94 - ETA: 27s - loss: 0.1581 - acc: 0.94 - ETA: 27s - loss: 0.1581 - acc: 0.94 - ETA: 27s - loss: 0.1584 - acc: 0.94 - ETA: 26s - loss: 0.1581 - acc: 0.94 - ETA: 26s - loss: 0.1583 - acc: 0.94 - ETA: 26s - loss: 0.1582 - acc: 0.94 - ETA: 25s - loss: 0.1581 - acc: 0.94 - ETA: 25s - loss: 0.1578 - acc: 0.94 - ETA: 25s - loss: 0.1578 - acc: 0.94 - ETA: 25s - loss: 0.1576 - acc: 0.94 - ETA: 24s - loss: 0.1582 - acc: 0.94 - ETA: 24s - loss: 0.1580 - acc: 0.94 - ETA: 24s - loss: 0.1586 - acc: 0.94 - ETA: 24s - loss: 0.1586 - acc: 0.94 - ETA: 23s - loss: 0.1582 - acc: 0.94 - ETA: 23s - loss: 0.1578 - acc: 0.94 - ETA: 23s - loss: 0.1575 - acc: 0.94 - ETA: 23s - loss: 0.1574 - acc: 0.94 - ETA: 22s - loss: 0.1570 - acc: 0.94 - ETA: 22s - loss: 0.1570 - acc: 0.94 - ETA: 22s - loss: 0.1566 - acc: 0.94 - ETA: 22s - loss: 0.1571 - acc: 0.94 - ETA: 21s - loss: 0.1572 - acc: 0.94 - ETA: 21s - loss: 0.1575 - acc: 0.94 - ETA: 21s - loss: 0.1579 - acc: 0.94 - ETA: 21s - loss: 0.1576 - acc: 0.94 - ETA: 20s - loss: 0.1574 - acc: 0.94 - ETA: 20s - loss: 0.1572 - acc: 0.94 - ETA: 20s - loss: 0.1572 - acc: 0.94 - ETA: 20s - loss: 0.1571 - acc: 0.94 - ETA: 19s - loss: 0.1572 - acc: 0.94 - ETA: 19s - loss: 0.1572 - acc: 0.94 - ETA: 19s - loss: 0.1570 - acc: 0.94 - ETA: 18s - loss: 0.1567 - acc: 0.94 - ETA: 18s - loss: 0.1563 - acc: 0.94 - ETA: 18s - loss: 0.1560 - acc: 0.94 - ETA: 18s - loss: 0.1557 - acc: 0.94 - ETA: 17s - loss: 0.1559 - acc: 0.94 - ETA: 17s - loss: 0.1556 - acc: 0.94 - ETA: 17s - loss: 0.1556 - acc: 0.94 - ETA: 17s - loss: 0.1556 - acc: 0.94 - ETA: 16s - loss: 0.1557 - acc: 0.94 - ETA: 16s - loss: 0.1554 - acc: 0.94 - ETA: 16s - loss: 0.1556 - acc: 0.94 - ETA: 16s - loss: 0.1556 - acc: 0.94 - ETA: 15s - loss: 0.1560 - acc: 0.94 - ETA: 15s - loss: 0.1563 - acc: 0.94 - ETA: 15s - loss: 0.1563 - acc: 0.94 - ETA: 15s - loss: 0.1563 - acc: 0.94 - ETA: 14s - loss: 0.1561 - acc: 0.94 - ETA: 14s - loss: 0.1564 - acc: 0.94 - ETA: 14s - loss: 0.1568 - acc: 0.94 - ETA: 14s - loss: 0.1567 - acc: 0.94 - ETA: 13s - loss: 0.1577 - acc: 0.94 - ETA: 13s - loss: 0.1579 - acc: 0.94 - ETA: 13s - loss: 0.1586 - acc: 0.94 - ETA: 12s - loss: 0.1586 - acc: 0.94 - ETA: 12s - loss: 0.1587 - acc: 0.94 - ETA: 12s - loss: 0.1588 - acc: 0.94 - ETA: 12s - loss: 0.1585 - acc: 0.94 - ETA: 11s - loss: 0.1583 - acc: 0.94 - ETA: 11s - loss: 0.1579 - acc: 0.94 - ETA: 11s - loss: 0.1577 - acc: 0.94 - ETA: 11s - loss: 0.1579 - acc: 0.94 - ETA: 10s - loss: 0.1579 - acc: 0.94 - ETA: 10s - loss: 0.1576 - acc: 0.94 - ETA: 10s - loss: 0.1582 - acc: 0.94 - ETA: 10s - loss: 0.1586 - acc: 0.94 - ETA: 9s - loss: 0.1588 - acc: 0.9432 - ETA: 9s - loss: 0.1587 - acc: 0.943 - ETA: 9s - loss: 0.1586 - acc: 0.943 - ETA: 9s - loss: 0.1583 - acc: 0.943 - ETA: 8s - loss: 0.1586 - acc: 0.943 - ETA: 8s - loss: 0.1587 - acc: 0.943 - ETA: 8s - loss: 0.1586 - acc: 0.943 - ETA: 8s - loss: 0.1584 - acc: 0.943 - ETA: 7s - loss: 0.1581 - acc: 0.943 - ETA: 7s - loss: 0.1578 - acc: 0.943 - ETA: 7s - loss: 0.1575 - acc: 0.944 - ETA: 6s - loss: 0.1574 - acc: 0.944 - ETA: 6s - loss: 0.1572 - acc: 0.944 - ETA: 6s - loss: 0.1577 - acc: 0.944 - ETA: 6s - loss: 0.1580 - acc: 0.944 - ETA: 5s - loss: 0.1577 - acc: 0.944 - ETA: 5s - loss: 0.1575 - acc: 0.944 - ETA: 5s - loss: 0.1577 - acc: 0.944 - ETA: 5s - loss: 0.1576 - acc: 0.944 - ETA: 4s - loss: 0.1578 - acc: 0.943 - ETA: 4s - loss: 0.1577 - acc: 0.943 - ETA: 4s - loss: 0.1578 - acc: 0.943 - ETA: 4s - loss: 0.1577 - acc: 0.944 - ETA: 3s - loss: 0.1575 - acc: 0.944 - ETA: 3s - loss: 0.1576 - acc: 0.944 - ETA: 3s - loss: 0.1574 - acc: 0.944 - ETA: 3s - loss: 0.1571 - acc: 0.944 - ETA: 2s - loss: 0.1573 - acc: 0.944 - ETA: 2s - loss: 0.1570 - acc: 0.944 - ETA: 2s - loss: 0.1569 - acc: 0.944 - ETA: 2s - loss: 0.1567 - acc: 0.944 - ETA: 1s - loss: 0.1565 - acc: 0.9444426/427 [============================>.] - ETA: 1s - loss: 0.1565 - acc: 0.944 - ETA: 1s - loss: 0.1562 - acc: 0.944 - ETA: 1s - loss: 0.1560 - acc: 0.944 - ETA: 0s - loss: 0.1561 - acc: 0.944 - ETA: 0s - loss: 0.1560 - acc: 0.944 - ETA: 0s - loss: 0.1560 - acc: 0.9444\n",
      "Epoch 00013: val_loss did not improve\n",
      "427/427 [==============================] - 112s 263ms/step - loss: 0.1557 - acc: 0.9445 - val_loss: 0.4130 - val_acc: 0.8490\n",
      "Epoch 14/25\n",
      " 24/427 [>.............................] - ETA: 2:00 - loss: 0.2982 - acc: 0.950 - ETA: 2:02 - loss: 0.1983 - acc: 0.950 - ETA: 2:03 - loss: 0.2077 - acc: 0.950 - ETA: 2:00 - loss: 0.1908 - acc: 0.937 - ETA: 1:43 - loss: 0.1748 - acc: 0.950 - ETA: 1:47 - loss: 0.1600 - acc: 0.958 - ETA: 1:47 - loss: 0.1662 - acc: 0.957 - ETA: 1:49 - loss: 0.1686 - acc: 0.950 - ETA: 1:48 - loss: 0.1597 - acc: 0.955 - ETA: 1:50 - loss: 0.1666 - acc: 0.945 - ETA: 1:50 - loss: 0.1712 - acc: 0.940 - ETA: 1:50 - loss: 0.1832 - acc: 0.933 - ETA: 1:49 - loss: 0.1752 - acc: 0.938 - ETA: 1:48 - loss: 0.1638 - acc: 0.942 - ETA: 1:49 - loss: 0.1628 - acc: 0.943 - ETA: 1:49 - loss: 0.1590 - acc: 0.946 - ETA: 1:50 - loss: 0.1583 - acc: 0.947 - ETA: 1:47 - loss: 0.1970 - acc: 0.926 - ETA: 1:46 - loss: 0.1908 - acc: 0.927 - ETA: 1:46 - loss: 0.1881 - acc: 0.926 - ETA: 1:46 - loss: 0.1918 - acc: 0.927 - ETA: 1:46 - loss: 0.1871 - acc: 0.930 - ETA: 1:46 - loss: 0.1883 - acc: 0.931 - ETA: 1:45 - loss: 0.1844 - acc: 0.9342"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-ff8da416791c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                     validation_steps=valid_X.shape[0] )\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1254\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "epochs = 25\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping  \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.aug.best.hdf5', \n",
    "                               monitor='val_loss',verbose=1, save_best_only=True)\n",
    "history_aug = model_custom.fit_generator(train_augmented_X.flow(train_X, train_targets, batch_size=batch_size,shuffle=True),\n",
    "                    steps_per_epoch=train_X.shape[0] ,\n",
    "                    epochs=epochs, verbose=1, callbacks=[checkpointer,early_stopping],\n",
    "                    validation_data=(valid_X, valid_targets),\n",
    "                    validation_steps=valid_X.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Augumented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights(model_custom,'weights.aug.best.hdf5', test_X, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-Like Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNetLikeCovNet(input_layer):    \n",
    "    from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D,Dense\n",
    "    x = Conv2D(filters=8, kernel_size=5, strides=5, input_shape=(96, 96, 1),\n",
    "                      padding='same')(input_layer)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Now through the second convolutional layer\n",
    "    x = (Conv2D(filters=32, kernel_size=5, strides=5, padding='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    dense_1 = Dense(1024, kernel_initializer='glorot_normal', activation='relu')(x)\n",
    "    drop_1 = Dropout(0.5)(dense_1)\n",
    "\n",
    "    dense_2 = Dense(99, kernel_initializer='glorot_normal', activation='relu')(drop_1)\n",
    "    drop_2 = Dropout(0.5)(dense_2)\n",
    "\n",
    "    output_layer = Dense(2, activation='softmax')(drop_2)\n",
    "    model = Model(input_layer,output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load & Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lenet_like = LeNetLikeCovNet(input_layer)\n",
    "#model = AlexNex(input_layer)\n",
    "model_lenet_like.compile(optimizer=rmsprop(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train Model on Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "epochs = 2\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.LeNet.best.hdf5', \n",
    "                               monitor='val_loss',verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "history = model_lenet_like.fit(train_X, train_targets,\n",
    "                    steps_per_epoch=train_X.shape[0] ,\n",
    "                    epochs=epochs, verbose=1, callbacks=[checkpointer,early_stopping],\n",
    "                    validation_data=(valid_X, valid_targets),\n",
    "                    validation_steps=valid_X.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate LeNet-Like Model on Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights(model_lenet_like,'weights.LeNet.best', test_X, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model on Augumented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.LeNet.aug.best.hdf5', \n",
    "                               monitor='val_loss',verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "history_aug = model_lenet_like.fit_generator(train_augmented_X.flow(train_X, train_targets, batch_size=batch_size,shuffle=True),\n",
    "                    steps_per_epoch=train_X.shape[0] ,\n",
    "                    epochs=epochs, verbose=1, callbacks=[checkpointer,early_stopping],\n",
    "                    validation_data=(valid_X, valid_targets),\n",
    "                    validation_steps=valid_X.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on Augumented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights(model_lenet_like, 'weights.LeNet.aug.best.hdf5', test_X, test_targets) # Load weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-Face Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on VGG16 architecture -> old paper(2015)\n",
    "vggface = VGGFace(model='vgg16') # or VGGFace() as default\n",
    "\n",
    "# Based on RESNET50 architecture -> new paper(2017)\n",
    "#vggface = VGGFace(model='resnet50')\n",
    "\n",
    "# Based on SENET50 architecture -> new paper(2017)\n",
    "#vggface = VGGFace(model='senet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 8631)         17684919    flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,246,071\n",
      "Trainable params: 41,192,951\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggface.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#custom parameters\n",
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "\n",
    "vgg_model = VGGFace(include_top=True, input_shape=(224, 224, 3))\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "custom_vgg_model = Model(vgg_model.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 27,823,938\n",
      "Trainable params: 27,823,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters Initialization\n",
    "from keras.optimizers import rmsprop,SGD,Adam,Adadelta\n",
    "#opt = rmsprop(lr=0.0001, decay=1e-6)\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer=rmsprop(0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "  3/186 [..............................] - ETA: 1:06:05 - loss: 11.2827 - acc: 0.300 - ETA: 55:48 - loss: 8.0590 - acc: 0.5000  - ETA: 51:23 - loss: 6.9845 - acc: 0.5667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-42e7f19c4e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     validation_steps=valid_tensors.shape[0] )\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping  \n",
    "\n",
    "batch_size = 10\n",
    "epochs = 40\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.custom_vgg_model.best.hdf5', \n",
    "                               monitor='val_loss',verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='auto')\n",
    "\n",
    "hist = custom_vgg_model.fit_generator(datagen_train.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    steps_per_epoch=train_tensors.shape[0] ,\n",
    "                    epochs=epochs, verbose=1, callbacks=[checkpointer,early_stopping],\n",
    "                    validation_data=datagen_valid.flow(valid_tensors, valid_targets, batch_size=batch_size),\n",
    "                    validation_steps=valid_tensors.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights(custom_vgg_model,'weights.custom_vgg_model.best.hdf5',test_X, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
